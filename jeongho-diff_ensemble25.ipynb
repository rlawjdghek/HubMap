{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indonesian-astrology",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ------------Library--------------#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.sampler import *\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.optim.lr_scheduler import MultiStepLR, CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "from torch.nn.utils.rnn import *\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.autograd import Variable\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "import tifffile as tiff\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import itertools as it\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from sklearn.model_selection import KFold\n",
    "# loss\n",
    "#from lovasz import lovasz_hinge\n",
    "#from losses_pytorch.lovasz_loss import LovaszSoftmax\n",
    "PI  = np.pi\n",
    "INF = np.inf\n",
    "EPS = 1e-12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upset-paint",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    # ---- factor ---- #\n",
    "    amp = True\n",
    "    gpu = \"0,1,2,3\"\n",
    "    encoder='b4'#'resnet34'\n",
    "    decoder='unet'\n",
    "    diff_arch = True\n",
    "    encoders = [\"resnext50_32x4d\", \"densenet121\", \"efficientnet-b4\", \"efficientnet-b4\", \"xception\"]\n",
    "    decoders = [\"unet\", \"fpn\", \"upp\", \"unet\", \"upp\"]\n",
    "    \n",
    "    batch_size=32\n",
    "    weight_decay=1e-6\n",
    "    epochs=25\n",
    "    n_fold=5\n",
    "    fold=0 # [0, 1, 2, 3, 4]\n",
    "    all_fold_train = True # all fold training\n",
    "    \n",
    "    # ---- Dataset ---- #\n",
    "    image_size=512 # crop size\n",
    "    crop_size=image_size\n",
    "    \n",
    "    tile_size = 640\n",
    "    tile_step = 320\n",
    "    tile_scale = 0.5\n",
    "    dataset = f'{tile_scale}_{tile_size}_{tile_step}_train_fold'#'0.25_320_160_train_fold'\n",
    "    val_dataset = f'{tile_scale}_{tile_size}_{tile_size}_val_fold'\n",
    "    if diff_arch:\n",
    "        dir = f'{epochs}_{encoders}_{decoders}_{image_size}_{tile_size}_{tile_step}_{tile_scale}'\n",
    "    else:\n",
    "        dir = f'{epochs}_{encoder}_{decoder}_{image_size}_{tile_size}_{tile_step}_{tile_scale}' \n",
    "    # ---- optimizer, scheduler .. ---- #\n",
    "    T_max=10 # CosineAnnealingLR\n",
    "    opt =  'radam_look' # [adamw, radam_look]\n",
    "    scheduler='CosineAnnealingLR' #'MultiStepLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    loss = 'bce' # [lovasz, bce, bce_dice, dice]\n",
    "    factor=0.4 # ReduceLROnPlateau, MultiStepLR\n",
    "    patience=3 # ReduceLROnPlateau\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    \n",
    "    decay_epoch = [4, 8, 12]\n",
    "    T_0=4 # CosineAnnealingWarmRestarts\n",
    "    #encoder_lr=4e-4\n",
    "    #decoder_lr=4e-4\n",
    "    start_lr = 1e-3\n",
    "    min_lr=1e-6\n",
    "    #----------------------------------#\n",
    "    \n",
    "    \n",
    "    # ----- 여러 시도 ------#\n",
    "    clf_head=False # encoder에 classfication head 붙일지 여부\n",
    "    label_smoothing = False # label smoothing 여부\n",
    "    multi_gpu=True if len(gpu)>1 else False # multi gpu 사용\n",
    "    clf_alpha = 0.3 # classification head 의 loss 비율\n",
    "    smoothing = 0.1 # label smoothing factor\n",
    "    dice_smoothing = 1 # dice loss 사용시 하이퍼 파라미터\n",
    "    \n",
    "    # ---- Else ---- #\n",
    "    num_workers=8\n",
    "    seed=42\n",
    "    \n",
    "data_dir = '/home/jeonghokim/competition/HubMap/data/'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "##----------------\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # for faster training, but not deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-product",
   "metadata": {},
   "source": [
    "# useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-community",
   "metadata": {
    "code_folding": [
     0,
     2,
     13,
     24,
     42,
     56,
     73,
     87,
     108,
     125,
     133,
     146,
     192,
     202,
     228,
     230,
     234,
     249
    ]
   },
   "outputs": [],
   "source": [
    "#-------evaluation metric, loss---------#\n",
    "###################################\n",
    "def np_binary_cross_entropy_loss(probability, mask):\n",
    "    p = probability.reshape(-1)\n",
    "    t = mask.reshape(-1)\n",
    "\n",
    "    #---\n",
    "    logp = -np.log(np.clip(p,1e-6,1))\n",
    "    logn = -np.log(np.clip(1-p,1e-6,1))\n",
    "    loss = t*logp +(1-t)*logn\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def np_dice_score(probability, mask):\n",
    "    p = probability.reshape(-1)\n",
    "    t = mask.reshape(-1)\n",
    "\n",
    "    p = p>0.5\n",
    "    t = t>0.5\n",
    "    uion = p.sum() + t.sum()\n",
    "    overlap = (p*t).sum()\n",
    "    dice = 2*overlap/(uion+0.001)\n",
    "    return dice\n",
    "\n",
    "def dice_score(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,):\n",
    "    \"\"\"\n",
    "    Reference:\n",
    "    https://catalyst-team.github.io/catalyst/_modules/catalyst/dl/utils/criterion/dice.html\n",
    "    \"\"\"\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "        targets = (targets > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    dice = 2 * intersection / (union + eps)\n",
    "\n",
    "    return dice\n",
    "def torch_accuracy(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,):\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "        \n",
    "    tp = torch.sum(targets*outputs)/torch.sum(targets)\n",
    "    tn = torch.sum((1-outputs)*(1-targets))/torch.sum(1-targets)\n",
    "\n",
    "    return tp, tn\n",
    "\n",
    "def np_accuracy(probability, mask):\n",
    "    p = probability.reshape(-1)\n",
    "    t = mask.reshape(-1)\n",
    "    p = p>0.5\n",
    "    t = t>0.5\n",
    "    tp = (p*t).sum()/((t).sum()+1e-7)\n",
    "    tn = ((1-p)*(1-t)).sum()/(1-t).sum()\n",
    "    return tp, tn\n",
    "\n",
    "def criterion_binary_cross_entropy(logit, mask):\n",
    "    logit = logit.reshape(-1)\n",
    "    mask = mask.reshape(-1)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(logit, mask)\n",
    "    return loss\n",
    "\n",
    "# threshold dice score\n",
    "def np_dice_score2(probability, mask, threshold):\n",
    "    p = probability.reshape(-1)\n",
    "    t = mask.reshape(-1)\n",
    "\n",
    "    p = p>threshold\n",
    "    t = t>0.5\n",
    "    uion = p.sum() + t.sum()\n",
    "    overlap = (p*t).sum()\n",
    "    dice = 2*overlap/(uion+0.001)\n",
    "    return dice\n",
    "\n",
    "# --------------------\n",
    "# Loss\n",
    "# --------------------\n",
    "class DiceBCELoss(nn.Module):\n",
    "    # Formula Given above.\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=args.smoothing):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        BCE = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).mean()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.mean() + targets.mean() + smooth)  \n",
    "        \n",
    "        Dice_BCE = BCE*0.6 + dice_loss*0.4\n",
    "        \n",
    "        return Dice_BCE.mean()\n",
    "class DiceLoss(nn.Module):\n",
    "    # Formula Given above.\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=args.dice_smoothing):\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        inputs = F.sigmoid(inputs)   \n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).mean()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.mean() + targets.mean() + smooth)  \n",
    "                \n",
    "        return dice_loss.mean()\n",
    "    \n",
    "#PyTorch lovasz\n",
    "def symmetric_lovasz(outputs, targets):\n",
    "    return 0.5*(lovasz_hinge(outputs, targets) + lovasz_hinge(-outputs, 1.0 - targets))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "#from torch.autograd import Function\n",
    "# copy from: https://github.com/Hsuxu/Loss_ToolBox-PyTorch/blob/master/LovaszSoftmax/lovasz_loss.py\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1:  # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "class LovaszSoftmax(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(LovaszSoftmax, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def prob_flatten(self, input, target):\n",
    "        assert input.dim() in [4, 5]\n",
    "        num_class = input.size(1)\n",
    "        if input.dim() == 4:\n",
    "            input = input.permute(0, 2, 3, 1).contiguous()\n",
    "            input_flatten = input.view(-1, num_class)\n",
    "        elif input.dim() == 5:\n",
    "            input = input.permute(0, 2, 3, 4, 1).contiguous()\n",
    "            input_flatten = input.view(-1, num_class)\n",
    "        target_flatten = target.view(-1)\n",
    "        return input_flatten, target_flatten\n",
    "\n",
    "    def lovasz_softmax_flat(self, inputs, targets):\n",
    "        num_classes = inputs.size(1)\n",
    "        losses = []\n",
    "        for c in range(num_classes):\n",
    "            target_c = (targets == c).float()\n",
    "            if num_classes == 1:\n",
    "                input_c = inputs[:, 0]\n",
    "            else:\n",
    "                input_c = inputs[:, c]\n",
    "            loss_c = (torch.autograd.Variable(target_c) - input_c).abs()\n",
    "            loss_c_sorted, loss_index = torch.sort(loss_c, 0, descending=True)\n",
    "            target_c_sorted = target_c[loss_index]\n",
    "            losses.append(torch.dot(loss_c_sorted, torch.autograd.Variable(lovasz_grad(target_c_sorted))))\n",
    "        losses = torch.stack(losses)\n",
    "\n",
    "        if self.reduction == 'none':\n",
    "            loss = losses\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = losses.sum()\n",
    "        else:\n",
    "            loss = losses.mean()\n",
    "        return loss\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # print(inputs.shape, targets.shape) # (batch size, class_num, x,y,z), (batch size, 1, x,y,z)\n",
    "        inputs, targets = self.prob_flatten(inputs, targets)\n",
    "        # print(inputs.shape, targets.shape)\n",
    "        losses = self.lovasz_softmax_flat(inputs, targets)\n",
    "        return losses\n",
    "class Lovasz_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lovasz_loss, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        return LovaszSoftmax()(inputs, targets)\n",
    "###################################\n",
    "#-------ELSE function---------#\n",
    "###################################\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  #stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1 ):\n",
    "        if '\\r' in message: is_file=0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            #time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass\n",
    "def print_args(args, logger=None):\n",
    "    for k, v in vars(args).items():\n",
    "        if logger is not None:\n",
    "            logger.write('{:<16} : {}\\n'.format(k, v))\n",
    "        else:\n",
    "            print('{:<16} : {}'.format(k, v))\n",
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr\n",
    "\n",
    "\n",
    "###########################\n",
    "#---- label smoothing -----\n",
    "###########################\n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = args.smoothing):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        x = x.float().flatten()\n",
    "        target = target.float() * (1-self.smoothing) + 0.5 * self.smoothing\n",
    "        target = target.flatten()\n",
    "\n",
    "\n",
    "        loss  = F.binary_cross_entropy_with_logits(x, target, reduction='mean')\n",
    "\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contained-information",
   "metadata": {
    "code_folding": [
     1,
     20,
     27,
     52,
     67,
     79,
     153,
     196,
     208
    ]
   },
   "outputs": [],
   "source": [
    "#-------masking & tile & decode---------#\n",
    "def read_tiff(image_file):\n",
    "    \"\"\"\n",
    "    *data size*\n",
    "    e.g.) (3, w, h) or (1,1,3,w,h) or (w, h, 3)  --> transform --> (w, h, 3)\n",
    "    \"\"\"\n",
    "    image = tiff.imread(image_file)\n",
    "    if image.shape[0] == 1:\n",
    "        image = image[0][0]\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        image = np.ascontiguousarray(image)\n",
    "    elif image.shape[0] == 3:\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        image = np.ascontiguousarray(image)\n",
    "    return image\n",
    "\n",
    "def read_mask(mask_file):\n",
    "    mask = np.array(Image.open(mask_file))\n",
    "    return mask\n",
    "\n",
    "def read_json_as_df(json_file):\n",
    "    with open(json_file) as f:\n",
    "        j = json.load(f)\n",
    "    df = pd.json_normalize(j)\n",
    "    return df\n",
    "\n",
    "\n",
    "def draw_strcuture(df, height, width, fill=255, structure=[]):\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    for row in df.values:\n",
    "        type  = row[2]  #geometry.type\n",
    "        coord = row[3]  # geometry.coordinates\n",
    "        name  = row[4]   # properties.classification.name\n",
    "\n",
    "        if structure !=[]:\n",
    "            if not any(s in name for s in structure): continue\n",
    "\n",
    "\n",
    "        if type=='Polygon':\n",
    "            pt = np.array(coord).astype(np.int32)\n",
    "            #cv2.polylines(mask, [coord.reshape((-1, 1, 2))], True, 255, 1)\n",
    "            cv2.fillPoly(mask, [pt.reshape((-1, 1, 2))], fill)\n",
    "\n",
    "        if type=='MultiPolygon':\n",
    "            for pt in coord:\n",
    "                pt = np.array(pt).astype(np.int32)\n",
    "                cv2.fillPoly(mask, [pt.reshape((-1, 1, 2))], fill)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# resize, cvtcolor, generate mask\n",
    "# 원하는 object 영역만 따오는 mask\n",
    "def draw_strcuture_from_hue(image, fill=255, scale=1/32): # 0.25/32 default\n",
    "    height, width, _ = image.shape\n",
    "    vv = cv2.resize(image, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "    vv = cv2.cvtColor(vv, cv2.COLOR_RGB2HSV)\n",
    "    # image_show('v[0]', v[:,:,0])\n",
    "    # image_show('v[1]', v[:,:,1])\n",
    "    # image_show('v[2]', v[:,:,2])\n",
    "    # cv2.waitKey(0)\n",
    "    mask = (vv[:, :, 1] > 32).astype(np.uint8) # rgb2hsv를 하고나서 1채널에 대해 시행하면 원하는 object만 잘따온다.\n",
    "    mask = mask*fill\n",
    "    mask = cv2.resize(mask, dsize=(width, height), interpolation=cv2.INTER_LINEAR) # 다시 원래사이즈로 복구\n",
    "\n",
    "    return mask\n",
    "\n",
    "# --- rle ---------------------------------\n",
    "def rle_decode(rle, height, width , fill=255):\n",
    "    s = rle.split()\n",
    "    start, length = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    start -= 1\n",
    "    mask = np.zeros(height*width, dtype=np.uint8)\n",
    "    for i, l in zip(start, length):\n",
    "        mask[i:i+l] = fill\n",
    "    mask = mask.reshape(width,height).T\n",
    "    mask = np.ascontiguousarray(mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def rle_encode(mask):\n",
    "    m = mask.T.flatten()\n",
    "    m = np.concatenate([[0], m, [0]])\n",
    "    run = np.where(m[1:] != m[:-1])[0] + 1\n",
    "    run[1::2] -= run[::2]\n",
    "    rle =  ' '.join(str(r) for r in run)\n",
    "    return rle\n",
    "\n",
    "\n",
    "# --- tile ---------------------------------\n",
    "\"\"\"\n",
    "-결국, tile_image, tile_mask만 가져다가 쓴다.\n",
    "1. scale로 resize를 하고 image size와 step만큼 건너뛰며 이미지를 만든다.\n",
    "2. 이때 일정 영역이 빈마스크면 데이터에서 제외한다.\n",
    "3. 쌓은 image와 mask를 return\n",
    "\"\"\"\n",
    "def to_tile(image, mask, structure, scale, size, step, min_score): \n",
    "    half = size//2\n",
    "    image_small = cv2.resize(image, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR) # defualt는 1/4만큼 w,h를 줄인다.\n",
    "    height, width, _ = image_small.shape\n",
    "\n",
    "    #make score\n",
    "    structure_small = cv2.resize(structure, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "    vv = structure_small.astype(np.float32)/255\n",
    "\n",
    "    #make coord\n",
    "    xx = np.linspace(half, width  - half, int(np.ceil((width  - size) / step)))\n",
    "    yy = np.linspace(half, height - half, int(np.ceil((height - size) / step)))\n",
    "    xx = [int(x) for x in xx]\n",
    "    yy = [int(y) for y in yy]\n",
    "\n",
    "    coord  = []\n",
    "    reject = []\n",
    "    for cy in yy:\n",
    "        for cx in xx:\n",
    "            cv = vv[cy - half:cy + half, cx - half:cx + half].mean() # h, w // tiling한 마스크(structure)가 평균 0.25를 안넘으면 버린다.\n",
    "            if cv>min_score: # min_score ,default:0.25, 0.25의 의미?, 타일링 이미지의 1/4는 object여야 한다는 의미?\n",
    "                coord.append([cx,cy,cv])\n",
    "            else:\n",
    "                reject.append([cx,cy,cv])\n",
    "    #-----\n",
    "    if 1: # resize한 image를 tiling 하여 리스트만든다\n",
    "        tile_image = []\n",
    "        for cx,cy,cv in coord:\n",
    "            t = image_small[cy - half:cy + half, cx - half:cx + half] # resize한 image에서 indexing만 하는과정\n",
    "            assert (t.shape == (size, size, 3))\n",
    "            tile_image.append(t)\n",
    "\n",
    "    if mask is not None: # mask를 resize하고 tiling하여 리스트 만든다\n",
    "        mask_small = cv2.resize(mask, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        tile_mask = []\n",
    "        for cx,cy,cv in coord:\n",
    "            t = mask_small[cy - half:cy + half, cx - half:cx + half]\n",
    "            assert (t.shape == (size, size))\n",
    "            tile_mask.append(t)\n",
    "    else:\n",
    "        mask_small = None\n",
    "        tile_mask  = None\n",
    "\n",
    "    return {\n",
    "        'image_small': image_small,\n",
    "        'mask_small' : mask_small,\n",
    "        'structure_small' : structure_small,\n",
    "        'tile_image' : tile_image,\n",
    "        'tile_mask'  : tile_mask,\n",
    "        'coord'  : coord,\n",
    "        'reject' : reject,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "submission할때 쓰임\n",
    "\"\"\"\n",
    "def to_mask(tile, coord, height, width, scale, size, step, min_score, aggregate='mean'):\n",
    "\n",
    "    half = size//2\n",
    "    mask  = np.zeros((height, width), np.float32)\n",
    "\n",
    "    if 'mean' in aggregate:\n",
    "        w = np.ones((size,size), np.float32)\n",
    "\n",
    "        #if 'sq' in aggregate:\n",
    "        if 1:\n",
    "            #https://stackoverflow.com/questions/17190649/how-to-obtain-a-gaussian-filter-in-python\n",
    "            y,x = np.mgrid[-half:half,-half:half]\n",
    "            y = half-abs(y)\n",
    "            x = half-abs(x)\n",
    "            w = np.minimum(x,y)\n",
    "            w = w/w.max()#*2.5\n",
    "            w = np.minimum(w,1)\n",
    "\n",
    "        #--------------\n",
    "        count = np.zeros((height, width), np.float32)\n",
    "        for t, (cx, cy, cv) in enumerate(coord):\n",
    "            mask [cy - half:cy + half, cx - half:cx + half] += tile[t]*w\n",
    "            count[cy - half:cy + half, cx - half:cx + half] += w\n",
    "               # see unet paper for \"Overlap-tile strategy for seamless segmentation of arbitrary large images\"\n",
    "        m = (count != 0)\n",
    "        mask[m] /= count[m]\n",
    "\n",
    "    if aggregate=='max':\n",
    "        for t, (cx, cy, cv) in enumerate(coord):\n",
    "            mask[cy - half:cy + half, cx - half:cx + half] = np.maximum(\n",
    "                mask[cy - half:cy + half, cx - half:cx + half], tile[t] )\n",
    "\n",
    "    return mask\n",
    "\n",
    "# --------------이 아래로 안씀 ------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# --draw ------------------------------------------\n",
    "\"\"\"\n",
    "경계선을 그리게 만든다, 컨투어\n",
    "하지만 안씀\n",
    "\"\"\"\n",
    "def mask_to_inner_contour(mask):\n",
    "    mask = mask>0.5\n",
    "    pad = np.lib.pad(mask, ((1, 1), (1, 1)), 'reflect')\n",
    "    contour = mask & (\n",
    "            (pad[1:-1,1:-1] != pad[:-2,1:-1]) \\\n",
    "          | (pad[1:-1,1:-1] != pad[2:,1:-1])  \\\n",
    "          | (pad[1:-1,1:-1] != pad[1:-1,:-2]) \\\n",
    "          | (pad[1:-1,1:-1] != pad[1:-1,2:])\n",
    "    )\n",
    "    return contour\n",
    "\n",
    "\n",
    "def draw_contour_overlay(image, mask, color=(0,0,255), thickness=1):\n",
    "    contour =  mask_to_inner_contour(mask)\n",
    "    if thickness==1:\n",
    "        image[contour] = color\n",
    "    else:\n",
    "        r = max(1,thickness//2)\n",
    "        for y,x in np.stack(np.where(contour)).T:\n",
    "            cv2.circle(image, (x,y), r, color, lineType=cv2.LINE_4 )\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-external",
   "metadata": {},
   "source": [
    "# make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intense-metro",
   "metadata": {
    "code_folding": [
     15,
     137,
     227,
     291
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------ make dataset  new version image fold--------- #\n",
    "#################################\n",
    "\"\"\"\n",
    "- robust validation을 위해 overlap 없는 데이터도 만든다\n",
    "\"\"\"\n",
    "# <todo> make difference scale tile\n",
    "\n",
    "tile_scale = 0.5\n",
    "tile_min_score = 0.25\n",
    "tile_size = 640#320  # 480 #\n",
    "tile_average_step = 320#160 #240  # 160 #192\n",
    "tile_average_step2 = tile_size\n",
    "\n",
    "#make tile train image\n",
    "# train,tiling (image,mask) png 저장용도\n",
    "def run_make_train_tile():\n",
    "\n",
    "    train_tile_dir = data_dir + f'/tile/{tile_scale}_{tile_size}_{tile_average_step}_train_fold' #nipa2\n",
    "\n",
    "    df_train = pd.read_csv(data_dir + '/train.csv')\n",
    "    print(df_train)\n",
    "    print(df_train.shape)\n",
    "    \n",
    "    df_all = []\n",
    "    \n",
    "    os.makedirs(train_tile_dir, exist_ok=True)\n",
    "    for i in range(0,len(df_train)):\n",
    "        id, encoding = df_train.iloc[i]\n",
    "        # 1. image 불러오고\n",
    "        image_file = data_dir + '/train/%s.tiff' % id\n",
    "        image = read_tiff(image_file)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        #mask = rle_decode(encoding, height, width, 255)\n",
    "        # 2. mask, target 불러오고\n",
    "        mask_file = data_dir + '/train/%s.mask.png' % id\n",
    "        mask = read_mask(mask_file)\n",
    "        \n",
    "        # 3. 일정영역,object만 표시한 mask불러오기.\n",
    "        structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)\n",
    "        print(id, mask_file)\n",
    "        \n",
    "        # make tile\n",
    "        # 4. 학습할 tile image, mask를 생성한다.\n",
    "        tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "\n",
    "        coord = np.array(tile['coord'])\n",
    "        df_image = pd.DataFrame()\n",
    "        df_image['cx']=coord[:,0].astype(np.int32)\n",
    "        df_image['cy']=coord[:,1].astype(np.int32)\n",
    "        df_image['cv']=coord[:,2]\n",
    "\n",
    "        # --- save ---\n",
    "        os.makedirs(train_tile_dir+'/%s'%id, exist_ok=True)\n",
    "\n",
    "        tile_id =[]\n",
    "        num = len(tile['tile_image'])\n",
    "        for t in range(num):\n",
    "            cx,cy,cv   = tile['coord'][t]\n",
    "            #s = '%s_y%08d_x%08d' % (id, cy, cx)\n",
    "            s = 'y%08d_x%08d' %(cy, cx)\n",
    "            tile_id.append(s)\n",
    "\n",
    "            tile_image = tile['tile_image'][t]\n",
    "            tile_mask  = tile['tile_mask'][t]\n",
    "            cv2.imwrite(train_tile_dir + '/%s/%s.png' %(id, s), tile_image)\n",
    "            cv2.imwrite(train_tile_dir + '/%s/%s.mask.png' %(id, s), tile_mask)\n",
    "\n",
    "\n",
    "        df_image['tile_id']= [f'{train_tile_dir}/{id}/'+ x for x in tile_id]\n",
    "        df_all.append(df_image)\n",
    "    df_all = pd.concat(df_all, 0).reset_index(drop=True)\n",
    "    df_all[['tile_id','cx','cy','cv']].to_csv(train_tile_dir+'/image_id.csv', index=False)\n",
    "#------\n",
    "# maek tile val image\n",
    "def run_make_val_tile():\n",
    "\n",
    "    train_tile_dir = data_dir + f'/tile/{tile_scale}_{tile_size}_{tile_average_step2}_val_fold' #nipa2\n",
    "\n",
    "    df_train = pd.read_csv(data_dir + '/train.csv')\n",
    "    print(df_train)\n",
    "    print(df_train.shape)\n",
    "    \n",
    "    df_all = []\n",
    "    \n",
    "    os.makedirs(train_tile_dir, exist_ok=True)\n",
    "    for i in range(0,len(df_train)):\n",
    "        id, encoding = df_train.iloc[i]\n",
    "        # 1. image 불러오고\n",
    "        image_file = data_dir + '/train/%s.tiff' % id\n",
    "        image = read_tiff(image_file)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        #mask = rle_decode(encoding, height, width, 255)\n",
    "        # 2. mask, target 불러오고\n",
    "        mask_file = data_dir + '/train/%s.mask.png' % id\n",
    "        mask = read_mask(mask_file)\n",
    "        \n",
    "        # 3. 일정영역,object만 표시한 mask불러오기.\n",
    "        structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)\n",
    "        print(id, mask_file)\n",
    "        \n",
    "        # make tile\n",
    "        # 4. 학습할 tile image, mask를 생성한다.\n",
    "        tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step2, tile_min_score)\n",
    "\n",
    "        coord = np.array(tile['coord'])\n",
    "        df_image = pd.DataFrame()\n",
    "        df_image['cx']=coord[:,0].astype(np.int32)\n",
    "        df_image['cy']=coord[:,1].astype(np.int32)\n",
    "        df_image['cv']=coord[:,2]\n",
    "\n",
    "        # --- save ---\n",
    "        os.makedirs(train_tile_dir+'/%s'%id, exist_ok=True)\n",
    "\n",
    "        tile_id =[]\n",
    "        num = len(tile['tile_image'])\n",
    "        for t in range(num):\n",
    "            cx,cy,cv   = tile['coord'][t]\n",
    "            #s = '%s_y%08d_x%08d' % (id, cy, cx)\n",
    "            s = 'y%08d_x%08d' %(cy, cx)\n",
    "            tile_id.append(s)\n",
    "\n",
    "            tile_image = tile['tile_image'][t]\n",
    "            tile_mask  = tile['tile_mask'][t]\n",
    "            cv2.imwrite(train_tile_dir + '/%s/%s.png' %(id, s), tile_image)\n",
    "            cv2.imwrite(train_tile_dir + '/%s/%s.mask.png' %(id, s), tile_mask)\n",
    "\n",
    "\n",
    "        df_image['tile_id']= [f'{train_tile_dir}/{id}/'+ x for x in tile_id]\n",
    "        df_all.append(df_image)\n",
    "    df_all = pd.concat(df_all, 0).reset_index(drop=True)\n",
    "    df_all[['tile_id','cx','cy','cv']].to_csv(train_tile_dir+'/image_id.csv', index=False)\n",
    "\n",
    "    \n",
    "#make tile train image\n",
    "# test tiling image png 저장용도\n",
    "def run_make_test_tile():\n",
    "    #tile_scale = 0.25\n",
    "    #tile_min_score = 0.25\n",
    "    #tile_size = 480#320  # 480 #\n",
    "    #tile_average_step = 240#160 #240  # 160 #192\n",
    "\n",
    "    #test_tile_dir = '/home/ubuntu/gwang/hubmap/etc/tile/0.25_640_320_test'\n",
    "    test_tile_dir = data_dir + f'/tile/{tile_scale}_{tile_size}_{tile_average_step}_test'\n",
    "    #---\n",
    "\n",
    "\n",
    "    os.makedirs(test_tile_dir, exist_ok=True)\n",
    "    assert False, 'todo modify test file'\n",
    "    for id in ['c68fe75ea','afa5e8098',]:\n",
    "        print(id)\n",
    "\n",
    "        # 1. test image load\n",
    "        image_file = data_dir + '/test/%s.tiff' % id\n",
    "        json_file  = data_dir + '/test/%s-anatomical-structure.json' % id\n",
    "\n",
    "        image = read_tiff(image_file)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        mask = None\n",
    "        # 2. test structure load\n",
    "        structure = draw_strcuture(read_json_as_df(json_file), height, width, structure=['Cortex'])\n",
    "        # structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)\n",
    "\n",
    "        # 3. test를 위한 tile image 생성\n",
    "        #make tile\n",
    "        tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "\n",
    "        coord = np.array(tile['coord'])\n",
    "        df_image = pd.DataFrame()\n",
    "        df_image['cx']=coord[:,0].astype(np.int32)\n",
    "        df_image['cy']=coord[:,1].astype(np.int32)\n",
    "        df_image['cv']=coord[:,2]\n",
    "\n",
    "        # --- save ---\n",
    "        os.makedirs(test_tile_dir+'/%s'%id, exist_ok=True)\n",
    "\n",
    "        tile_id =[]\n",
    "        num = len(tile['tile_image'])\n",
    "        for t in range(num):\n",
    "            cx,cy,cv   = tile['coord'][t]\n",
    "            s = 'y%08d_x%08d' % (cy, cx)\n",
    "            tile_id.append(s)\n",
    "\n",
    "            tile_image = tile['tile_image'][t]\n",
    "            cv2.imwrite(test_tile_dir + '/%s/%s.png' % (id, s), tile_image)\n",
    "            #image_show('tile_image', tile_image)\n",
    "            #cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        df_image['tile_id']=tile_id\n",
    "        df_image[['tile_id','cx','cy','cv']].to_csv(test_tile_dir+'/%s.csv'%id, index=False)\n",
    "        #------\n",
    "\n",
    "\n",
    "#make tile train image\n",
    "# tile이 아닌 train image의 mask생성\n",
    "def run_make_train_mask():\n",
    "\n",
    "    df_train = pd.read_csv(data_dir + '/train.csv')\n",
    "    print(df_train)\n",
    "    print(df_train.shape)\n",
    "\n",
    "    for i in range(0,len(df_train)):\n",
    "        id, encoding = df_train.iloc[i]\n",
    "\n",
    "        image_file = data_dir + '/train/%s.tiff' % id\n",
    "        image = read_tiff(image_file)\n",
    "\n",
    "        if image.shape[0]==1:\n",
    "            image = image[0][0]\n",
    "            image = image.transpose(1, 2, 0)\n",
    "            image = np.ascontiguousarray(image)\n",
    "            height, width = image.shape[:2]\n",
    "        elif image.shape[0] == 3:\n",
    "            image = image.transpose(1, 2, 0)\n",
    "            image = np.ascontiguousarray(image)\n",
    "            height, width = image.shape[:2]\n",
    "        else:\n",
    "            height, width = image.shape[:2]\n",
    "        mask = rle_decode(encoding, height, width, 255)\n",
    "\n",
    "        cv2.imwrite(data_dir + '/train/%s.mask.png' % id, mask)\n",
    "\n",
    "\n",
    "#make tile train image\n",
    "def run_make_pseudo_tile():\n",
    "\n",
    "    \n",
    "    tile_scale = 0.25\n",
    "    tile_min_score = 0.25\n",
    "    tile_size = 480#320  #480 #\n",
    "    tile_average_step = 240 #160 #240  # 192\n",
    "    #---\n",
    "    pseudo_tile_dir = data_dir + f'/tile/{tile_scale}_{tile_size}_{tile_average_step}_pseudo_0.95'\n",
    "    #df_train = pd.read_csv(data_dir + '/train.csv')\n",
    "    #df_pseudo = pd.read_csv('/root/share1/kaggle/2020/hubmap/result/resnet34/fold2/submit-fold-2-resnet34-00010000_model_lb0.837.csv')\n",
    "    df_pseudo = pd.read_csv('../../submission/0.891_submission-fold6-00004000_model_thres-0.9.csv')\n",
    "    \n",
    "    print(df_pseudo)\n",
    "    print(df_pseudo.shape)\n",
    "\n",
    "    os.makedirs(pseudo_tile_dir, exist_ok=True)\n",
    "    for i in range(0,len(df_pseudo)):\n",
    "        id, encoding = df_pseudo.iloc[i]\n",
    "\n",
    "        image_file = data_dir + '/test/%s.tiff' % id\n",
    "        image = read_tiff(image_file)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        mask = rle_decode(encoding, height, width, 255)\n",
    "\n",
    "        #make tile\n",
    "        structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)\n",
    "\n",
    "        tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "        #to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "\n",
    "        #mask, scale, size, step, min_score\n",
    "\n",
    "        coord = np.array(tile['coord'])\n",
    "        df_image = pd.DataFrame()\n",
    "        df_image['cx']=coord[:,0].astype(np.int32)\n",
    "        df_image['cy']=coord[:,1].astype(np.int32)\n",
    "        df_image['cv']=coord[:,2]\n",
    "\n",
    "        # --- save ---\n",
    "        os.makedirs(pseudo_tile_dir + '/%s'%id, exist_ok=True)\n",
    "\n",
    "        tile_id =[]\n",
    "        num = len(tile['tile_image'])\n",
    "        for t in range(num):\n",
    "            cx,cy,cv   = tile['coord'][t]\n",
    "            s = 'y%08d_x%08d' % (cy, cx)\n",
    "            tile_id.append(s)\n",
    "\n",
    "            tile_image = tile['tile_image'][t]\n",
    "            tile_mask  = tile['tile_mask'][t]\n",
    "            cv2.imwrite(pseudo_tile_dir + '/%s/%s.png' % (id, s), tile_image)\n",
    "            cv2.imwrite(pseudo_tile_dir + '/%s/%s.mask.png' % (id, s), tile_mask)\n",
    "\n",
    "            #image_show('tile_image', tile_image)\n",
    "            #image_show('tile_mask', tile_mask)\n",
    "            #cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        df_image['tile_id']=tile_id\n",
    "        df_image[['tile_id','cx','cy','cv']].to_csv(pseudo_tile_dir+'/%s.csv'%id, index=False)\n",
    "        #------\n",
    "\n",
    "def split_fold():\n",
    "    \n",
    "    df = pd.read_csv(f'{data_dir}/tile/{tile_scale}_{tile_size}_{tile_average_step}_train_fold/image_id.csv')\n",
    "    df2 = pd.read_csv(f'{data_dir}/tile/{tile_scale}_{tile_size}_{tile_average_step2}_val_fold/image_id.csv')\n",
    "\n",
    "    a = {0 : '0486052bb', 1 : '095bf7a1f', 2 : '1e2425f28', 3 : '26dc41664',\n",
    "        4 : '2f6ecfcdf', 5 : '4ef6695ce', 6 : '54f2eec69', 7 : '8242609fa',\n",
    "        8 : 'aaa6a05cc', 9 : 'afa5e8098', 10 :'b2dc8411c', 11: 'b9a3865fc',\n",
    "        12 :'c68fe75ea', 13: 'cb2d976f4', 14 :'e79de561c'}\n",
    "    #\n",
    "    kf = KFold(n_splits=args.n_fold, random_state=args.seed, shuffle=True)\n",
    "    fold_dict={}\n",
    "    for n, (t,v) in enumerate(kf.split(a)):\n",
    "        for f in v:\n",
    "            fold_dict[a[f]] = n\n",
    "\n",
    "    df['fold'] = df['tile_id'].apply(lambda x : x.split('/')[-2])\n",
    "    df['fold'] = df['fold'].apply(lambda x :fold_dict[x])\n",
    "    \n",
    "    df2['fold'] = df2['tile_id'].apply(lambda x : x.split('/')[-2])\n",
    "    df2['fold'] = df2['fold'].apply(lambda x :fold_dict[x])\n",
    "    \n",
    "    df.to_csv(f'{data_dir}/tile/{tile_scale}_{tile_size}_{tile_average_step}_train_fold/image_id_split.csv', index=False)\n",
    "    df2.to_csv(f'{data_dir}/tile/{tile_scale}_{tile_size}_{tile_average_step2}_val_fold/image_id_split.csv', index=False)\n",
    "    print('saved split fold')\n",
    "    \n",
    "# main #################################################################\n",
    "if 0:\n",
    "    if __name__ == '__main__':\n",
    "        #print('started run make train mask')\n",
    "        # 1.\n",
    "        print('started 1')\n",
    "        run_make_train_mask()\n",
    "        # 2.\n",
    "        print('started 2')\n",
    "        run_make_train_tile()\n",
    "        # 3.\n",
    "        print('started 3')\n",
    "        run_make_val_tile()\n",
    "        \n",
    "        #print('started 3')\n",
    "        #run_make_test_tile()\n",
    "        # 4. if use pseudo datasets\n",
    "        #run_make_pseudo_tile()\n",
    "        \n",
    "        print('split kfold csv')\n",
    "        split_fold()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-thing",
   "metadata": {},
   "source": [
    "# Dataset & augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hired-updating",
   "metadata": {
    "code_folding": [
     0,
     6,
     44,
     92,
     130,
     131,
     242
    ]
   },
   "outputs": [],
   "source": [
    "#--------------- Dataset ----------------#\n",
    "##########################################\n",
    "\n",
    "#--------------- \n",
    "# Old version\n",
    "#--------------- \n",
    "def make_image_id_v1(mode):\n",
    "    train_image_id = {\n",
    "        0 : '0486052bb', 1 : '095bf7a1f',\n",
    "        2 : '1e2425f28', 3 : '26dc41664',\n",
    "        4 : '2f6ecfcdf', 5 : '4ef6695ce',\n",
    "        6 : '54f2eec69', 7 : '8242609fa',\n",
    "        8 : 'aaa6a05cc', 9 : 'afa5e8098', \n",
    "        10 :'b2dc8411c', 11: 'b9a3865fc',\n",
    "        12 :'c68fe75ea', 13: 'cb2d976f4',\n",
    "        14 :'e79de561c'\n",
    "    }\n",
    "\n",
    "    test_image_id = {\n",
    "        0 : '2ec3f1bb9', 1 : '3589adb90',\n",
    "        2 : '57512b7f1', 3 : 'aa05346ff',\n",
    "        4 : 'd488c759a',\n",
    "    }\n",
    "    if 'pseudo-all'==mode:\n",
    "        test_id = [ test_image_id[i] for i in [0,1,2,3,4] ]\n",
    "        return test_id\n",
    "\n",
    "    if 'test-all'==mode:\n",
    "        test_id = [ test_image_id[i] for i in [0,1,2,3,4] ] # list(test_image_id.values()) #\n",
    "        return test_id\n",
    "\n",
    "    if 'train-all'==mode:\n",
    "        train_id = [ train_image_id[i] for i in [x for x in train_image_id] ] # list(test_image_id.values()) #\n",
    "        return train_id\n",
    "\n",
    "    if 'valid' in mode or 'train' in mode:\n",
    "        fold = {int(x) for x in mode.split('-')[1].split(',')}\n",
    "        #valid = [fold,]\n",
    "        train = list({x for x in train_image_id}-fold)\n",
    "        valid_id = [ train_image_id[i] for i in fold ]\n",
    "        train_id = [ train_image_id[i] for i in train ]\n",
    "\n",
    "        if 'valid' in mode: return valid_id\n",
    "        if 'train' in mode: return train_id\n",
    "class HuDataset_v1(Dataset):\n",
    "    def __init__(self, image_id, image_dir, augment=None):\n",
    "        self.augment = augment\n",
    "        self.image_id = image_id\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        tile_id = []\n",
    "        for i in range(len(image_dir)):\n",
    "            for id in image_id[i]: \n",
    "                df = pd.read_csv(data_dir + '/tile/%s/%s.csv'% (self.image_dir[i],id) )\n",
    "                tile_id += ('%s/%s/'%(self.image_dir[i],id) + df.tile_id).tolist()\n",
    "\n",
    "        self.tile_id = tile_id\n",
    "        self.len =len(self.tile_id)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __str__(self):\n",
    "        string  = ''\n",
    "        string += '\\tlen  = %d\\n'%len(self)\n",
    "        string += '\\timage_dir = %s\\n'%self.image_dir\n",
    "        string += '\\timage_id  = %s\\n'%str(self.image_id)\n",
    "        string += '\\t          = %d\\n'%sum(len(i) for i in self.image_id)\n",
    "        return string\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.tile_id[index]\n",
    "        image = cv2.imread(data_dir + '/tile/%s.png'%(id), cv2.IMREAD_COLOR)\n",
    "        mask  = cv2.imread(data_dir + '/tile/%s.mask.png'%(id), cv2.IMREAD_GRAYSCALE)\n",
    "        #print(data_dir + '/tile/%s/%s.png'%(self.image_dir,id))\n",
    "\n",
    "        image = image.astype(np.float32) / 255\n",
    "        mask  = mask.astype(np.float32) / 255\n",
    "        r = {\n",
    "            'index' : index,\n",
    "            'tile_id' : id,\n",
    "            'mask' : mask,\n",
    "            'image' : image,\n",
    "        }\n",
    "        if self.augment is not None: r = self.augment(r)\n",
    "        return r\n",
    "\n",
    "#--------------- \n",
    "# Old version (simple fold)\n",
    "#--------------- \n",
    "def make_image_id_(mode):\n",
    "    train_image_id = {\n",
    "        0 : '0486052bb', 1 : '095bf7a1f',\n",
    "        2 : '1e2425f28', 3 : '26dc41664',\n",
    "        4 : '2f6ecfcdf', 5 : '4ef6695ce',\n",
    "        6 : '54f2eec69', 7 : '8242609fa',\n",
    "        8 : 'aaa6a05cc', 9 : 'afa5e8098', \n",
    "        10 :'b2dc8411c', 11: 'b9a3865fc',\n",
    "        12 :'c68fe75ea', 13: 'cb2d976f4',\n",
    "        14 :'e79de561c'\n",
    "    }\n",
    "\n",
    "    test_image_id = {\n",
    "        0 : '2ec3f1bb9', 1 : '3589adb90',\n",
    "        2 : '57512b7f1', 3 : 'aa05346ff',\n",
    "        4 : 'd488c759a',\n",
    "    }\n",
    "    if 'pseudo-all'==mode:\n",
    "        test_id = [ test_image_id[i] for i in [0,1,2,3,4] ]\n",
    "        return test_id\n",
    "\n",
    "    if 'test-all'==mode:\n",
    "        test_id = [ test_image_id[i] for i in [0,1,2,3,4] ] # list(test_image_id.values()) #\n",
    "        return test_id\n",
    "\n",
    "    if 'train-all'==mode:\n",
    "        train_id = [ train_image_id[i] for i in [x for x in train_image_id] ] # list(test_image_id.values()) #\n",
    "        return train_id\n",
    "\n",
    "    if 'valid' in mode or 'train' in mode:\n",
    "        fold = {int(x) for x in mode.split('-')[1].split(',')}\n",
    "        #valid = [fold,]\n",
    "        train = list({x for x in train_image_id}-fold)\n",
    "        valid_id = [ train_image_id[i] for i in fold ]\n",
    "        train_id = [ train_image_id[i] for i in train ]\n",
    "\n",
    "        if 'valid' in mode: return valid_id\n",
    "        if 'train' in mode: return train_id\n",
    "class HuDataset_(Dataset):\n",
    "    def __init__(self, tile_id, augment=None):\n",
    "        self.augment = augment\n",
    "\n",
    "        self.tile_id = tile_id\n",
    "        self.len =len(self.tile_id)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __str__(self):\n",
    "        string  = ''\n",
    "        string += '\\tlen  = %d\\n'%len(self)\n",
    "        return string\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.tile_id[index]\n",
    "        image = cv2.imread(f'{data_dir}/tile/{args.dataset}/{id}.png', cv2.IMREAD_COLOR)\n",
    "        mask  = cv2.imread(f'{data_dir}/tile/{args.dataset}/{id}.mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "        #print(data_dir + '/tile/%s/%s.png'%(self.image_dir,id))\n",
    "\n",
    "        image = image.astype(np.float32) / 255\n",
    "        mask  = mask.astype(np.float32) / 255\n",
    "        r = {\n",
    "            'index' : index,\n",
    "            'tile_id' : id,\n",
    "            'mask' : mask,\n",
    "            'image' : image,\n",
    "        }\n",
    "        if self.augment is not None: r = self.augment()\n",
    "        \n",
    "        return r\n",
    "\n",
    "#--------------- \n",
    "# New version(image fold)\n",
    "#--------------- \n",
    "def make_image_id(mode):\n",
    "    train_image_id = {\n",
    "        0 : '0486052bb', 1 : '095bf7a1f',\n",
    "        2 : '1e2425f28', 3 : '26dc41664',\n",
    "        4 : '2f6ecfcdf', 5 : '4ef6695ce',\n",
    "        6 : '54f2eec69', 7 : '8242609fa',\n",
    "        8 : 'aaa6a05cc', 9 : 'afa5e8098', \n",
    "        10 :'b2dc8411c', 11: 'b9a3865fc',\n",
    "        12 :'c68fe75ea', 13: 'cb2d976f4',\n",
    "        14 :'e79de561c'\n",
    "    }\n",
    "\n",
    "    test_image_id = {\n",
    "        0 : '2ec3f1bb9', 1 : '3589adb90',\n",
    "        2 : '57512b7f1', 3 : 'aa05346ff',\n",
    "        4 : 'd488c759a',\n",
    "    }\n",
    "    if 'pseudo-all'==mode:\n",
    "        test_id = [ test_image_id[i] for i in [0,1,2,3,4] ]\n",
    "        return test_id\n",
    "\n",
    "    if 'test-all'==mode:\n",
    "        test_id = [ test_image_id[i] for i in [0,1,2,3,4] ] # list(test_image_id.values()) #\n",
    "        return test_id\n",
    "\n",
    "    if 'train-all'==mode:\n",
    "        train_id = [ train_image_id[i] for i in [x for x in train_image_id] ] # list(test_image_id.values()) #\n",
    "        return train_id\n",
    "\n",
    "    if 'valid' in mode or 'train' in mode:\n",
    "        fold = {int(x) for x in mode.split('-')[1].split(',')}\n",
    "        #valid = [fold,]\n",
    "        train = list({x for x in train_image_id}-fold)\n",
    "        valid_id = [ train_image_id[i] for i in fold ]\n",
    "        train_id = [ train_image_id[i] for i in train ]\n",
    "\n",
    "        if 'valid' in mode: return valid_id\n",
    "        if 'train' in mode: return train_id\n",
    "class HuDataset(Dataset):\n",
    "    def __init__(self, df, augment=None):\n",
    "        self.augment = augment\n",
    "\n",
    "        #self.tile_id = tile_id\n",
    "        #self.len =len(self.tile_id)\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __str__(self):\n",
    "        string  = ''\n",
    "        string += '\\tlen  = %d\\n'%len(self)\n",
    "        return string\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.df['tile_id'].loc[index]\n",
    "        image = cv2.imread(f'{id}.png', cv2.IMREAD_COLOR)\n",
    "        mask  = cv2.imread(f'{id}.mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "        #print(data_dir + '/tile/%s/%s.png'%(self.image_dir,id))\n",
    "\n",
    "        image = image.astype(np.float32) / 255\n",
    "        mask  = mask.astype(np.float32) / 255\n",
    "        r = {\n",
    "            'index' : index,\n",
    "            'tile_id' : id,\n",
    "            'mask' : mask,\n",
    "            'image' : image,\n",
    "        }\n",
    "        if self.augment is not None: r = self.augment(r)\n",
    "        #if self.augment is not None: r = self.augment(image=r['image'], mask=r['mask'])\n",
    "        return r\n",
    "\n",
    "def null_collate(batch):\n",
    "    batch_size = len(batch)\n",
    "    index = []\n",
    "    mask = []\n",
    "    image = []\n",
    "    for r in batch:\n",
    "        index.append(r['index'])\n",
    "        mask.append(r['mask'])\n",
    "        image.append(r['image'])\n",
    "\n",
    "    image = np.stack(image)\n",
    "    image = image[...,::-1]\n",
    "    image = image.transpose(0,3,1,2)\n",
    "    image = np.ascontiguousarray(image)\n",
    "\n",
    "    mask  = np.stack(mask)\n",
    "    mask  = np.ascontiguousarray(mask)\n",
    "\n",
    "    #---\n",
    "    image = torch.from_numpy(image).contiguous().float()\n",
    "    mask  = torch.from_numpy(mask).contiguous().unsqueeze(1)\n",
    "    mask  = (mask>0.5).float()\n",
    "\n",
    "    return {\n",
    "        'index' : index,\n",
    "        'mask' : mask,\n",
    "        'image' : image,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "narrow-schema",
   "metadata": {
    "code_folding": [
     0,
     3,
     19,
     27,
     42,
     82,
     91,
     97,
     103,
     122
    ]
   },
   "outputs": [],
   "source": [
    "#---------- augmentation ---------------------#\n",
    "###############################################\n",
    "#flip\n",
    "def do_random_flip_transpose(image, mask):\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,0)\n",
    "        mask = cv2.flip(mask,0)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = cv2.flip(image,1)\n",
    "        mask = cv2.flip(mask,1)\n",
    "    if np.random.rand()>0.5:\n",
    "        image = image.transpose(1,0,2)\n",
    "        mask = mask.transpose(1,0)\n",
    "\n",
    "    image = np.ascontiguousarray(image)\n",
    "    mask = np.ascontiguousarray(mask)\n",
    "    return image, mask\n",
    "\n",
    "#geometric\n",
    "def do_random_crop(image, mask, size):\n",
    "    height, width = image.shape[:2]\n",
    "    x = np.random.choice(width -size)\n",
    "    y = np.random.choice(height-size)\n",
    "    image = image[y:y+size,x:x+size]\n",
    "    mask  = mask[y:y+size,x:x+size]\n",
    "    return image, mask\n",
    "\n",
    "def do_random_scale_crop(image, mask, size, mag):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    s = 1 + np.random.uniform(-1, 1)*mag\n",
    "    s =  int(s*size)\n",
    "\n",
    "    x = np.random.choice(width -s)\n",
    "    y = np.random.choice(height-s)\n",
    "    image = image[y:y+s,x:x+s]\n",
    "    mask  = mask[y:y+s,x:x+s]\n",
    "    if s!=size:\n",
    "        image = cv2.resize(image, dsize=(size,size), interpolation=cv2.INTER_LINEAR)\n",
    "        mask  = cv2.resize(mask, dsize=(size,size), interpolation=cv2.INTER_LINEAR)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_rotate_crop(image, mask, size, mag=30 ):\n",
    "    angle = 1+np.random.uniform(-1, 1)*mag\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    dst = np.array([\n",
    "        [0,0],[size,size], [size,0], [0,size],\n",
    "    ])\n",
    "\n",
    "    c = np.cos(angle/180*2*PI)\n",
    "    s = np.sin(angle/180*2*PI)\n",
    "    src = (dst-size//2)@np.array([[c, -s],[s, c]]).T\n",
    "    src[:,0] -= src[:,0].min()\n",
    "    src[:,1] -= src[:,1].min()\n",
    "\n",
    "    src[:,0] = src[:,0] + np.random.uniform(0,width -src[:,0].max())\n",
    "    src[:,1] = src[:,1] + np.random.uniform(0,height-src[:,1].max())\n",
    "\n",
    "    if 0: #debug\n",
    "        def to_int(f):\n",
    "            return (int(f[0]),int(f[1]))\n",
    "\n",
    "        cv2.line(image, to_int(src[0]), to_int(src[1]), (0,0,1), 16)\n",
    "        cv2.line(image, to_int(src[1]), to_int(src[2]), (0,0,1), 16)\n",
    "        cv2.line(image, to_int(src[2]), to_int(src[3]), (0,0,1), 16)\n",
    "        cv2.line(image, to_int(src[3]), to_int(src[0]), (0,0,1), 16)\n",
    "        image_show_norm('image', image, min=0, max=1)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "    transform = cv2.getAffineTransform(src[:3].astype(np.float32), dst[:3].astype(np.float32))\n",
    "    image = cv2.warpAffine( image, transform, (size, size), flags=cv2.INTER_LINEAR,\n",
    "                                 borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "    mask  = cv2.warpAffine( mask, transform, (size, size), flags=cv2.INTER_LINEAR,\n",
    "                                 borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "    return image, mask\n",
    "\n",
    "#warp/elastic deform ...\n",
    "#<todo>\n",
    "\n",
    "#noise\n",
    "def do_random_noise(image, mask, mag=0.1):\n",
    "    height, width = image.shape[:2]\n",
    "    noise = np.random.uniform(-1,1, (height, width,1))*mag\n",
    "    image = image + noise\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "#intensity\n",
    "def do_random_contast(image, mask, mag=0.3):\n",
    "    alpha = 1 + random.uniform(-1,1)*mag\n",
    "    image = image * alpha\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_gain(image, mask, mag=0.3):\n",
    "    alpha = 1 + random.uniform(-1,1)*mag\n",
    "    image = image ** alpha\n",
    "    image = np.clip(image,0,1)\n",
    "    return image, mask\n",
    "\n",
    "def do_random_hsv(image, mask, mag=[0.15,0.25,0.25]):\n",
    "    image = (image*255).astype(np.uint8)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h = hsv[:, :, 0].astype(np.float32)  # hue\n",
    "    s = hsv[:, :, 1].astype(np.float32)  # saturation\n",
    "    v = hsv[:, :, 2].astype(np.float32)  # value\n",
    "    h = (h*(1 + random.uniform(-1,1)*mag[0]))%180\n",
    "    s =  s*(1 + random.uniform(-1,1)*mag[1])\n",
    "    v =  v*(1 + random.uniform(-1,1)*mag[2])\n",
    "\n",
    "    hsv[:, :, 0] = np.clip(h,0,180).astype(np.uint8)\n",
    "    hsv[:, :, 1] = np.clip(s,0,255).astype(np.uint8)\n",
    "    hsv[:, :, 2] = np.clip(v,0,255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    image = image.astype(np.float32)/255\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def filter_small(mask, min_size):\n",
    "\n",
    "    m = (mask*255).astype(np.uint8)\n",
    "\n",
    "    num_comp, comp, stat, centroid = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "    if num_comp==1: return mask\n",
    "\n",
    "    filtered = np.zeros(comp.shape,dtype=np.uint8)\n",
    "    area = stat[:, -1]\n",
    "    for i in range(1, num_comp):\n",
    "        if area[i] >= min_size:\n",
    "            filtered[comp == i] = 255\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vertical-commander",
   "metadata": {
    "code_folding": [
     0,
     2,
     41,
     117
    ]
   },
   "outputs": [],
   "source": [
    "#---------- optimizer, scheduler ---------------------#\n",
    "############################################\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, optimizer, alpha=0.5, k=6):\n",
    "\n",
    "        if not 0.0 <= alpha <= 1.0:\n",
    "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
    "        if not 1 <= k:\n",
    "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        for group in self.param_groups:\n",
    "            group[\"step_counter\"] = 0\n",
    "\n",
    "        self.slow_weights = [\n",
    "                [p.clone().detach() for p in group['params']]\n",
    "            for group in self.param_groups]\n",
    "\n",
    "        for w in it.chain(*self.slow_weights):\n",
    "            w.requires_grad = False\n",
    "        self.state = optimizer.state\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        loss = self.optimizer.step()\n",
    "\n",
    "        for group,slow_weights in zip(self.param_groups,self.slow_weights):\n",
    "            group['step_counter'] += 1\n",
    "            if group['step_counter'] % self.k != 0:\n",
    "                continue\n",
    "            for p,q in zip(group['params'],slow_weights):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                q.data.add_(p.data - q.data, alpha=self.alpha )\n",
    "                p.data.copy_(q.data)\n",
    "        return loss\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value = 1 - beta2)\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(exp_avg, denom, value=-step_size * group['lr'])\n",
    "                else:\n",
    "                    p_data_fp32.add_(exp_avg, alpha=-step_size * group['lr'])\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "#---------- scheduler ---------------------#\n",
    "def get_scheduler(optimizer):\n",
    "    if args.scheduler =='CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0 = args.epochs//args.T_0, T_mult=1, eta_min=0, last_epoch=-1)\n",
    "    elif args.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=args.T_max, eta_min=args.min_lr, last_epoch=-1)\n",
    "    elif args.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience, verbose=True, \n",
    "                                      min_lr = args.min_lr, eps=args.eps)\n",
    "    else:\n",
    "        scheduler=None\n",
    "        assert False, 'not implement'\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-relief",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "established-glasgow",
   "metadata": {
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "class DOWNBLOCK(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOWNBLOCK, self).__init__()\n",
    "        self.down_conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.down_bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.down_bn1(self.down_conv1(x)))\n",
    "        return x\n",
    "    \n",
    "def SegModel():\n",
    "    models = []\n",
    "    # 다른 모덷들일때\n",
    "    if args.diff_arch:\n",
    "        for i in range(args.n_fold):\n",
    "            en_name = args.encoders[i]\n",
    "            de_name = args.decoders[i]\n",
    "            # decoder별로 로드\n",
    "            if de_name.lower() == \"unet\":\n",
    "                if args.clf_head:\n",
    "                    print('classification head')\n",
    "                    aux_params=dict(\n",
    "                        pooling='avg',             # one of 'avg', 'max'\n",
    "                        dropout=0.5,               # dropout ratio, default is None\n",
    "                        activation='sigmoid',      # activation function, default is None\n",
    "                        classes=1,                 # define number of output labels\n",
    "                    )\n",
    "                    model = smp.Unet(\n",
    "                        encoder_name=en_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights='imagenet',     # use `imagenet` pretrained weights for encoder initialization\n",
    "                        in_channels=3,                  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
    "                        classes=1,                      # model output channels (number of classes in your dataset)\n",
    "                        aux_params=aux_params\n",
    "                        )\n",
    "                else:\n",
    "                    model = smp.Unet(\n",
    "                        encoder_name=en_name,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                        encoder_weights='imagenet',     # use `imagenet` pretrained weights for encoder initialization\n",
    "                        in_channels=3,                  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
    "                        classes=1,                      # model output channels (number of classes in your dataset)\n",
    "                        )\n",
    "            elif de_name.lower() == \"fpn\":\n",
    "                model = smp.FPN(\n",
    "                    encoder_name=en_name,\n",
    "                    encoder_weights=\"imagenet\",\n",
    "                    in_channels=3,\n",
    "                    classes=1\n",
    "                )\n",
    "            elif de_name.lower() == \"upp\":\n",
    "                model = smp.UnetPlusPlus(\n",
    "                    encoder_name=en_name,\n",
    "                    encoder_weights=\"imagenet\",\n",
    "                    in_channels=3,\n",
    "                    classes=1\n",
    "                )\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            models.append(model)\n",
    "                \n",
    "        \n",
    "    # 같은 모델 일 때 5개 복사\n",
    "    else:\n",
    "        if args.encoder in ['b0','b1','b2','b3','b4','b5','b6','b7']:\n",
    "            encoder_name_ = f'efficientnet-{args.encoder}' #'timm-efficientnet-b4'\n",
    "            print('encoder : ', encoder_name_)\n",
    "        else:\n",
    "            encoder_name_ = args.encoder\n",
    "        if args.decoder =='fpn':\n",
    "            print('fpn loaded')\n",
    "            model = smp.FPN(\n",
    "                encoder_name=encoder_name_,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                encoder_weights='imagenet',     # use `imagenet` pretrained weights for encoder initialization\n",
    "                in_channels=3,                  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
    "                classes=1,                      # model output channels (number of classes in your dataset)\n",
    "                )\n",
    "        elif args.decoder =='unet':\n",
    "            print('unet loaded')\n",
    "            if args.clf_head:\n",
    "                print('classification head')\n",
    "                aux_params=dict(\n",
    "                    pooling='avg',             # one of 'avg', 'max'\n",
    "                    dropout=0.5,               # dropout ratio, default is None\n",
    "                    activation='sigmoid',      # activation function, default is None\n",
    "                    classes=1,                 # define number of output labels\n",
    "                )\n",
    "                model = smp.Unet(\n",
    "                    encoder_name=encoder_name_,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights='imagenet',     # use `imagenet` pretrained weights for encoder initialization\n",
    "                    in_channels=3,                  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
    "                    classes=1,                      # model output channels (number of classes in your dataset)\n",
    "                    aux_params=aux_params\n",
    "                    )\n",
    "            else:\n",
    "                model = smp.Unet(\n",
    "                    encoder_name=encoder_name_,        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                    encoder_weights='imagenet',     # use `imagenet` pretrained weights for encoder initialization\n",
    "                    in_channels=3,                  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
    "                    classes=1,                      # model output channels (number of classes in your dataset)\n",
    "                    )\n",
    "                #list_ = [DOWNBLOCK(), model, nn.Upsample(size=640, mode='bilinear', align_corners=True)]\n",
    "                #model = nn.Sequential(*list_)\n",
    "        if args.encoder=='R50':\n",
    "            if args.decoder=='ViT':\n",
    "                vit_name='R50-ViT-B_16'\n",
    "                config_vit = CONFIGS[vit_name]\n",
    "                config_vit.n_classes = 1\n",
    "                config_vit.n_skip = 3\n",
    "                if vit_name.find('R50') != -1:\n",
    "                    config_vit.patches.grid = (int(args.image_size / 16), int(args.image_size / 16))\n",
    "                model = VisionTransformer(config_vit, img_size=args.image_size, num_classes=config_vit.n_classes) \n",
    "        for i in range(args.n_fold):\n",
    "            models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-participant",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inappropriate-curve",
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "# ------- image fold train version ------- #\n",
    "\n",
    "# augmentation\n",
    "#\"\"\"현재 crop 없는상태\"\"\"\n",
    "def train_augment(record):\n",
    "    image = record['image']\n",
    "    mask  = record['mask']\n",
    "    \n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask : do_random_rotate_crop(image, mask, size=args.crop_size, mag=45),\n",
    "        lambda image, mask : do_random_scale_crop(image, mask, size=args.crop_size, mag=0.075),\n",
    "        lambda image, mask : do_random_crop(image, mask, size=args.crop_size),\n",
    "    ],1): image, mask = fn(image, mask)\n",
    "\n",
    "    #if (np.random.choice(10,1)<7)[0]:\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask : (image, mask),\n",
    "        lambda image, mask : do_random_contast(image, mask, mag=0.8),\n",
    "        lambda image, mask : do_random_gain(image, mask, mag=0.9),\n",
    "        #lambda image, mask : do_random_hsv(image, mask, mag=[0.1, 0.2, 0]),\n",
    "        lambda image, mask : do_random_noise(image, mask, mag=0.1),\n",
    "    ],2): image, mask =  fn(image, mask)\n",
    "    #if (np.random.choice(10,1)<7)[0]:\n",
    "    image, mask = do_random_hsv(image, mask, mag=[0.1, 0.2, 0])\n",
    "    image, mask = do_random_flip_transpose(image, mask)\n",
    "\n",
    "    record['mask'] = mask\n",
    "    record['image'] = image\n",
    "    return record\n",
    "#그냥 데이터 로더 3개 만들어서 이미지별로 각각 계산해서 평균하자..\n",
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    total = 0 ; dice=0 ; loss=0 ; tp = 0 ; tn = 0\n",
    "    dice2=0 ; loss2=0\n",
    "    valid_probability, valid_probability2, valid_probability3 = [],[],[]\n",
    "    valid_mask, valid_mask2, valid_mask3 = [],[],[]\n",
    "\n",
    "    net = net.eval()\n",
    "\n",
    "    #start_timer = timer()\n",
    "    with torch.no_grad():\n",
    "        for t, batch in enumerate(valid_loader):\n",
    "            batch_size = len(batch['index'])\n",
    "            mask  = batch['mask']\n",
    "            image = batch['image'].to(device)\n",
    "            \n",
    "            if args.clf_head:\n",
    "                logit, _ = net(image) # seg, clf\n",
    "            else:\n",
    "                logit = net(image)#data_parallel(net, image) #net(input)#\n",
    "            probability = torch.sigmoid(logit)\n",
    "                \n",
    "            valid_probability.append(probability.data.cpu().numpy())\n",
    "            valid_mask.append(mask.data.cpu().numpy())\n",
    "\n",
    "    #assert(valid_num == len(valid_loader.dataset)) # drop last True이면 assert되는거임\n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "    if args.loss =='bce':\n",
    "        loss = np_binary_cross_entropy_loss(probability, mask)\n",
    "    elif args.loss =='lovasz':\n",
    "        loss = 0\n",
    "    \n",
    "    # mean loss, dice ..\n",
    "    dice = np_dice_score(probability, mask)\n",
    "    tp, tn = np_accuracy(probability, mask)\n",
    "\n",
    "    return [dice, loss,  tp, tn]\n",
    "\n",
    "def run_train(args):\n",
    "    out_dir = data_dir + f'/result/{args.dir}_{args.encoder}_{args.image_size}'\n",
    "\n",
    "    ## setup  ----------------------------------------\n",
    "    for f in ['checkpoint','train','valid'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "    #backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.train.txt',mode='a')\n",
    "\n",
    "    # my log argument\n",
    "    print_args(args, log)\n",
    "\n",
    "    log.write('\\tout_dir  = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "\n",
    "\n",
    "    log.write('** dataset setting **\\n')\n",
    "    #-----------dataset split --------------------#\n",
    "    tile_id = []\n",
    "    image_dir_ = f'{args.dataset}'#'0.25_320_160_train'\n",
    "    image_dir=[image_dir_, ] # pseudo할때 뒤에 추가\n",
    "    \n",
    "    image_dir_val_ = f'{args.val_dataset}'#'0.25_320_320_val'\n",
    "    image_dir_val=[image_dir_val_, ]\n",
    "    \n",
    "    for i in range(len(image_dir)):\n",
    "        df = pd.read_csv(data_dir + '/tile/%s/image_id_split.csv'% (image_dir[i]) )\n",
    "\n",
    "    for i in range(len(image_dir_val)):\n",
    "        df2 = pd.read_csv(data_dir + '/tile/%s/image_id_split.csv'% (image_dir_val[i]) )\n",
    "    df2['img_id'] = df2['tile_id'].apply(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    kf = KFold(n_splits=args.n_fold, random_state=args.seed, shuffle=True)\n",
    "    all_dice = []\n",
    "    models = SegModel()\n",
    "    for model_idx in range(args.n_fold):\n",
    "        for n_fold, (trn_idx, val_idx) in enumerate(kf.split(df)):\n",
    "            train_df = df[df['fold']!= n_fold].reset_index(drop=True)\n",
    "            val_df = df2[df2['fold']== n_fold].reset_index(drop=True).copy()\n",
    "\n",
    "            # validation loader 3개 만들기 위함\n",
    "            unique_value = val_df['tile_id'].apply(lambda x: x.split('/')[-2]).unique() #[valid_id1, valid_id2, valid_id3 ]\n",
    "            val_img_id1 = unique_value[0] ; val_img_id2 = unique_value[1] ; val_img_id3= unique_value[2]\n",
    "            val_df1= val_df[val_df['img_id']==val_img_id1].reset_index(drop=True)\n",
    "            val_df2= val_df[val_df['img_id']==val_img_id2].reset_index(drop=True)\n",
    "            val_df3= val_df[val_df['img_id']==val_img_id3].reset_index(drop=True)\n",
    "            #####################################################\n",
    "            train_dataset = HuDataset(\n",
    "                df = train_df,\n",
    "                augment = train_augment\n",
    "            )\n",
    "            train_loader  = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 8,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            # val loader1\n",
    "            valid_dataset1 = HuDataset(\n",
    "                df = val_df1\n",
    "                ,\n",
    "            )\n",
    "            valid_loader1 = DataLoader(\n",
    "                valid_dataset1,\n",
    "                sampler = SequentialSampler(valid_dataset1),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 4,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            # val loader2\n",
    "            valid_dataset2 = HuDataset(\n",
    "                df = val_df2\n",
    "                ,\n",
    "            )\n",
    "\n",
    "            valid_loader2 = DataLoader(\n",
    "                valid_dataset2,\n",
    "                sampler = SequentialSampler(valid_dataset2),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 4,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            # val loader3\n",
    "            valid_dataset3 = HuDataset(\n",
    "                df = val_df3\n",
    "                ,\n",
    "            )\n",
    "            valid_loader3 = DataLoader(\n",
    "                valid_dataset3,\n",
    "                sampler = SequentialSampler(valid_dataset3),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 4,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            log.write('fold = %s\\n'%str(n_fold))\n",
    "            log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "            log.write('valid_dataset1 : \\n%s\\n'%(valid_dataset1))\n",
    "            log.write('valid_dataset2 : \\n%s\\n'%(valid_dataset2))\n",
    "            log.write('valid_dataset3 : \\n%s\\n'%(valid_dataset3))\n",
    "            log.write('\\n')\n",
    "\n",
    "            # ------------------------\n",
    "            #  Model\n",
    "            # ------------------------\n",
    "            log.write('** net setting **\\n')\n",
    "\n",
    "            scaler = GradScaler()\n",
    "\n",
    "            net = models[model_idx]\n",
    "            net = net.to(device)\n",
    "            if args.multi_gpu:\n",
    "                log.write('multi gpu')\n",
    "                net = nn.DataParallel(net)\n",
    "\n",
    "\n",
    "            # ------------------------\n",
    "            #  Optimizer\n",
    "            # ------------------------\n",
    "            if args.opt =='adamw':\n",
    "                optimizer = torch.optim.AdamW(net.parameters(), lr = args.start_lr)\n",
    "\n",
    "            elif args.opt =='radam_look':\n",
    "                optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=args.start_lr), alpha=0.5, k=5)\n",
    "            if optimizer == None:\n",
    "                assert False, 'no have optimizer'\n",
    "\n",
    "            # ------------------------\n",
    "            #  scheduler\n",
    "            # ------------------------\n",
    "            scheduler = get_scheduler(optimizer)\n",
    "\n",
    "\n",
    "            log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "            #log.write('schduler\\n  %s\\n'%(schduler))\n",
    "            log.write('\\n')\n",
    "\n",
    "            ## start training here! ##############################################\n",
    "            #array([0.57142857, 0.42857143])\n",
    "            log.write('** start training here! **\\n')\n",
    "            log.write('   is_mixed_precision = %s \\n'%str(args.amp))\n",
    "            log.write('   batch_size = %d \\n'%(args.batch_size))\n",
    "            log.write('             |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n",
    "            log.write('rate  epoch  | dice   loss   tp     tn     | loss           | time           \\n')\n",
    "            log.write('-------------------------------------------------------------------------------------\\n')\n",
    "                      #0.00100   0.50  0.80 | 0.891  0.020  0.000  0.000  | 0.000  0.000   |  0 hr 02 min\n",
    "\n",
    "            def message(mode='print'):\n",
    "                if mode==('print'):\n",
    "                    asterisk = ' '\n",
    "                    loss = batch_loss\n",
    "                if mode==('log'):\n",
    "                    asterisk = '*'\n",
    "                    loss = train_loss\n",
    "\n",
    "                text = \\\n",
    "                    '%0.5f  %s%s    | '%(rate, epoch, asterisk,) +\\\n",
    "                    '%4.3f  %4.3f  %4.3f  %4.3f  | '%(*valid_loss,) +\\\n",
    "                    '%4.3f  %4.3f   | '%(*loss,) +\\\n",
    "                    '%s' % (time_to_str(timer() - start_timer,'min'))\n",
    "\n",
    "                return text\n",
    "\n",
    "            #----\n",
    "            valid_loss = np.zeros(4,np.float32)\n",
    "            train_loss = np.zeros(2,np.float32)\n",
    "            batch_loss = np.zeros_like(train_loss)\n",
    "            sum_train_loss = np.zeros_like(train_loss)\n",
    "            sum_train = 0\n",
    "            loss = torch.FloatTensor([0]).sum()\n",
    "\n",
    "\n",
    "            start_timer = timer()\n",
    "            rate = 0\n",
    "            best_dice = 0\n",
    "            for epoch in range(1, args.epochs+1):\n",
    "                #print('\\r',end='',flush=True)\n",
    "                #log.write(message(mode='log')+'\\n')\n",
    "                # training\n",
    "                for t, batch in enumerate(train_loader):\n",
    "\n",
    "                    # learning rate schduler -------------\n",
    "                    #adjust_learning_rate(optimizer, schduler(iteration))\n",
    "                    rate = get_learning_rate(optimizer)\n",
    "\n",
    "                    # one iteration update  -------------\n",
    "                    batch_size = len(batch['index'])\n",
    "                    net.train()\n",
    "\n",
    "                    if args.amp:\n",
    "                        #image = image.half()\n",
    "                        with autocast():\n",
    "                            mask  = batch['mask'].to(device)\n",
    "                            image = batch['image'].to(device)\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "                            #logit = data_parallel(net, image)\n",
    "                            if args.clf_head:\n",
    "                                logit, logit2 = net(image) # seg logit, clf logit\n",
    "                            else:\n",
    "                                logit = net(image)\n",
    "                            if args.loss == 'bce':\n",
    "                                if args.label_smoothing:\n",
    "                                    loss = LabelSmoothing()(logit, mask)\n",
    "                                else:\n",
    "                                    loss = criterion_binary_cross_entropy(logit, mask)\n",
    "                                if args.clf_head:\n",
    "                                    loss += args.clf_alpha *nn.BCEWithLogitsLoss()(logit2, (mask.sum(dim=(2,3))>0).float() )\n",
    "                            elif args.loss =='lovasz':\n",
    "                                #loss = LovaszHingeLoss()(logit, mask)\n",
    "                                loss = symmetric_lovasz(logit, mask)\n",
    "\n",
    "                            elif args.loss == 'bce_dice':\n",
    "                                loss = DiceBCELoss()(logit, mask)\n",
    "\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                    else :\n",
    "                        mask  = batch['mask'].to(device)\n",
    "                        image = batch['image'].to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        #logit = data_parallel(net, image)\n",
    "                        logit = net(image)\n",
    "                        if args.loss == 'bce':\n",
    "                            loss = criterion_binary_cross_entropy(logit, mask)\n",
    "                        elif args.loss =='lovasz':\n",
    "                            loss = symmetric_lovasz(logit, mask)\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                    # print statistics  --------\n",
    "\n",
    "                    batch_loss = np.array([ loss.item(), 0 ])\n",
    "                    sum_train_loss += batch_loss\n",
    "                    sum_train += 1\n",
    "\n",
    "                    #print('\\r',end='',flush=True)\n",
    "                    #print(message(mode='print'), end='',flush=True)\n",
    "\n",
    "\n",
    "                # train loss\n",
    "                train_loss = sum_train_loss/(sum_train+1e-12)\n",
    "                sum_train_loss[...] = 0\n",
    "                sum_train = 0\n",
    "                print(\"do valid...\")\n",
    "                # scheudler\n",
    "                valid_loss1 = do_valid(net, valid_loader1) #\n",
    "                valid_loss2 = do_valid(net, valid_loader2)\n",
    "                valid_loss3 = do_valid(net, valid_loader3)\n",
    "                valid_loss = (np.array(valid_loss1) + np.array(valid_loss2) + np.array(valid_loss3))/3\n",
    "\n",
    "                log.write(message(mode='log')+'\\n')\n",
    "                log.write(f'{val_img_id1} dice : {valid_loss1[0]:.5f}, {val_img_id2} dice : {valid_loss2[0]:.5f}, {val_img_id3} dice : {valid_loss3[0]:.5f}\\n')\n",
    "\n",
    "                if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                    scheduler.step(valid_loss[0])\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "                # saved models\n",
    "                #if valid_loss[0] > best_dice:\n",
    "                if valid_loss[0] > best_dice:\n",
    "                    best_dice = valid_loss[0]\n",
    "                    log.write(f'\\n saved best models, dice:{best_dice:.5f}\\n')\n",
    "                    torch.save({\n",
    "                        'state_dict': net.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                    }, out_dir + f'/checkpoint/{model_idx}model_{n_fold}fold_{epoch}epoch_{best_dice:.4f}_{args.encoders[model_idx]}_{args.decoders[model_idx]}model.pth')\n",
    "\n",
    "                log.write('='*80+'\\n')\n",
    "\n",
    "            log.write('\\n')\n",
    "\n",
    "            all_dice.append(best_dice)\n",
    "\n",
    "        print(f'all dice score : {sum(all_dice)/len(all_dice) : .4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chief-lexington",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__module__       : __main__\n",
      "amp              : True\n",
      "gpu              : 0,1,2,3,4,5,6,7\n",
      "encoder          : b4\n",
      "decoder          : unet\n",
      "diff_arch        : True\n",
      "encoders         : ['resnext50_32x4d', 'densenet121', 'efficientnet-b4', 'efficientnet-b4', 'xception']\n",
      "decoders         : ['unet', 'fpn', 'upp', 'unet', 'upp']\n",
      "batch_size       : 32\n",
      "weight_decay     : 1e-06\n",
      "epochs           : 25\n",
      "n_fold           : 5\n",
      "fold             : 0\n",
      "all_fold_train   : True\n",
      "image_size       : 512\n",
      "crop_size        : 512\n",
      "tile_size        : 640\n",
      "tile_step        : 320\n",
      "tile_scale       : 0.5\n",
      "dataset          : 0.5_640_320_train_fold\n",
      "val_dataset      : 0.5_640_640_val_fold\n",
      "dir              : 25_['resnext50_32x4d', 'densenet121', 'efficientnet-b4', 'efficientnet-b4', 'xception']_['unet', 'fpn', 'upp', 'unet', 'upp']_512_640_320_0.5\n",
      "T_max            : 10\n",
      "opt              : radam_look\n",
      "scheduler        : CosineAnnealingLR\n",
      "loss             : bce\n",
      "factor           : 0.4\n",
      "patience         : 3\n",
      "eps              : 1e-06\n",
      "decay_epoch      : [4, 8, 12]\n",
      "T_0              : 4\n",
      "start_lr         : 0.001\n",
      "min_lr           : 1e-06\n",
      "clf_head         : False\n",
      "label_smoothing  : False\n",
      "multi_gpu        : True\n",
      "clf_alpha        : 0.3\n",
      "smoothing        : 0.1\n",
      "dice_smoothing   : 1\n",
      "num_workers      : 8\n",
      "seed             : 42\n",
      "__dict__         : <attribute '__dict__' of 'args' objects>\n",
      "__weakref__      : <attribute '__weakref__' of 'args' objects>\n",
      "__doc__          : None\n",
      "\tout_dir  = /home/jeonghokim/competition/HubMap/data//result/25_['resnext50_32x4d', 'densenet121', 'efficientnet-b4', 'efficientnet-b4', 'xception']_['unet', 'fpn', 'upp', 'unet', 'upp']_512_640_320_0.5_b4_512\n",
      "\n",
      "** dataset setting **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /home/jeonghokim/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776cd34862614203ab811efd9d5d463c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/95.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/densenet121-fbdb23505.pth\" to /home/jeonghokim/.cache/torch/hub/checkpoints/densenet121-fbdb23505.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addc939b34d14460a0c3f2e5863df651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/30.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /home/jeonghokim/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6194bcb8dc2f490895ab78c418c84a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/74.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth\" to /home/jeonghokim/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce188be3b064dc48a232e3454cf1548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/87.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold = 3\n",
      "train_dataset : \n",
      "\tlen  = 18676\n",
      "\n",
      "valid_dataset1 : \n",
      "\tlen  = 184\n",
      "\n",
      "valid_dataset2 : \n",
      "\tlen  = 443\n",
      "\n",
      "valid_dataset3 : \n",
      "\tlen  = 105\n",
      "\n",
      "\n",
      "** net setting **\n",
      "multi gpuoptimizer\n",
      "  Lookahead (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    step_counter: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "** start training here! **\n",
      "   is_mixed_precision = True \n",
      "   batch_size = 32 \n",
      "             |-------------- VALID---------|---- TRAIN/BATCH ----------------\n",
      "rate  epoch  | dice   loss   tp     tn     | loss           | time           \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-059aaf3279a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# set seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no set seed'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e74fdd2573fe>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    279\u001b[0m                                 \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# seg logit, clf logit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                                 \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bce'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hubmap/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hubmap/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hubmap/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hubmap/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hubmap/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hubmap/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # set seed\n",
    "    print('no set seed') if args.seed ==-1 else set_seeds(seed=args.seed)\n",
    "    run_train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "australian-composer",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# #0.9333, deterministic하게 결정시킨것임.\n",
    "\n",
    "# b9a3865fc dice : 0.94369, 0486052bb dice : 0.95022, afa5e8098 dice : 0.90132\n",
    "# saved best models, dice:0.93174\n",
    "\n",
    "# aaa6a05cc dice : 0.90918, cb2d976f4 dice : 0.94353, 4ef6695ce dice : 0.93610\n",
    "# saved best models, dice:0.92960\n",
    "\n",
    "# e79de561c dice : 0.93229, 095bf7a1f dice : 0.93469, 1e2425f28 dice : 0.93323\n",
    "# saved best models, dice:0.93340\n",
    "\n",
    "# 2f6ecfcdf dice : 0.95216, 8242609fa dice : 0.95276, b2dc8411c dice : 0.94840\n",
    "# saved best models, dice:0.95111\n",
    " \n",
    "# 54f2eec69 dice : 0.92800, 26dc41664 dice : 0.94386, c68fe75ea dice : 0.88966\n",
    "# saved best models, dice:0.92050\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-trash",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train with albumentation augment version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-typing",
   "metadata": {
    "hidden": true
   },
   "source": [
    "albumentation으로 augmentation 실험할 경우 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "significant-pacific",
   "metadata": {
    "code_folding": [
     32,
     38,
     77
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ------- image fold train version, my augment ------- #\n",
    "\n",
    "# augmentation\n",
    "def train_augment():\n",
    "\n",
    "    return A.Compose([\n",
    "            A.OneOf([\n",
    "                A.RandomCrop(args.image_size,args.crop_size),\n",
    "                A.RandomResizedCrop(args.image_size,args.crop_size)\n",
    "             ], p=1),\n",
    "            A.OneOf([\n",
    "                #A.RandomContrast(),\n",
    "                #A.RandomBrightness(),\n",
    "                A.RandomGamma(),\n",
    "                A.RandomBrightnessContrast()\n",
    "                ], p=0.5),\n",
    "            A.OneOf([\n",
    "                A.CLAHE(clip_limit=2),\n",
    "                A.HueSaturationValue(10,15,10),\n",
    "                A.ChannelShuffle(),\n",
    "                A.InvertImg()\n",
    "                ], p=1),\n",
    "            A.OneOf([\n",
    "                A.HorizontalFlip(),\n",
    "                A.VerticalFlip(),\n",
    "                A.RandomRotate90(),\n",
    "                A.ShiftScaleRotate()\n",
    "            ], p = 0.5 ),\n",
    "        \n",
    "        #A.Resize(512, 512),\n",
    "        ToTensor()\n",
    "    ],p=1.)\n",
    "def val_augment():\n",
    "\n",
    "    return A.Compose([\n",
    "        ToTensor()\n",
    "    ],p=1.)\n",
    "\n",
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    total = 0 ; dice=0 ; loss=0 ; tp = 0 ; tn = 0\n",
    "    dice2=0 ; loss2=0\n",
    "    valid_probability, valid_probability2, valid_probability3 = [],[],[]\n",
    "    valid_mask, valid_mask2, valid_mask3 = [],[],[]\n",
    "\n",
    "    net = net.eval()\n",
    "\n",
    "    #start_timer = timer()\n",
    "    with torch.no_grad():\n",
    "        for t, (image,mask) in enumerate(valid_loader):\n",
    "            #mask  = batch['mask']\n",
    "            image = image.to(device)\n",
    "            \n",
    "            if args.clf_head:\n",
    "                logit, _ = net(image) # seg, clf\n",
    "            else:\n",
    "                logit = net(image)#data_parallel(net, image) #net(input)#\n",
    "            probability = torch.sigmoid(logit)\n",
    "                \n",
    "            valid_probability.append(probability.data.cpu().numpy())\n",
    "            valid_mask.append(mask.data.cpu().numpy())\n",
    "\n",
    "    #assert(valid_num == len(valid_loader.dataset)) # drop last True이면 assert되는거임\n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "    if args.loss =='bce':\n",
    "        loss = np_binary_cross_entropy_loss(probability, mask)\n",
    "    elif args.loss =='lovasz':\n",
    "        loss = 0\n",
    "    \n",
    "    # mean loss, dice ..\n",
    "    dice = np_dice_score(probability, mask)\n",
    "    tp, tn = np_accuracy(probability, mask)\n",
    "\n",
    "    return [dice, loss,  tp, tn]\n",
    "\n",
    "def run_train(args):\n",
    "    out_dir = data_dir + f'/result/{args.dir}_{args.encoder}_{args.image_size}'\n",
    "\n",
    "    ## setup  ----------------------------------------\n",
    "    for f in ['checkpoint','train','valid'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "    #backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.train.txt',mode='a')\n",
    "\n",
    "    # my log argument\n",
    "    print_args(args, log)\n",
    "\n",
    "    log.write('\\tout_dir  = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "\n",
    "\n",
    "    log.write('** dataset setting **\\n')\n",
    "    #-----------dataset split --------------------#\n",
    "    tile_id = []\n",
    "    image_dir_ = f'{args.dataset}'#'0.25_320_160_train'\n",
    "    image_dir=[image_dir_, ] # pseudo할때 뒤에 추가\n",
    "    \n",
    "    image_dir_val_ = f'{args.val_dataset}'#'0.25_320_320_val'\n",
    "    image_dir_val=[image_dir_val_, ]\n",
    "    \n",
    "    for i in range(len(image_dir)):\n",
    "        df = pd.read_csv(data_dir + '/tile/%s/image_id_split.csv'% (image_dir[i]) )\n",
    "\n",
    "    for i in range(len(image_dir_val)):\n",
    "        df2 = pd.read_csv(data_dir + '/tile/%s/image_id_split.csv'% (image_dir_val[i]) )\n",
    "    df2['img_id'] = df2['tile_id'].apply(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    kf = KFold(n_splits=args.n_fold, random_state=args.seed, shuffle=True)\n",
    "    all_dice = []\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        if not args.all_fold_train:\n",
    "            if n_fold != args.fold:\n",
    "                print(f'{n_fold} fold pass')\n",
    "                continue\n",
    "        if n_fold in [3, 4]:\n",
    "            print(n_fold,'fold pass')\n",
    "            continue\n",
    "        train_df = df[df['fold']!= n_fold].reset_index(drop=True)\n",
    "        val_df = df2[df2['fold']== n_fold].reset_index(drop=True).copy()\n",
    "        \n",
    "        # validation loader 3개 만들기 위함\n",
    "        unique_value = val_df['tile_id'].apply(lambda x: x.split('/')[-2]).unique() #[valid_id1, valid_id2, valid_id3 ]\n",
    "        val_img_id1 = unique_value[0] ; val_img_id2 = unique_value[1] ; val_img_id3= unique_value[2]\n",
    "        val_df1= val_df[val_df['img_id']==val_img_id1].reset_index(drop=True)\n",
    "        val_df2= val_df[val_df['img_id']==val_img_id2].reset_index(drop=True)\n",
    "        val_df3= val_df[val_df['img_id']==val_img_id3].reset_index(drop=True)\n",
    "        #####################################################\n",
    "        train_dataset = HuDataset(\n",
    "            df = train_df,\n",
    "            augment = train_augment()\n",
    "        )\n",
    "        train_loader  = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size  = args.batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 8,\n",
    "            pin_memory  = True,\n",
    "        )\n",
    "        # val loader1\n",
    "        valid_dataset1 = HuDataset(\n",
    "            df = val_df1,\n",
    "            augment = val_augment()\n",
    "        )\n",
    "        valid_loader1 = DataLoader(\n",
    "            valid_dataset1,\n",
    "            sampler = SequentialSampler(valid_dataset1),\n",
    "            batch_size  = args.batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 4,\n",
    "            pin_memory  = True,\n",
    "        )\n",
    "        # val loader2\n",
    "        valid_dataset2 = HuDataset(\n",
    "            df = val_df2,\n",
    "            augment = val_augment()\n",
    "        )\n",
    "        \n",
    "        valid_loader2 = DataLoader(\n",
    "            valid_dataset2,\n",
    "            sampler = SequentialSampler(valid_dataset2),\n",
    "            batch_size  = args.batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 4,\n",
    "            pin_memory  = True,\n",
    "        )\n",
    "        # val loader3\n",
    "        valid_dataset3 = HuDataset(\n",
    "            df = val_df3,\n",
    "            augment = val_augment()\n",
    "        )\n",
    "        valid_loader3 = DataLoader(\n",
    "            valid_dataset3,\n",
    "            sampler = SequentialSampler(valid_dataset3),\n",
    "            batch_size  = args.batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 4,\n",
    "            pin_memory  = True,\n",
    "        )\n",
    "        log.write('fold = %s\\n'%str(n_fold))\n",
    "        log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "        log.write('valid_dataset1 : \\n%s\\n'%(valid_dataset1))\n",
    "        log.write('valid_dataset2 : \\n%s\\n'%(valid_dataset2))\n",
    "        log.write('valid_dataset3 : \\n%s\\n'%(valid_dataset3))\n",
    "        log.write('\\n')\n",
    "\n",
    "        # ------------------------\n",
    "        #  Model\n",
    "        # ------------------------\n",
    "        log.write('** net setting **\\n')\n",
    "\n",
    "        scaler = GradScaler()\n",
    "        net = SegModel() \n",
    "        net = net.to(device)\n",
    "        \n",
    "        # ------------------------\n",
    "        #  Optimizer\n",
    "        # ------------------------\n",
    "        if args.opt =='adamw':\n",
    "            optimizer = torch.optim.AdamW(net.parameters(), lr = args.start_lr)\n",
    "\n",
    "        elif args.opt =='radam_look':\n",
    "            optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=args.start_lr), alpha=0.5, k=5)\n",
    "        if optimizer == None:\n",
    "            assert False, 'no have optimizer'\n",
    "        \n",
    "        # ------------------------\n",
    "        #  scheduler\n",
    "        # ------------------------\n",
    "        scheduler = get_scheduler(optimizer)\n",
    "\n",
    "\n",
    "        log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "        #log.write('schduler\\n  %s\\n'%(schduler))\n",
    "        log.write('\\n')\n",
    "\n",
    "        ## start training here! ##############################################\n",
    "        #array([0.57142857, 0.42857143])\n",
    "        log.write('** start training here! **\\n')\n",
    "        log.write('   is_mixed_precision = %s \\n'%str(args.amp))\n",
    "        log.write('   batch_size = %d \\n'%(args.batch_size))\n",
    "        log.write('             |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n",
    "        log.write('rate  epoch  | dice   loss   tp     tn     | loss           | time           \\n')\n",
    "        log.write('-------------------------------------------------------------------------------------\\n')\n",
    "                  #0.00100   0.50  0.80 | 0.891  0.020  0.000  0.000  | 0.000  0.000   |  0 hr 02 min\n",
    "\n",
    "        def message(mode='print'):\n",
    "            if mode==('print'):\n",
    "                asterisk = ' '\n",
    "                loss = batch_loss\n",
    "            if mode==('log'):\n",
    "                asterisk = '*'\n",
    "                loss = train_loss\n",
    "\n",
    "            text = \\\n",
    "                '%0.5f  %s%s    | '%(rate, epoch, asterisk,) +\\\n",
    "                '%4.3f  %4.3f  %4.3f  %4.3f  | '%(*valid_loss,) +\\\n",
    "                '%4.3f  %4.3f   | '%(*loss,) +\\\n",
    "                '%s' % (time_to_str(timer() - start_timer,'min'))\n",
    "\n",
    "            return text\n",
    "\n",
    "        #----\n",
    "        valid_loss = np.zeros(4,np.float32)\n",
    "        train_loss = np.zeros(2,np.float32)\n",
    "        batch_loss = np.zeros_like(train_loss)\n",
    "        sum_train_loss = np.zeros_like(train_loss)\n",
    "        sum_train = 0\n",
    "        loss = torch.FloatTensor([0]).sum()\n",
    "\n",
    "\n",
    "        start_timer = timer()\n",
    "        rate = 0\n",
    "        best_dice = 0\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            #print('\\r',end='',flush=True)\n",
    "            #log.write(message(mode='log')+'\\n')\n",
    "            # training\n",
    "            for t, (image, mask) in enumerate(train_loader):\n",
    "                # learning rate schduler -------------\n",
    "                #adjust_learning_rate(optimizer, schduler(iteration))\n",
    "                rate = get_learning_rate(optimizer)\n",
    "\n",
    "                # one iteration update  -------------\n",
    "                #batch_size = len(batch['index'])\n",
    "                net.train()\n",
    "\n",
    "                if args.amp:\n",
    "                    #image = image.half()\n",
    "                    with autocast():\n",
    "                        mask  = mask.to(device)\n",
    "                        image = image.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        #logit = data_parallel(net, image)\n",
    "                        if args.clf_head:\n",
    "                            logit, logit2 = net(image) # seg logit, clf logit\n",
    "                        else:\n",
    "                            logit = net(image)\n",
    "                        if args.loss == 'bce':\n",
    "                            if args.label_smoothing:\n",
    "                                loss = LabelSmoothing()(logit, mask)\n",
    "                            else:\n",
    "                                loss = criterion_binary_cross_entropy(logit, mask)\n",
    "                            if args.clf_head:\n",
    "                                loss += args.clf_alpha *nn.BCEWithLogitsLoss()(logit2, (mask.sum(dim=(2,3))>0).float() )\n",
    "                        elif args.loss =='lovasz':\n",
    "                            #loss = LovaszHingeLoss()(logit, mask)\n",
    "                            loss = symmetric_lovasz(logit, mask)\n",
    "                            \n",
    "                        elif args.loss == 'bce_dice':\n",
    "                            loss = DiceBCELoss()(logit, mask)\n",
    "                        elif args.loss == 'dice':\n",
    "                            loss = DiceLoss()(logit, mask)\n",
    "                            \n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "                else :\n",
    "                    mask  = batch['mask'].to(device)\n",
    "                    image = batch['image'].to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    #logit = data_parallel(net, image)\n",
    "                    logit = net(image)\n",
    "                    if args.loss == 'bce':\n",
    "                        loss = criterion_binary_cross_entropy(logit, mask)\n",
    "                    elif args.loss =='lovasz':\n",
    "                        loss = symmetric_lovasz(logit, mask)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "\n",
    "                # print statistics  --------\n",
    "\n",
    "                batch_loss = np.array([ loss.item(), 0 ])\n",
    "                sum_train_loss += batch_loss\n",
    "                sum_train += 1\n",
    "\n",
    "                #print('\\r',end='',flush=True)\n",
    "                #print(message(mode='print'), end='',flush=True)\n",
    "            \n",
    "\n",
    "            # train loss\n",
    "            train_loss = sum_train_loss/(sum_train+1e-12)\n",
    "            sum_train_loss[...] = 0\n",
    "            sum_train = 0\n",
    "\n",
    "            # scheudler\n",
    "            valid_loss1 = do_valid(net, valid_loader1) #\n",
    "            valid_loss2 = do_valid(net, valid_loader2)\n",
    "            valid_loss3 = do_valid(net, valid_loader3)\n",
    "            valid_loss = (np.array(valid_loss1) + np.array(valid_loss2) + np.array(valid_loss3))/3\n",
    "            \n",
    "            log.write(message(mode='log')+'\\n')\n",
    "            log.write(f'{val_img_id1} dice : {valid_loss1[0]:.5f}, {val_img_id2} dice : {valid_loss2[0]:.5f}, {val_img_id3} dice : {valid_loss3[0]:.5f}\\n')\n",
    "            \n",
    "            if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                scheduler.step(valid_loss[0])\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            # saved models\n",
    "            #if valid_loss[0] > best_dice:\n",
    "            if valid_loss[0] > best_dice:\n",
    "                best_dice = valid_loss[0]\n",
    "                log.write(f'\\n saved best models, dice:{best_dice:.5f}\\n')\n",
    "                torch.save({\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                }, out_dir + f'/checkpoint/{n_fold}fold_{epoch}epoch_{best_dice:.4f}_model.pth')\n",
    "            \n",
    "            log.write('='*80+'\\n')\n",
    "\n",
    "        log.write('\\n')\n",
    "        \n",
    "        all_dice.append(best_dice)\n",
    "    \n",
    "    print(f'all dice score : {sum(all_dice)/len(all_dice) : .4f}')\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "available-canal",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__module__       : __main__\n",
      "amp              : True\n",
      "gpu              : 0, 1, 2, 3\n",
      "encoder          : b4\n",
      "decoder          : unet\n",
      "diff_arch        : True\n",
      "encoders         : ['efficientnet-b4', 'efficientnet-b4', 'resnet34', 'xception', 'dpn68']\n",
      "decoders         : ['unet', 'fpn', 'upp', 'unet', 'upp']\n",
      "batch_size       : 64\n",
      "weight_decay     : 1e-06\n",
      "epochs           : 1\n",
      "n_fold           : 5\n",
      "fold             : 0\n",
      "all_fold_train   : True\n",
      "image_size       : 512\n",
      "crop_size        : 512\n",
      "tile_size        : 640\n",
      "tile_step        : 320\n",
      "tile_scale       : 0.5\n",
      "dataset          : 0.5_640_320_train_fold\n",
      "val_dataset      : 0.5_640_640_val_fold\n",
      "dir              : 1_['efficientnet-b4', 'efficientnet-b4', 'resnet34', 'xception', 'dpn68']_['unet', 'fpn', 'upp', 'unet', 'upp']_512_640_320_0.5\n",
      "T_max            : 10\n",
      "opt              : radam_look\n",
      "scheduler        : CosineAnnealingLR\n",
      "loss             : bce\n",
      "factor           : 0.4\n",
      "patience         : 3\n",
      "eps              : 1e-06\n",
      "decay_epoch      : [4, 8, 12]\n",
      "T_0              : 4\n",
      "start_lr         : 0.001\n",
      "min_lr           : 1e-06\n",
      "clf_head         : False\n",
      "label_smoothing  : False\n",
      "multi_gpu        : True\n",
      "clf_alpha        : 0.3\n",
      "smoothing        : 0.1\n",
      "dice_smoothing   : 1\n",
      "num_workers      : 8\n",
      "seed             : 42\n",
      "__dict__         : <attribute '__dict__' of 'args' objects>\n",
      "__weakref__      : <attribute '__weakref__' of 'args' objects>\n",
      "__doc__          : None\n",
      "\tout_dir  = /home/jeonghokim/competition/HubMap/data//result/1_['efficientnet-b4', 'efficientnet-b4', 'resnet34', 'xception', 'dpn68']_['unet', 'fpn', 'upp', 'unet', 'upp']_512_640_320_0.5_b4_512\n",
      "\n",
      "** dataset setting **\n",
      "fold = 0\n",
      "train_dataset : \n",
      "\tlen  = 16331\n",
      "\n",
      "valid_dataset1 : \n",
      "\tlen  = 442\n",
      "\n",
      "valid_dataset2 : \n",
      "\tlen  = 208\n",
      "\n",
      "valid_dataset3 : \n",
      "\tlen  = 670\n",
      "\n",
      "\n",
      "** net setting **\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-059aaf3279a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# set seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no set seed'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b6bdf2f2403c>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# ------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # set seed\n",
    "    print('no set seed') if args.seed ==-1 else set_seeds(seed=args.seed)\n",
    "    run_train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-embassy",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minimal-sociology",
   "metadata": {
    "code_folding": [
     0,
     3,
     30,
     76,
     113
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------- tile shuffle fold train version(use X) ----------#\n",
    "\"\"\"\n",
    "# augmentation\n",
    "def train_augment(record):\n",
    "    image = record['image']\n",
    "    mask  = record['mask']\n",
    "    \n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask : do_random_rotate_crop(image, mask, size=args.image_size, mag=45),\n",
    "        lambda image, mask : do_random_scale_crop(image, mask, size=args.image_size, mag=0.075),\n",
    "        lambda image, mask : do_random_crop(image, mask, size=args.image_size),\n",
    "    ],1): image, mask = fn(image, mask)\n",
    "\n",
    "    #if (np.random.choice(10,1)<7)[0]:\n",
    "    for fn in np.random.choice([\n",
    "        lambda image, mask : (image, mask),\n",
    "        lambda image, mask : do_random_contast(image, mask, mag=0.8),\n",
    "        lambda image, mask : do_random_gain(image, mask, mag=0.9),\n",
    "        #lambda image, mask : do_random_hsv(image, mask, mag=[0.1, 0.2, 0]),\n",
    "        lambda image, mask : do_random_noise(image, mask, mag=0.1),\n",
    "    ],2): image, mask =  fn(image, mask)\n",
    "    #if (np.random.choice(10,1)<7)[0]:\n",
    "    image, mask = do_random_hsv(image, mask, mag=[0.1, 0.2, 0])\n",
    "    image, mask = do_random_flip_transpose(image, mask)\n",
    "\n",
    "    record['mask'] = mask\n",
    "    record['image'] = image\n",
    "    return record\n",
    "\n",
    "# validation\n",
    "def do_valid2(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    total = 0 ; dice=0 ; loss=0 ; tp = 0 ; tn = 0\n",
    "    dice2=0 ; loss2=0\n",
    "    valid_probability, valid_probability2 = [],[]\n",
    "    valid_mask = []\n",
    "\n",
    "    net = net.eval()\n",
    "\n",
    "    #start_timer = timer()\n",
    "    with torch.no_grad():\n",
    "        for t, batch in enumerate(valid_loader):\n",
    "            batch_size = len(batch['index'])\n",
    "            mask  = batch['mask']\n",
    "            image = batch['image'].to(device)\n",
    "\n",
    "            logit = net(image)#data_parallel(net, image) #net(input)#\n",
    "            probability = torch.sigmoid(logit)\n",
    "            \n",
    "            # loss\n",
    "            if args.loss =='bce':\n",
    "                #loss += criterion_binary_cross_entropy(probability.data.cpu(), mask.data.cpu()).item()\n",
    "                loss += np_binary_cross_entropy_loss(probability.cpu().numpy(), mask.cpu().numpy())\n",
    "            elif args.loss =='lovasz':\n",
    "                loss += symmetric_lovasz(probability.data.cpu(), mask.data.cpu()).item()\n",
    "                \n",
    "            # dice\n",
    "            dice += dice_score(probability.data.cpu(), mask.data.cpu(), threshold = 0.5).item()\n",
    "            tp_, tn_ = torch_accuracy(probability.data.cpu(), mask.data.cpu(), threshold = 0.5)\n",
    "            tp+=tp_.item() ; tn += tn_.item()\n",
    "            # numpy\n",
    "            #dice2 += np_dice_score(probability.data.cpu().numpy(), mask.data.cpu().numpy())\n",
    "            #loss2 += np_binary_cross_entropy_loss(probability.cpu().numpy(), mask.cpu().numpy())\n",
    "\n",
    "            #valid_num += batch_size\n",
    "\n",
    "    #assert(valid_num == len(valid_loader.dataset)) # drop last True이면 assert되는거임\n",
    "    \n",
    "    # mean loss, dice ..\n",
    "    loss = loss/len(valid_loader)\n",
    "    dice = dice/len(valid_loader)\n",
    "    tp = tp/len(valid_loader) ; tn = tn/len(valid_loader)\n",
    "\n",
    "    return [dice, loss,  tp, tn]\n",
    "# append 버전\n",
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    total = 0 ; dice=0 ; loss=0 ; tp = 0 ; tn = 0\n",
    "    dice2=0 ; loss2=0\n",
    "    valid_probability, valid_probability2 = [],[]\n",
    "    valid_mask = []\n",
    "\n",
    "    net = net.eval()\n",
    "\n",
    "    #start_timer = timer()\n",
    "    with torch.no_grad():\n",
    "        for t, batch in enumerate(valid_loader):\n",
    "            batch_size = len(batch['index'])\n",
    "            mask  = batch['mask']\n",
    "            image = batch['image'].to(device)\n",
    "\n",
    "            logit = net(image)#data_parallel(net, image) #net(input)#\n",
    "            probability = torch.sigmoid(logit)\n",
    "            \n",
    "            valid_probability.append(probability.data.cpu().numpy())\n",
    "            valid_mask.append(mask.data.cpu().numpy())\n",
    "\n",
    "\n",
    "    \n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "    if args.loss =='bce':\n",
    "        loss = np_binary_cross_entropy_loss(probability, mask)\n",
    "    elif args.loss =='lovasz':\n",
    "        loss = symmetric_lovasz(probability, mask)\n",
    "    \n",
    "    # mean loss, dice ..\n",
    "    dice = np_dice_score(probability, mask)\n",
    "    tp, tn = np_accuracy(probability, mask)\n",
    "    return [dice, loss,  tp, tn]\n",
    "\n",
    "def run_train(args):\n",
    "    out_dir = data_dir + f'/result/{args.dir}_fold{args.fold}_{args.encoder}_{args.image_size}'\n",
    "\n",
    "    ## setup  ----------------------------------------\n",
    "    for f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "    #backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.train.txt',mode='a')\n",
    "\n",
    "    # my log argument\n",
    "    print_args(args, log)\n",
    "\n",
    "    log.write('\\tout_dir  = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "\n",
    "\n",
    "    log.write('** dataset setting **\\n')\n",
    "    #-----------dataset split --------------------#\n",
    "    tile_id = []\n",
    "    image_dir_ = f'{args.dataset}'#'0.25_480_240_train'\n",
    "    image_dir=[image_dir_, ] # pseudo할때 뒤에 추가\n",
    "\n",
    "    for i in range(len(image_dir)):\n",
    "        df = pd.read_csv(data_dir + '/tile/%s/image_id.csv'% (image_dir[i]) )\n",
    "        tile_id += ('%s/'%(image_dir[i]) + df.tile_id).tolist()\n",
    "\n",
    "    kf = KFold(n_splits=args.n_fold, random_state=args.seed, shuffle=True)\n",
    "    all_dice = []\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kf.split(tile_id)):\n",
    "        if not args.all_fold_train:\n",
    "            if n_fold != args.fold:\n",
    "                print(f'{n_fold} fold pass')\n",
    "                continue\n",
    "\n",
    "        #####################################################\n",
    "        train_dataset = HuDataset(\n",
    "            tile_id = df.loc[trn_idx]['tile_id'].tolist(),\n",
    "            augment = train_augment\n",
    "        )\n",
    "        train_loader  = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size  = args.batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 8,\n",
    "            pin_memory  = True,\n",
    "            collate_fn  = null_collate\n",
    "        )\n",
    "\n",
    "        valid_dataset = HuDataset(\n",
    "            tile_id = df.loc[val_idx]['tile_id'].tolist()\n",
    "            ,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            sampler = SequentialSampler(valid_dataset),\n",
    "            batch_size  = args.batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 4,\n",
    "            pin_memory  = True,\n",
    "            collate_fn  = null_collate\n",
    "        )\n",
    "        log.write('fold = %s\\n'%str(n_fold))\n",
    "        log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "        log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "        log.write('\\n')\n",
    "\n",
    "        # ------------------------\n",
    "        #  Model\n",
    "        # ------------------------\n",
    "        log.write('** net setting **\\n')\n",
    "\n",
    "        scaler = GradScaler()\n",
    "        net = SegModel() \n",
    "        net = net.to(device)\n",
    "        \n",
    "        # ------------------------\n",
    "        #  Optimizer\n",
    "        # ------------------------\n",
    "        if args.opt =='adamw':\n",
    "            optimizer = torch.optim.AdamW(net.parameters(), lr = args.start_lr)\n",
    "\n",
    "        elif args.opt =='radam_look':\n",
    "            optimizer = Lookahead(RAdam(filter(lambda p: p.requires_grad, net.parameters()),lr=args.start_lr), alpha=0.5, k=5)\n",
    "        if optimizer == None:\n",
    "            assert False, 'no have optimizer'\n",
    "        \n",
    "        # ------------------------\n",
    "        #  scheduler\n",
    "        # ------------------------\n",
    "        scheduler = get_scheduler(optimizer)\n",
    "\n",
    "\n",
    "        log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "        #log.write('schduler\\n  %s\\n'%(schduler))\n",
    "        log.write('\\n')\n",
    "\n",
    "        ## start training here! ##############################################\n",
    "        #array([0.57142857, 0.42857143])\n",
    "        log.write('** start training here! **\\n')\n",
    "        log.write('   is_mixed_precision = %s \\n'%str(args.amp))\n",
    "        log.write('   batch_size = %d \\n'%(args.batch_size))\n",
    "        log.write('             |-------------- VALID---------|---- TRAIN/BATCH ----------------\\n')\n",
    "        log.write('rate  epoch  | dice   loss   tp     tn     | loss           | time           \\n')\n",
    "        log.write('-------------------------------------------------------------------------------------\\n')\n",
    "                  #0.00100   0.50  0.80 | 0.891  0.020  0.000  0.000  | 0.000  0.000   |  0 hr 02 min\n",
    "\n",
    "        def message(mode='print'):\n",
    "            if mode==('print'):\n",
    "                asterisk = ' '\n",
    "                loss = batch_loss\n",
    "            if mode==('log'):\n",
    "                asterisk = '*'\n",
    "                loss = train_loss\n",
    "\n",
    "            text = \\\n",
    "                '%0.5f  %s%s    | '%(rate, epoch, asterisk,) +\\\n",
    "                '%4.3f  %4.3f  %4.3f  %4.3f  | '%(*valid_loss,) +\\\n",
    "                '%4.3f  %4.3f   | '%(*loss,) +\\\n",
    "                '%s' % (time_to_str(timer() - start_timer,'min'))\n",
    "\n",
    "            return text\n",
    "\n",
    "        #----\n",
    "        valid_loss = np.zeros(4,np.float32)\n",
    "        train_loss = np.zeros(2,np.float32)\n",
    "        batch_loss = np.zeros_like(train_loss)\n",
    "        sum_train_loss = np.zeros_like(train_loss)\n",
    "        sum_train = 0\n",
    "        loss = torch.FloatTensor([0]).sum()\n",
    "\n",
    "\n",
    "        start_timer = timer()\n",
    "        rate = 0\n",
    "        best_dice = 0\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            #print('\\r',end='',flush=True)\n",
    "            #log.write(message(mode='log')+'\\n')\n",
    "            # training\n",
    "            for t, batch in enumerate(train_loader):\n",
    "\n",
    "                # learning rate schduler -------------\n",
    "                #adjust_learning_rate(optimizer, schduler(iteration))\n",
    "                rate = get_learning_rate(optimizer)\n",
    "\n",
    "                # one iteration update  -------------\n",
    "                batch_size = len(batch['index'])\n",
    "                net.train()\n",
    "\n",
    "                if args.amp:\n",
    "                    #image = image.half()\n",
    "                    with autocast():\n",
    "                        mask  = batch['mask'].to(device)\n",
    "                        image = batch['image'].to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        #logit = data_parallel(net, image)\n",
    "                        logit = net(image)\n",
    "                        if args.loss == 'bce':\n",
    "                            loss = criterion_binary_cross_entropy(logit, mask)\n",
    "                        elif args.loss =='lovasz':\n",
    "                            loss = symmetric_lovasz(logit, mask)\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "                else :\n",
    "                    mask  = batch['mask'].to(device)\n",
    "                    image = batch['image'].to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    #logit = data_parallel(net, image)\n",
    "                    logit = net(image)\n",
    "                    if args.loss == 'bce':\n",
    "                        loss = criterion_binary_cross_entropy(logit, mask)\n",
    "                    elif args.loss =='lovasz':\n",
    "                        loss = symmetric_lovasz(logit, mask)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "\n",
    "                # print statistics  --------\n",
    "\n",
    "                batch_loss = np.array([ loss.item(), 0 ])\n",
    "                sum_train_loss += batch_loss\n",
    "                sum_train += 1\n",
    "\n",
    "                #print('\\r',end='',flush=True)\n",
    "                #print(message(mode='print'), end='',flush=True)\n",
    "\n",
    "            # train loss\n",
    "            train_loss = sum_train_loss/(sum_train+1e-12)\n",
    "            sum_train_loss[...] = 0\n",
    "            sum_train = 0\n",
    "\n",
    "            # scheudler\n",
    "            valid_loss = do_valid(net, valid_loader) #\n",
    "            log.write(message(mode='log')+'\\n')\n",
    "            if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                scheduler.step(valid_loss[0])\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "            # saved models\n",
    "            #if valid_loss[0] > best_dice:\n",
    "            if valid_loss[0] > best_dice:\n",
    "                best_dice = valid_loss[0]\n",
    "                print(f'\\n saved best models, dice:{best_dice:.5f}')\n",
    "                torch.save({\n",
    "                    'state_dict': net.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                }, out_dir + f'/checkpoint/{n_fold}fold_{epoch}epoch_{best_dice:.4f}_model.pth')\n",
    "\n",
    "        log.write('\\n')\n",
    "        all_dice.append(best_dice)\n",
    "    \n",
    "    print(f'all dice score : {sum(all_dice)/len(all_dice) : .4f}')\n",
    "  \n",
    "     \"\"\"   \n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-influence",
   "metadata": {},
   "source": [
    "# validation 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-factory",
   "metadata": {},
   "source": [
    "eval mode : 모델들 불러와서 validation에 해당하는 이미지 예측후 cv측정, threshold별 dice 계산\n",
    "\n",
    "gen_image : validation에 해당하는 이미지 예측후 visualize(저장된 이미지로 확인가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "antique-ready",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "class args:\n",
    "    # ---- factor ---- #\n",
    "    server ='local' # ['kaggle', 'local'] local은 cv측정용도\n",
    "    amp = False\n",
    "    gpu = 1\n",
    "    \n",
    "    encoder='b4'#'resnet34'\n",
    "    decoder='unet'\n",
    "    n_fold = 5\n",
    "    diff_arch = True\n",
    "    encoders = [\"resnext50_32x4d\", \"densenet121\", \"vgg19\", \"xception\", \"xception\"]\n",
    "    decoders = [\"unet\", \"fpn\", \"upp\", \"unet\", \"upp\"]\n",
    "    batch_size=16\n",
    "    #fold=0\n",
    "    mode = 'eval' # ['eval', 'gen_image']\n",
    "    loss = 'bce'\n",
    "    clf_head=False\n",
    "    dataset = '0.5_640_320_train_fold'#'[0.25_256_128_train', '0.25_480_240_train' ]# dataset size\n",
    "    val_dataset = '0.5_640_640_val_fold'\n",
    "    \n",
    "    model_path = sorted(glob(\"./data/result/ensemble25/checkpoint/*.pth\"))\n",
    "    \n",
    "    \n",
    "    sub = '[visualize][04.05]_0.9337_models'# submission name\n",
    "    \n",
    "    # ---- Dataset ---- #\n",
    "    \n",
    "    tile_size = 640\n",
    "    tile_average_step = 320\n",
    "    tile_scale = 0.25\n",
    "    tile_min_score = 0.25  \n",
    "\n",
    "#assert args.server!='local', 'not implement'\n",
    "device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "round-stranger",
   "metadata": {
    "code_folding": [
     2,
     41,
     189,
     199,
     204,
     214,
     218
    ]
   },
   "outputs": [],
   "source": [
    "all_dice_dict={}\n",
    "\n",
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    total = 0 ; dice=0 ; loss=0 ; tp = 0 ; tn = 0\n",
    "    dice2=0 ; loss2=0\n",
    "    valid_probability, valid_probability2, valid_probability3 = [],[],[]\n",
    "    valid_mask, valid_mask2, valid_mask3 = [],[],[]\n",
    "\n",
    "    net = net.eval()\n",
    "\n",
    "    #start_timer = timer()\n",
    "    with torch.no_grad():\n",
    "        for t, batch in enumerate(valid_loader):\n",
    "            mask  = batch['mask']\n",
    "            image = batch['image'].to(device)\n",
    "            \n",
    "            if args.clf_head:\n",
    "                logit, _ = net(image) # seg, clf\n",
    "            else:\n",
    "                logit = net(image)#data_parallel(net, image) #net(input)#\n",
    "            probability = torch.sigmoid(logit)\n",
    "                \n",
    "            valid_probability.append(probability.data.cpu().numpy())\n",
    "            valid_mask.append(mask.data.cpu().numpy())\n",
    "\n",
    "    #assert(valid_num == len(valid_loader.dataset)) # drop last True이면 assert되는거임\n",
    "    probability = np.concatenate(valid_probability)\n",
    "    mask = np.concatenate(valid_mask)\n",
    "    if args.loss =='bce':\n",
    "        loss = np_binary_cross_entropy_loss(probability, mask)\n",
    "    elif args.loss =='lovasz':\n",
    "        loss = 0\n",
    "    \n",
    "    dice = [np_dice_score2(probability, mask, round(th, 2)) for th in np.arange(0.1, 0.7, 0.05)]\n",
    "    #tp, tn = np_accuracy(probability, mask)\n",
    "\n",
    "    return np.array(dice)#[dice_dict, loss,  tp, tn]\n",
    "\n",
    "\n",
    "def gen_val_image(args):\n",
    "    out_dir = args.model_path[0].split('checkpoint')[0]\n",
    "\n",
    "    ## setup  ----------------------------------------\n",
    "    for f in ['checkpoint','train','valid','backup'] : os.makedirs(out_dir +'/'+f, exist_ok=True)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.val.txt',mode='a')\n",
    "\n",
    "    # my log argument\n",
    "    print_args(args, log)\n",
    "\n",
    "    submit_dir = out_dir + '/valid/%s-mean'%(args.server)\n",
    "    os.makedirs(submit_dir,exist_ok=True)\n",
    "\n",
    "    #\n",
    "    for fold in range(5):\n",
    "        scaler = GradScaler()\n",
    "        net = SegModel() \n",
    "        net = net.to(device)\n",
    "        state_dict = torch.load(args.model_path[fold], map_location=lambda storage, loc: storage)['state_dict']\n",
    "        net.load_state_dict(state_dict,strict=True)  #True\n",
    "        net = net.eval()\n",
    "\n",
    "        #log.write('schduler\\n  %s\\n'%(schduler))\n",
    "        log.write('\\n')\n",
    "\n",
    "        #----      \n",
    "\n",
    "        # make validation predict images\n",
    "        tile_size = args.tile_size #320\n",
    "        tile_average_step = args.tile_average_step#320 #192\n",
    "        tile_scale = args.tile_scale\n",
    "        tile_min_score = args.tile_min_score\n",
    "        #\n",
    "        a = pd.read_csv('../hubmap/tile/0.25_320_160_train_fold/image_id_split.csv')\n",
    "        b = a[a['fold']==fold]\n",
    "        valid_image_id = b['tile_id'].apply(lambda x : x.split('/')[-2]).unique()\n",
    "\n",
    "        #\n",
    "        start_timer = timer()\n",
    "        for id in valid_image_id:\n",
    "            image_file = data_dir + '/train/%s.tiff' % id\n",
    "            image = read_tiff(image_file)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            json_file  = data_dir + '/train/%s-anatomical-structure.json' % id\n",
    "            structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)   \n",
    "            mask_file = data_dir + '/train/%s.mask.png' % id\n",
    "            mask  = read_mask(mask_file)\n",
    "\n",
    "            #--- predict here!  ---\n",
    "            tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "\n",
    "            tile_image = tile['tile_image']\n",
    "            tile_image = np.stack(tile_image)[..., ::-1]\n",
    "            tile_image = np.ascontiguousarray(tile_image.transpose(0,3,1,2))\n",
    "            tile_image = tile_image.astype(np.float32)/255\n",
    "            print(tile_image.shape)\n",
    "            tile_probability = []\n",
    "\n",
    "            batch = np.array_split(tile_image, len(tile_image)//4)\n",
    "            for t,m in enumerate(batch):\n",
    "                print('\\r %s  %d / %d   %s'%(id, t, len(batch), time_to_str(timer() - start_timer, 'sec')), end='',flush=True)\n",
    "                m = torch.from_numpy(m).to(device)\n",
    "\n",
    "                p = []\n",
    "                with torch.no_grad():\n",
    "                    logit = net(m)\n",
    "                    p.append(torch.sigmoid(logit))\n",
    "                    if args.server == 'local':\n",
    "                        if 0: #tta here\n",
    "                            #logit = data_parallel(net, m.flip(dims=(2,)))\n",
    "                            logit = net(m.flip(dims=(2,)))\n",
    "                            p.append(torch.sigmoid(logit.flip(dims=(2,))))\n",
    "\n",
    "                            #logit = data_parallel(net, m.flip(dims=(3,)))\n",
    "                            logit = net(m.flip(dims=(3,)))\n",
    "                            p.append(torch.sigmoid(logit.flip(dims=(3,))))\n",
    "                        p = torch.cat(p)\n",
    "\n",
    "                tile_probability.append(p.data.cpu().numpy())\n",
    "            print('\\r' , end='',flush=True)\n",
    "            log.write('%s  %d / %d   %s\\n'%(id, t, len(batch), time_to_str(timer() - start_timer, 'sec')))\n",
    "\n",
    "            tile_probability = np.concatenate(tile_probability).squeeze(1)\n",
    "            height, width = tile['image_small'].shape[:2]\n",
    "            probability = to_mask(tile_probability, tile['coord'], height, width,\n",
    "                                  tile_scale, tile_size, tile_average_step, tile_min_score,\n",
    "                                  aggregate='mean')\n",
    "            #\n",
    "            truth = tile['mask_small'].astype(np.float32)/255\n",
    "            overlay = np.dstack([\n",
    "                np.zeros_like(truth),\n",
    "                probability, #green\n",
    "                truth, #red\n",
    "            ])\n",
    "\n",
    "            image_small = tile['image_small'].astype(np.float32)/255\n",
    "            #predict = (probability>thres).astype(np.float32)\n",
    "            overlay1 = 1-(1-image_small)*(1-overlay)\n",
    "            overlay2 = image_small.copy()\n",
    "            overlay2 = draw_contour_overlay(overlay2, tile['structure_small'], color=(1, 1, 1), thickness=3)\n",
    "            overlay2 = draw_contour_overlay(overlay2, truth, color=(0, 0, 1), thickness=8)\n",
    "            overlay2 = draw_contour_overlay(overlay2, probability, color=(0, 1, 0), thickness=3)\n",
    "\n",
    "            if 1:\n",
    "                #cv2.imwrite(submit_dir+'/%s.image_small.png'%id, (image_small*255).astype(np.uint8))\n",
    "                #cv2.imwrite(submit_dir+'/%s.probability.png'%id, (probability*255).astype(np.uint8))\n",
    "                #cv2.imwrite(submit_dir+'/%s.predict.png'%id, (predict*255).astype(np.uint8))\n",
    "                #cv2.imwrite(submit_dir+'/%s.overlay.png'%id, (overlay*255).astype(np.uint8))\n",
    "                #cv2.imwrite(submit_dir+'/%s.overlay1.png'%id, (overlay1*255).astype(np.uint8))\n",
    "                cv2.imwrite(submit_dir+'/%s.overlay2.png'%id, (overlay2*255).astype(np.uint8))\n",
    "def eval_image(args):\n",
    "\n",
    "    #-----------dataset split --------------------#\n",
    "    tile_id = []\n",
    "    image_dir_ = f'{args.dataset}'#'0.25_320_160_train'\n",
    "    image_dir=[image_dir_, ] # pseudo할때 뒤에 추가\n",
    "    \n",
    "    image_dir_val_ = f'{args.val_dataset}'#'0.25_320_320_val'\n",
    "    image_dir_val=[image_dir_val_, ]\n",
    "    \n",
    "    for i in range(len(image_dir)):\n",
    "        df = pd.read_csv(data_dir + '/tile/%s/image_id_split.csv'% (image_dir[i]) )\n",
    "\n",
    "    for i in range(len(image_dir_val)):\n",
    "        df2 = pd.read_csv(data_dir + '/tile/%s/image_id_split.csv'% (image_dir_val[i]) )\n",
    "    df2['img_id'] = df2['tile_id'].apply(lambda x: x.split('/')[-2])\n",
    "        \n",
    "    all_dice = []\n",
    "    for model_idx in range(5):\n",
    "        for n_fold in range(5):\n",
    "\n",
    "            train_df = df[df['fold']!= n_fold].reset_index(drop=True)\n",
    "            val_df = df2[df2['fold']== n_fold].reset_index(drop=True).copy()\n",
    "\n",
    "            # validation loader 3개 만들기 위함\n",
    "            unique_value = val_df['tile_id'].apply(lambda x: x.split('/')[-2]).unique() #[valid_id1, valid_id2, valid_id3 ]\n",
    "            val_img_id1 = unique_value[0] ; val_img_id2 = unique_value[1] ; val_img_id3= unique_value[2]\n",
    "            val_df1= val_df[val_df['img_id']==val_img_id1].reset_index(drop=True)\n",
    "            val_df2= val_df[val_df['img_id']==val_img_id2].reset_index(drop=True)\n",
    "            val_df3= val_df[val_df['img_id']==val_img_id3].reset_index(drop=True)\n",
    "            #####################################################\n",
    "            # val loader1\n",
    "            valid_dataset1 = HuDataset(\n",
    "                df = val_df1\n",
    "                ,\n",
    "            )\n",
    "            valid_loader1 = DataLoader(\n",
    "                valid_dataset1,\n",
    "                sampler = SequentialSampler(valid_dataset1),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 4,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            # val loader2\n",
    "            valid_dataset2 = HuDataset(\n",
    "                df = val_df2\n",
    "                ,\n",
    "            )\n",
    "\n",
    "            valid_loader2 = DataLoader(\n",
    "                valid_dataset2,\n",
    "                sampler = SequentialSampler(valid_dataset2),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 4,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            # val loader3\n",
    "            valid_dataset3 = HuDataset(\n",
    "                df = val_df3\n",
    "                ,\n",
    "            )\n",
    "            valid_loader3 = DataLoader(\n",
    "                valid_dataset3,\n",
    "                sampler = SequentialSampler(valid_dataset3),\n",
    "                batch_size  = args.batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 4,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "            )\n",
    "            # ------------------------\n",
    "            #  Model\n",
    "            # ------------------------\n",
    "\n",
    "            scaler = GradScaler()\n",
    "            models = SegModel() \n",
    "            net = models[model_idx].to(device)\n",
    "            state_dict = torch.load(args.model_path[n_fold], map_location=lambda storage, loc: storage)['state_dict']\n",
    "            # 병렬처리를 했으면 앞에 module이 붙으므로 키를 바꿔줘야 한다. \n",
    "            for key in list(state_dict.keys()):\n",
    "                if \"module.\" in key:\n",
    "                    state_dict[key.replace(\"module.\", \"\")] = state_dict[key]\n",
    "                    del state_dict[key]\n",
    "            net.load_state_dict(state_dict,strict=True)  #True\n",
    "            net = net.eval()\n",
    "\n",
    "            print(\"model load success!!!\")\n",
    "            # scheudler\n",
    "            valid_loss1 = do_valid(net, valid_loader1) #\n",
    "            valid_loss2 = do_valid(net, valid_loader2)\n",
    "            valid_loss3 = do_valid(net, valid_loader3)\n",
    "            valid_loss = (valid_loss1 + valid_loss2 + valid_loss3)/3\n",
    "\n",
    "            all_dice.append(valid_loss)\n",
    "\n",
    "    dice = sum(all_dice)/len(all_dice)\n",
    "    for n, th in enumerate(np.arange(0.1, 0.7, 0.05)):\n",
    "        th = round(th, 2)\n",
    "        print(f'th:{th}, dice score : {dice[n] : .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "documented-enforcement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success!!!\n",
      "model load success!!!\n",
      "model load success!!!\n",
      "model load success!!!\n",
      "model load success!!!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FPN:\n\tMissing key(s) in state_dict: \"encoder.features.conv0.weight\", \"encoder.features.norm0.weight\", \"encoder.features.norm0.bias\", \"encoder.features.norm0.running_mean\", \"encoder.features.norm0.running_var\", \"encoder.features.denseblock1.denselayer1.norm1.weight\", \"encoder.features.denseblock1.denselayer1.norm1.bias\", \"encoder.features.denseblock1.denselayer1.norm1.running_mean\", \"encoder.features.denseblock1.denselayer1.norm1.running_var\", \"encoder.features.denseblock1.denselayer1.conv1.weight\", \"encoder.features.denseblock1.denselayer1.norm2.weight\", \"encoder.features.denseblock1.denselayer1.norm2.bias\", \"encoder.features.denseblock1.denselayer1.norm2.running_mean\", \"encoder.features.denseblock1.denselayer1.norm2.running_var\", \"encoder.features.denseblock1.denselayer1.conv2.weight\", \"encoder.features.denseblock1.denselayer2.norm1.weight\", \"encoder.features.denseblock1.denselayer2.norm1.bias\", \"encoder.features.denseblock1.denselayer2.norm1.running_mean\", \"encoder.features.denseblock1.denselayer2.norm1.running_var\", \"encoder.features.denseblock1.denselayer2.conv1.weight\", \"encoder.features.denseblock1.denselayer2.norm2.weight\", \"encoder.features.denseblock1.denselayer2.norm2.bias\", \"encoder.features.denseblock1.denselayer2.norm2.running_mean\", \"encoder.features.denseblock1.denselayer2.norm2.running_var\", \"encoder.features.denseblock1.denselayer2.conv2.weight\", \"encoder.features.denseblock1.denselayer3.norm1.weight\", \"encoder.features.denseblock1.denselayer3.norm1.bias\", \"encoder.features.denseblock1.denselayer3.norm1.running_mean\", \"encoder.features.denseblock1.denselayer3.norm1.running_var\", \"encoder.features.denseblock1.denselayer3.conv1.weight\", \"encoder.features.denseblock1.denselayer3.norm2.weight\", \"encoder.features.denseblock1.denselayer3.norm2.bias\", \"encoder.features.denseblock1.denselayer3.norm2.running_mean\", \"encoder.features.denseblock1.denselayer3.norm2.running_var\", \"encoder.features.denseblock1.denselayer3.conv2.weight\", \"encoder.features.denseblock1.denselayer4.norm1.weight\", \"encoder.features.denseblock1.denselayer4.norm1.bias\", \"encoder.features.denseblock1.denselayer4.norm1.running_mean\", \"encoder.features.denseblock1.denselayer4.norm1.running_var\", \"encoder.features.denseblock1.denselayer4.conv1.weight\", \"encoder.features.denseblock1.denselayer4.norm2.weight\", \"encoder.features.denseblock1.denselayer4.norm2.bias\", \"encoder.features.denseblock1.denselayer4.norm2.running_mean\", \"encoder.features.denseblock1.denselayer4.norm2.running_var\", \"encoder.features.denseblock1.denselayer4.conv2.weight\", \"encoder.features.denseblock1.denselayer5.norm1.weight\", \"encoder.features.denseblock1.denselayer5.norm1.bias\", \"encoder.features.denseblock1.denselayer5.norm1.running_mean\", \"encoder.features.denseblock1.denselayer5.norm1.running_var\", \"encoder.features.denseblock1.denselayer5.conv1.weight\", \"encoder.features.denseblock1.denselayer5.norm2.weight\", \"encoder.features.denseblock1.denselayer5.norm2.bias\", \"encoder.features.denseblock1.denselayer5.norm2.running_mean\", \"encoder.features.denseblock1.denselayer5.norm2.running_var\", \"encoder.features.denseblock1.denselayer5.conv2.weight\", \"encoder.features.denseblock1.denselayer6.norm1.weight\", \"encoder.features.denseblock1.denselayer6.norm1.bias\", \"encoder.features.denseblock1.denselayer6.norm1.running_mean\", \"encoder.features.denseblock1.denselayer6.norm1.running_var\", \"encoder.features.denseblock1.denselayer6.conv1.weight\", \"encoder.features.denseblock1.denselayer6.norm2.weight\", \"encoder.features.denseblock1.denselayer6.norm2.bias\", \"encoder.features.denseblock1.denselayer6.norm2.running_mean\", \"encoder.features.denseblock1.denselayer6.norm2.running_var\", \"encoder.features.denseblock1.denselayer6.conv2.weight\", \"encoder.features.transition1.norm.weight\", \"encoder.features.transition1.norm.bias\", \"encoder.features.transition1.norm.running_mean\", \"encoder.features.transition1.norm.running_var\", \"encoder.features.transition1.conv.weight\", \"encoder.features.denseblock2.denselayer1.norm1.weight\", \"encoder.features.denseblock2.denselayer1.norm1.bias\", \"encoder.features.denseblock2.denselayer1.norm1.running_mean\", \"encoder.features.denseblock2.denselayer1.norm1.running_var\", \"encoder.features.denseblock2.denselayer1.conv1.weight\", \"encoder.features.denseblock2.denselayer1.norm2.weight\", \"encoder.features.denseblock2.denselayer1.norm2.bias\", \"encoder.features.denseblock2.denselayer1.norm2.running_mean\", \"encoder.features.denseblock2.denselayer1.norm2.running_var\", \"encoder.features.denseblock2.denselayer1.conv2.weight\", \"encoder.features.denseblock2.denselayer2.norm1.weight\", \"encoder.features.denseblock2.denselayer2.norm1.bias\", \"encoder.features.denseblock2.denselayer2.norm1.running_mean\", \"encoder.features.denseblock2.denselayer2.norm1.running_var\", \"encoder.features.denseblock2.denselayer2.conv1.weight\", \"encoder.features.denseblock2.denselayer2.norm2.weight\", \"encoder.features.denseblock2.denselayer2.norm2.bias\", \"encoder.features.denseblock2.denselayer2.norm2.running_mean\", \"encoder.features.denseblock2.denselayer2.norm2.running_var\", \"encoder.features.denseblock2.denselayer2.conv2.weight\", \"encoder.features.denseblock2.denselayer3.norm1.weight\", \"encoder.features.denseblock2.denselayer3.norm1.bias\", \"encoder.features.denseblock2.denselayer3.norm1.running_mean\", \"encoder.features.denseblock2.denselayer3.norm1.running_var\", \"encoder.features.denseblock2.denselayer3.conv1.weight\", \"encoder.features.denseblock2.denselayer3.norm2.weight\", \"encoder.features.denseblock2.denselayer3.norm2.bias\", \"encoder.features.denseblock2.denselayer3.norm2.running_mean\", \"encoder.features.denseblock2.denselayer3.norm2.running_var\", \"encoder.features.denseblock2.denselayer3.conv2.weight\", \"encoder.features.denseblock2.denselayer4.norm1.weight\", \"encoder.features.denseblock2.denselayer4.norm1.bias\", \"encoder.features.denseblock2.denselayer4.norm1.running_mean\", \"encoder.features.denseblock2.denselayer4.norm1.running_var\", \"encoder.features.denseblock2.denselayer4.conv1.weight\", \"encoder.features.denseblock2.denselayer4.norm2.weight\", \"encoder.features.denseblock2.denselayer4.norm2.bias\", \"encoder.features.denseblock2.denselayer4.norm2.running_mean\", \"encoder.features.denseblock2.denselayer4.norm2.running_var\", \"encoder.features.denseblock2.denselayer4.conv2.weight\", \"encoder.features.denseblock2.denselayer5.norm1.weight\", \"encoder.features.denseblock2.denselayer5.norm1.bias\", \"encoder.features.denseblock2.denselayer5.norm1.running_mean\", \"encoder.features.denseblock2.denselayer5.norm1.running_var\", \"encoder.features.denseblock2.denselayer5.conv1.weight\", \"encoder.features.denseblock2.denselayer5.norm2.weight\", \"encoder.features.denseblock2.denselayer5.norm2.bias\", \"encoder.features.denseblock2.denselayer5.norm2.running_mean\", \"encoder.features.denseblock2.denselayer5.norm2.running_var\", \"encoder.features.denseblock2.denselayer5.conv2.weight\", \"encoder.features.denseblock2.denselayer6.norm1.weight\", \"encoder.features.denseblock2.denselayer6.norm1.bias\", \"encoder.features.denseblock2.denselayer6.norm1.running_mean\", \"encoder.features.denseblock2.denselayer6.norm1.running_var\", \"encoder.features.denseblock2.denselayer6.conv1.weight\", \"encoder.features.denseblock2.denselayer6.norm2.weight\", \"encoder.features.denseblock2.denselayer6.norm2.bias\", \"encoder.features.denseblock2.denselayer6.norm2.running_mean\", \"encoder.features.denseblock2.denselayer6.norm2.running_var\", \"encoder.features.denseblock2.denselayer6.conv2.weight\", \"encoder.features.denseblock2.denselayer7.norm1.weight\", \"encoder.features.denseblock2.denselayer7.norm1.bias\", \"encoder.features.denseblock2.denselayer7.norm1.running_mean\", \"encoder.features.denseblock2.denselayer7.norm1.running_var\", \"encoder.features.denseblock2.denselayer7.conv1.weight\", \"encoder.features.denseblock2.denselayer7.norm2.weight\", \"encoder.features.denseblock2.denselayer7.norm2.bias\", \"encoder.features.denseblock2.denselayer7.norm2.running_mean\", \"encoder.features.denseblock2.denselayer7.norm2.running_var\", \"encoder.features.denseblock2.denselayer7.conv2.weight\", \"encoder.features.denseblock2.denselayer8.norm1.weight\", \"encoder.features.denseblock2.denselayer8.norm1.bias\", \"encoder.features.denseblock2.denselayer8.norm1.running_mean\", \"encoder.features.denseblock2.denselayer8.norm1.running_var\", \"encoder.features.denseblock2.denselayer8.conv1.weight\", \"encoder.features.denseblock2.denselayer8.norm2.weight\", \"encoder.features.denseblock2.denselayer8.norm2.bias\", \"encoder.features.denseblock2.denselayer8.norm2.running_mean\", \"encoder.features.denseblock2.denselayer8.norm2.running_var\", \"encoder.features.denseblock2.denselayer8.conv2.weight\", \"encoder.features.denseblock2.denselayer9.norm1.weight\", \"encoder.features.denseblock2.denselayer9.norm1.bias\", \"encoder.features.denseblock2.denselayer9.norm1.running_mean\", \"encoder.features.denseblock2.denselayer9.norm1.running_var\", \"encoder.features.denseblock2.denselayer9.conv1.weight\", \"encoder.features.denseblock2.denselayer9.norm2.weight\", \"encoder.features.denseblock2.denselayer9.norm2.bias\", \"encoder.features.denseblock2.denselayer9.norm2.running_mean\", \"encoder.features.denseblock2.denselayer9.norm2.running_var\", \"encoder.features.denseblock2.denselayer9.conv2.weight\", \"encoder.features.denseblock2.denselayer10.norm1.weight\", \"encoder.features.denseblock2.denselayer10.norm1.bias\", \"encoder.features.denseblock2.denselayer10.norm1.running_mean\", \"encoder.features.denseblock2.denselayer10.norm1.running_var\", \"encoder.features.denseblock2.denselayer10.conv1.weight\", \"encoder.features.denseblock2.denselayer10.norm2.weight\", \"encoder.features.denseblock2.denselayer10.norm2.bias\", \"encoder.features.denseblock2.denselayer10.norm2.running_mean\", \"encoder.features.denseblock2.denselayer10.norm2.running_var\", \"encoder.features.denseblock2.denselayer10.conv2.weight\", \"encoder.features.denseblock2.denselayer11.norm1.weight\", \"encoder.features.denseblock2.denselayer11.norm1.bias\", \"encoder.features.denseblock2.denselayer11.norm1.running_mean\", \"encoder.features.denseblock2.denselayer11.norm1.running_var\", \"encoder.features.denseblock2.denselayer11.conv1.weight\", \"encoder.features.denseblock2.denselayer11.norm2.weight\", \"encoder.features.denseblock2.denselayer11.norm2.bias\", \"encoder.features.denseblock2.denselayer11.norm2.running_mean\", \"encoder.features.denseblock2.denselayer11.norm2.running_var\", \"encoder.features.denseblock2.denselayer11.conv2.weight\", \"encoder.features.denseblock2.denselayer12.norm1.weight\", \"encoder.features.denseblock2.denselayer12.norm1.bias\", \"encoder.features.denseblock2.denselayer12.norm1.running_mean\", \"encoder.features.denseblock2.denselayer12.norm1.running_var\", \"encoder.features.denseblock2.denselayer12.conv1.weight\", \"encoder.features.denseblock2.denselayer12.norm2.weight\", \"encoder.features.denseblock2.denselayer12.norm2.bias\", \"encoder.features.denseblock2.denselayer12.norm2.running_mean\", \"encoder.features.denseblock2.denselayer12.norm2.running_var\", \"encoder.features.denseblock2.denselayer12.conv2.weight\", \"encoder.features.transition2.norm.weight\", \"encoder.features.transition2.norm.bias\", \"encoder.features.transition2.norm.running_mean\", \"encoder.features.transition2.norm.running_var\", \"encoder.features.transition2.conv.weight\", \"encoder.features.denseblock3.denselayer1.norm1.weight\", \"encoder.features.denseblock3.denselayer1.norm1.bias\", \"encoder.features.denseblock3.denselayer1.norm1.running_mean\", \"encoder.features.denseblock3.denselayer1.norm1.running_var\", \"encoder.features.denseblock3.denselayer1.conv1.weight\", \"encoder.features.denseblock3.denselayer1.norm2.weight\", \"encoder.features.denseblock3.denselayer1.norm2.bias\", \"encoder.features.denseblock3.denselayer1.norm2.running_mean\", \"encoder.features.denseblock3.denselayer1.norm2.running_var\", \"encoder.features.denseblock3.denselayer1.conv2.weight\", \"encoder.features.denseblock3.denselayer2.norm1.weight\", \"encoder.features.denseblock3.denselayer2.norm1.bias\", \"encoder.features.denseblock3.denselayer2.norm1.running_mean\", \"encoder.features.denseblock3.denselayer2.norm1.running_var\", \"encoder.features.denseblock3.denselayer2.conv1.weight\", \"encoder.features.denseblock3.denselayer2.norm2.weight\", \"encoder.features.denseblock3.denselayer2.norm2.bias\", \"encoder.features.denseblock3.denselayer2.norm2.running_mean\", \"encoder.features.denseblock3.denselayer2.norm2.running_var\", \"encoder.features.denseblock3.denselayer2.conv2.weight\", \"encoder.features.denseblock3.denselayer3.norm1.weight\", \"encoder.features.denseblock3.denselayer3.norm1.bias\", \"encoder.features.denseblock3.denselayer3.norm1.running_mean\", \"encoder.features.denseblock3.denselayer3.norm1.running_var\", \"encoder.features.denseblock3.denselayer3.conv1.weight\", \"encoder.features.denseblock3.denselayer3.norm2.weight\", \"encoder.features.denseblock3.denselayer3.norm2.bias\", \"encoder.features.denseblock3.denselayer3.norm2.running_mean\", \"encoder.features.denseblock3.denselayer3.norm2.running_var\", \"encoder.features.denseblock3.denselayer3.conv2.weight\", \"encoder.features.denseblock3.denselayer4.norm1.weight\", \"encoder.features.denseblock3.denselayer4.norm1.bias\", \"encoder.features.denseblock3.denselayer4.norm1.running_mean\", \"encoder.features.denseblock3.denselayer4.norm1.running_var\", \"encoder.features.denseblock3.denselayer4.conv1.weight\", \"encoder.features.denseblock3.denselayer4.norm2.weight\", \"encoder.features.denseblock3.denselayer4.norm2.bias\", \"encoder.features.denseblock3.denselayer4.norm2.running_mean\", \"encoder.features.denseblock3.denselayer4.norm2.running_var\", \"encoder.features.denseblock3.denselayer4.conv2.weight\", \"encoder.features.denseblock3.denselayer5.norm1.weight\", \"encoder.features.denseblock3.denselayer5.norm1.bias\", \"encoder.features.denseblock3.denselayer5.norm1.running_mean\", \"encoder.features.denseblock3.denselayer5.norm1.running_var\", \"encoder.features.denseblock3.denselayer5.conv1.weight\", \"encoder.features.denseblock3.denselayer5.norm2.weight\", \"encoder.features.denseblock3.denselayer5.norm2.bias\", \"encoder.features.denseblock3.denselayer5.norm2.running_mean\", \"encoder.features.denseblock3.denselayer5.norm2.running_var\", \"encoder.features.denseblock3.denselayer5.conv2.weight\", \"encoder.features.denseblock3.denselayer6.norm1.weight\", \"encoder.features.denseblock3.denselayer6.norm1.bias\", \"encoder.features.denseblock3.denselayer6.norm1.running_mean\", \"encoder.features.denseblock3.denselayer6.norm1.running_var\", \"encoder.features.denseblock3.denselayer6.conv1.weight\", \"encoder.features.denseblock3.denselayer6.norm2.weight\", \"encoder.features.denseblock3.denselayer6.norm2.bias\", \"encoder.features.denseblock3.denselayer6.norm2.running_mean\", \"encoder.features.denseblock3.denselayer6.norm2.running_var\", \"encoder.features.denseblock3.denselayer6.conv2.weight\", \"encoder.features.denseblock3.denselayer7.norm1.weight\", \"encoder.features.denseblock3.denselayer7.norm1.bias\", \"encoder.features.denseblock3.denselayer7.norm1.running_mean\", \"encoder.features.denseblock3.denselayer7.norm1.running_var\", \"encoder.features.denseblock3.denselayer7.conv1.weight\", \"encoder.features.denseblock3.denselayer7.norm2.weight\", \"encoder.features.denseblock3.denselayer7.norm2.bias\", \"encoder.features.denseblock3.denselayer7.norm2.running_mean\", \"encoder.features.denseblock3.denselayer7.norm2.running_var\", \"encoder.features.denseblock3.denselayer7.conv2.weight\", \"encoder.features.denseblock3.denselayer8.norm1.weight\", \"encoder.features.denseblock3.denselayer8.norm1.bias\", \"encoder.features.denseblock3.denselayer8.norm1.running_mean\", \"encoder.features.denseblock3.denselayer8.norm1.running_var\", \"encoder.features.denseblock3.denselayer8.conv1.weight\", \"encoder.features.denseblock3.denselayer8.norm2.weight\", \"encoder.features.denseblock3.denselayer8.norm2.bias\", \"encoder.features.denseblock3.denselayer8.norm2.running_mean\", \"encoder.features.denseblock3.denselayer8.norm2.running_var\", \"encoder.features.denseblock3.denselayer8.conv2.weight\", \"encoder.features.denseblock3.denselayer9.norm1.weight\", \"encoder.features.denseblock3.denselayer9.norm1.bias\", \"encoder.features.denseblock3.denselayer9.norm1.running_mean\", \"encoder.features.denseblock3.denselayer9.norm1.running_var\", \"encoder.features.denseblock3.denselayer9.conv1.weight\", \"encoder.features.denseblock3.denselayer9.norm2.weight\", \"encoder.features.denseblock3.denselayer9.norm2.bias\", \"encoder.features.denseblock3.denselayer9.norm2.running_mean\", \"encoder.features.denseblock3.denselayer9.norm2.running_var\", \"encoder.features.denseblock3.denselayer9.conv2.weight\", \"encoder.features.denseblock3.denselayer10.norm1.weight\", \"encoder.features.denseblock3.denselayer10.norm1.bias\", \"encoder.features.denseblock3.denselayer10.norm1.running_mean\", \"encoder.features.denseblock3.denselayer10.norm1.running_var\", \"encoder.features.denseblock3.denselayer10.conv1.weight\", \"encoder.features.denseblock3.denselayer10.norm2.weight\", \"encoder.features.denseblock3.denselayer10.norm2.bias\", \"encoder.features.denseblock3.denselayer10.norm2.running_mean\", \"encoder.features.denseblock3.denselayer10.norm2.running_var\", \"encoder.features.denseblock3.denselayer10.conv2.weight\", \"encoder.features.denseblock3.denselayer11.norm1.weight\", \"encoder.features.denseblock3.denselayer11.norm1.bias\", \"encoder.features.denseblock3.denselayer11.norm1.running_mean\", \"encoder.features.denseblock3.denselayer11.norm1.running_var\", \"encoder.features.denseblock3.denselayer11.conv1.weight\", \"encoder.features.denseblock3.denselayer11.norm2.weight\", \"encoder.features.denseblock3.denselayer11.norm2.bias\", \"encoder.features.denseblock3.denselayer11.norm2.running_mean\", \"encoder.features.denseblock3.denselayer11.norm2.running_var\", \"encoder.features.denseblock3.denselayer11.conv2.weight\", \"encoder.features.denseblock3.denselayer12.norm1.weight\", \"encoder.features.denseblock3.denselayer12.norm1.bias\", \"encoder.features.denseblock3.denselayer12.norm1.running_mean\", \"encoder.features.denseblock3.denselayer12.norm1.running_var\", \"encoder.features.denseblock3.denselayer12.conv1.weight\", \"encoder.features.denseblock3.denselayer12.norm2.weight\", \"encoder.features.denseblock3.denselayer12.norm2.bias\", \"encoder.features.denseblock3.denselayer12.norm2.running_mean\", \"encoder.features.denseblock3.denselayer12.norm2.running_var\", \"encoder.features.denseblock3.denselayer12.conv2.weight\", \"encoder.features.denseblock3.denselayer13.norm1.weight\", \"encoder.features.denseblock3.denselayer13.norm1.bias\", \"encoder.features.denseblock3.denselayer13.norm1.running_mean\", \"encoder.features.denseblock3.denselayer13.norm1.running_var\", \"encoder.features.denseblock3.denselayer13.conv1.weight\", \"encoder.features.denseblock3.denselayer13.norm2.weight\", \"encoder.features.denseblock3.denselayer13.norm2.bias\", \"encoder.features.denseblock3.denselayer13.norm2.running_mean\", \"encoder.features.denseblock3.denselayer13.norm2.running_var\", \"encoder.features.denseblock3.denselayer13.conv2.weight\", \"encoder.features.denseblock3.denselayer14.norm1.weight\", \"encoder.features.denseblock3.denselayer14.norm1.bias\", \"encoder.features.denseblock3.denselayer14.norm1.running_mean\", \"encoder.features.denseblock3.denselayer14.norm1.running_var\", \"encoder.features.denseblock3.denselayer14.conv1.weight\", \"encoder.features.denseblock3.denselayer14.norm2.weight\", \"encoder.features.denseblock3.denselayer14.norm2.bias\", \"encoder.features.denseblock3.denselayer14.norm2.running_mean\", \"encoder.features.denseblock3.denselayer14.norm2.running_var\", \"encoder.features.denseblock3.denselayer14.conv2.weight\", \"encoder.features.denseblock3.denselayer15.norm1.weight\", \"encoder.features.denseblock3.denselayer15.norm1.bias\", \"encoder.features.denseblock3.denselayer15.norm1.running_mean\", \"encoder.features.denseblock3.denselayer15.norm1.running_var\", \"encoder.features.denseblock3.denselayer15.conv1.weight\", \"encoder.features.denseblock3.denselayer15.norm2.weight\", \"encoder.features.denseblock3.denselayer15.norm2.bias\", \"encoder.features.denseblock3.denselayer15.norm2.running_mean\", \"encoder.features.denseblock3.denselayer15.norm2.running_var\", \"encoder.features.denseblock3.denselayer15.conv2.weight\", \"encoder.features.denseblock3.denselayer16.norm1.weight\", \"encoder.features.denseblock3.denselayer16.norm1.bias\", \"encoder.features.denseblock3.denselayer16.norm1.running_mean\", \"encoder.features.denseblock3.denselayer16.norm1.running_var\", \"encoder.features.denseblock3.denselayer16.conv1.weight\", \"encoder.features.denseblock3.denselayer16.norm2.weight\", \"encoder.features.denseblock3.denselayer16.norm2.bias\", \"encoder.features.denseblock3.denselayer16.norm2.running_mean\", \"encoder.features.denseblock3.denselayer16.norm2.running_var\", \"encoder.features.denseblock3.denselayer16.conv2.weight\", \"encoder.features.denseblock3.denselayer17.norm1.weight\", \"encoder.features.denseblock3.denselayer17.norm1.bias\", \"encoder.features.denseblock3.denselayer17.norm1.running_mean\", \"encoder.features.denseblock3.denselayer17.norm1.running_var\", \"encoder.features.denseblock3.denselayer17.conv1.weight\", \"encoder.features.denseblock3.denselayer17.norm2.weight\", \"encoder.features.denseblock3.denselayer17.norm2.bias\", \"encoder.features.denseblock3.denselayer17.norm2.running_mean\", \"encoder.features.denseblock3.denselayer17.norm2.running_var\", \"encoder.features.denseblock3.denselayer17.conv2.weight\", \"encoder.features.denseblock3.denselayer18.norm1.weight\", \"encoder.features.denseblock3.denselayer18.norm1.bias\", \"encoder.features.denseblock3.denselayer18.norm1.running_mean\", \"encoder.features.denseblock3.denselayer18.norm1.running_var\", \"encoder.features.denseblock3.denselayer18.conv1.weight\", \"encoder.features.denseblock3.denselayer18.norm2.weight\", \"encoder.features.denseblock3.denselayer18.norm2.bias\", \"encoder.features.denseblock3.denselayer18.norm2.running_mean\", \"encoder.features.denseblock3.denselayer18.norm2.running_var\", \"encoder.features.denseblock3.denselayer18.conv2.weight\", \"encoder.features.denseblock3.denselayer19.norm1.weight\", \"encoder.features.denseblock3.denselayer19.norm1.bias\", \"encoder.features.denseblock3.denselayer19.norm1.running_mean\", \"encoder.features.denseblock3.denselayer19.norm1.running_var\", \"encoder.features.denseblock3.denselayer19.conv1.weight\", \"encoder.features.denseblock3.denselayer19.norm2.weight\", \"encoder.features.denseblock3.denselayer19.norm2.bias\", \"encoder.features.denseblock3.denselayer19.norm2.running_mean\", \"encoder.features.denseblock3.denselayer19.norm2.running_var\", \"encoder.features.denseblock3.denselayer19.conv2.weight\", \"encoder.features.denseblock3.denselayer20.norm1.weight\", \"encoder.features.denseblock3.denselayer20.norm1.bias\", \"encoder.features.denseblock3.denselayer20.norm1.running_mean\", \"encoder.features.denseblock3.denselayer20.norm1.running_var\", \"encoder.features.denseblock3.denselayer20.conv1.weight\", \"encoder.features.denseblock3.denselayer20.norm2.weight\", \"encoder.features.denseblock3.denselayer20.norm2.bias\", \"encoder.features.denseblock3.denselayer20.norm2.running_mean\", \"encoder.features.denseblock3.denselayer20.norm2.running_var\", \"encoder.features.denseblock3.denselayer20.conv2.weight\", \"encoder.features.denseblock3.denselayer21.norm1.weight\", \"encoder.features.denseblock3.denselayer21.norm1.bias\", \"encoder.features.denseblock3.denselayer21.norm1.running_mean\", \"encoder.features.denseblock3.denselayer21.norm1.running_var\", \"encoder.features.denseblock3.denselayer21.conv1.weight\", \"encoder.features.denseblock3.denselayer21.norm2.weight\", \"encoder.features.denseblock3.denselayer21.norm2.bias\", \"encoder.features.denseblock3.denselayer21.norm2.running_mean\", \"encoder.features.denseblock3.denselayer21.norm2.running_var\", \"encoder.features.denseblock3.denselayer21.conv2.weight\", \"encoder.features.denseblock3.denselayer22.norm1.weight\", \"encoder.features.denseblock3.denselayer22.norm1.bias\", \"encoder.features.denseblock3.denselayer22.norm1.running_mean\", \"encoder.features.denseblock3.denselayer22.norm1.running_var\", \"encoder.features.denseblock3.denselayer22.conv1.weight\", \"encoder.features.denseblock3.denselayer22.norm2.weight\", \"encoder.features.denseblock3.denselayer22.norm2.bias\", \"encoder.features.denseblock3.denselayer22.norm2.running_mean\", \"encoder.features.denseblock3.denselayer22.norm2.running_var\", \"encoder.features.denseblock3.denselayer22.conv2.weight\", \"encoder.features.denseblock3.denselayer23.norm1.weight\", \"encoder.features.denseblock3.denselayer23.norm1.bias\", \"encoder.features.denseblock3.denselayer23.norm1.running_mean\", \"encoder.features.denseblock3.denselayer23.norm1.running_var\", \"encoder.features.denseblock3.denselayer23.conv1.weight\", \"encoder.features.denseblock3.denselayer23.norm2.weight\", \"encoder.features.denseblock3.denselayer23.norm2.bias\", \"encoder.features.denseblock3.denselayer23.norm2.running_mean\", \"encoder.features.denseblock3.denselayer23.norm2.running_var\", \"encoder.features.denseblock3.denselayer23.conv2.weight\", \"encoder.features.denseblock3.denselayer24.norm1.weight\", \"encoder.features.denseblock3.denselayer24.norm1.bias\", \"encoder.features.denseblock3.denselayer24.norm1.running_mean\", \"encoder.features.denseblock3.denselayer24.norm1.running_var\", \"encoder.features.denseblock3.denselayer24.conv1.weight\", \"encoder.features.denseblock3.denselayer24.norm2.weight\", \"encoder.features.denseblock3.denselayer24.norm2.bias\", \"encoder.features.denseblock3.denselayer24.norm2.running_mean\", \"encoder.features.denseblock3.denselayer24.norm2.running_var\", \"encoder.features.denseblock3.denselayer24.conv2.weight\", \"encoder.features.transition3.norm.weight\", \"encoder.features.transition3.norm.bias\", \"encoder.features.transition3.norm.running_mean\", \"encoder.features.transition3.norm.running_var\", \"encoder.features.transition3.conv.weight\", \"encoder.features.denseblock4.denselayer1.norm1.weight\", \"encoder.features.denseblock4.denselayer1.norm1.bias\", \"encoder.features.denseblock4.denselayer1.norm1.running_mean\", \"encoder.features.denseblock4.denselayer1.norm1.running_var\", \"encoder.features.denseblock4.denselayer1.conv1.weight\", \"encoder.features.denseblock4.denselayer1.norm2.weight\", \"encoder.features.denseblock4.denselayer1.norm2.bias\", \"encoder.features.denseblock4.denselayer1.norm2.running_mean\", \"encoder.features.denseblock4.denselayer1.norm2.running_var\", \"encoder.features.denseblock4.denselayer1.conv2.weight\", \"encoder.features.denseblock4.denselayer2.norm1.weight\", \"encoder.features.denseblock4.denselayer2.norm1.bias\", \"encoder.features.denseblock4.denselayer2.norm1.running_mean\", \"encoder.features.denseblock4.denselayer2.norm1.running_var\", \"encoder.features.denseblock4.denselayer2.conv1.weight\", \"encoder.features.denseblock4.denselayer2.norm2.weight\", \"encoder.features.denseblock4.denselayer2.norm2.bias\", \"encoder.features.denseblock4.denselayer2.norm2.running_mean\", \"encoder.features.denseblock4.denselayer2.norm2.running_var\", \"encoder.features.denseblock4.denselayer2.conv2.weight\", \"encoder.features.denseblock4.denselayer3.norm1.weight\", \"encoder.features.denseblock4.denselayer3.norm1.bias\", \"encoder.features.denseblock4.denselayer3.norm1.running_mean\", \"encoder.features.denseblock4.denselayer3.norm1.running_var\", \"encoder.features.denseblock4.denselayer3.conv1.weight\", \"encoder.features.denseblock4.denselayer3.norm2.weight\", \"encoder.features.denseblock4.denselayer3.norm2.bias\", \"encoder.features.denseblock4.denselayer3.norm2.running_mean\", \"encoder.features.denseblock4.denselayer3.norm2.running_var\", \"encoder.features.denseblock4.denselayer3.conv2.weight\", \"encoder.features.denseblock4.denselayer4.norm1.weight\", \"encoder.features.denseblock4.denselayer4.norm1.bias\", \"encoder.features.denseblock4.denselayer4.norm1.running_mean\", \"encoder.features.denseblock4.denselayer4.norm1.running_var\", \"encoder.features.denseblock4.denselayer4.conv1.weight\", \"encoder.features.denseblock4.denselayer4.norm2.weight\", \"encoder.features.denseblock4.denselayer4.norm2.bias\", \"encoder.features.denseblock4.denselayer4.norm2.running_mean\", \"encoder.features.denseblock4.denselayer4.norm2.running_var\", \"encoder.features.denseblock4.denselayer4.conv2.weight\", \"encoder.features.denseblock4.denselayer5.norm1.weight\", \"encoder.features.denseblock4.denselayer5.norm1.bias\", \"encoder.features.denseblock4.denselayer5.norm1.running_mean\", \"encoder.features.denseblock4.denselayer5.norm1.running_var\", \"encoder.features.denseblock4.denselayer5.conv1.weight\", \"encoder.features.denseblock4.denselayer5.norm2.weight\", \"encoder.features.denseblock4.denselayer5.norm2.bias\", \"encoder.features.denseblock4.denselayer5.norm2.running_mean\", \"encoder.features.denseblock4.denselayer5.norm2.running_var\", \"encoder.features.denseblock4.denselayer5.conv2.weight\", \"encoder.features.denseblock4.denselayer6.norm1.weight\", \"encoder.features.denseblock4.denselayer6.norm1.bias\", \"encoder.features.denseblock4.denselayer6.norm1.running_mean\", \"encoder.features.denseblock4.denselayer6.norm1.running_var\", \"encoder.features.denseblock4.denselayer6.conv1.weight\", \"encoder.features.denseblock4.denselayer6.norm2.weight\", \"encoder.features.denseblock4.denselayer6.norm2.bias\", \"encoder.features.denseblock4.denselayer6.norm2.running_mean\", \"encoder.features.denseblock4.denselayer6.norm2.running_var\", \"encoder.features.denseblock4.denselayer6.conv2.weight\", \"encoder.features.denseblock4.denselayer7.norm1.weight\", \"encoder.features.denseblock4.denselayer7.norm1.bias\", \"encoder.features.denseblock4.denselayer7.norm1.running_mean\", \"encoder.features.denseblock4.denselayer7.norm1.running_var\", \"encoder.features.denseblock4.denselayer7.conv1.weight\", \"encoder.features.denseblock4.denselayer7.norm2.weight\", \"encoder.features.denseblock4.denselayer7.norm2.bias\", \"encoder.features.denseblock4.denselayer7.norm2.running_mean\", \"encoder.features.denseblock4.denselayer7.norm2.running_var\", \"encoder.features.denseblock4.denselayer7.conv2.weight\", \"encoder.features.denseblock4.denselayer8.norm1.weight\", \"encoder.features.denseblock4.denselayer8.norm1.bias\", \"encoder.features.denseblock4.denselayer8.norm1.running_mean\", \"encoder.features.denseblock4.denselayer8.norm1.running_var\", \"encoder.features.denseblock4.denselayer8.conv1.weight\", \"encoder.features.denseblock4.denselayer8.norm2.weight\", \"encoder.features.denseblock4.denselayer8.norm2.bias\", \"encoder.features.denseblock4.denselayer8.norm2.running_mean\", \"encoder.features.denseblock4.denselayer8.norm2.running_var\", \"encoder.features.denseblock4.denselayer8.conv2.weight\", \"encoder.features.denseblock4.denselayer9.norm1.weight\", \"encoder.features.denseblock4.denselayer9.norm1.bias\", \"encoder.features.denseblock4.denselayer9.norm1.running_mean\", \"encoder.features.denseblock4.denselayer9.norm1.running_var\", \"encoder.features.denseblock4.denselayer9.conv1.weight\", \"encoder.features.denseblock4.denselayer9.norm2.weight\", \"encoder.features.denseblock4.denselayer9.norm2.bias\", \"encoder.features.denseblock4.denselayer9.norm2.running_mean\", \"encoder.features.denseblock4.denselayer9.norm2.running_var\", \"encoder.features.denseblock4.denselayer9.conv2.weight\", \"encoder.features.denseblock4.denselayer10.norm1.weight\", \"encoder.features.denseblock4.denselayer10.norm1.bias\", \"encoder.features.denseblock4.denselayer10.norm1.running_mean\", \"encoder.features.denseblock4.denselayer10.norm1.running_var\", \"encoder.features.denseblock4.denselayer10.conv1.weight\", \"encoder.features.denseblock4.denselayer10.norm2.weight\", \"encoder.features.denseblock4.denselayer10.norm2.bias\", \"encoder.features.denseblock4.denselayer10.norm2.running_mean\", \"encoder.features.denseblock4.denselayer10.norm2.running_var\", \"encoder.features.denseblock4.denselayer10.conv2.weight\", \"encoder.features.denseblock4.denselayer11.norm1.weight\", \"encoder.features.denseblock4.denselayer11.norm1.bias\", \"encoder.features.denseblock4.denselayer11.norm1.running_mean\", \"encoder.features.denseblock4.denselayer11.norm1.running_var\", \"encoder.features.denseblock4.denselayer11.conv1.weight\", \"encoder.features.denseblock4.denselayer11.norm2.weight\", \"encoder.features.denseblock4.denselayer11.norm2.bias\", \"encoder.features.denseblock4.denselayer11.norm2.running_mean\", \"encoder.features.denseblock4.denselayer11.norm2.running_var\", \"encoder.features.denseblock4.denselayer11.conv2.weight\", \"encoder.features.denseblock4.denselayer12.norm1.weight\", \"encoder.features.denseblock4.denselayer12.norm1.bias\", \"encoder.features.denseblock4.denselayer12.norm1.running_mean\", \"encoder.features.denseblock4.denselayer12.norm1.running_var\", \"encoder.features.denseblock4.denselayer12.conv1.weight\", \"encoder.features.denseblock4.denselayer12.norm2.weight\", \"encoder.features.denseblock4.denselayer12.norm2.bias\", \"encoder.features.denseblock4.denselayer12.norm2.running_mean\", \"encoder.features.denseblock4.denselayer12.norm2.running_var\", \"encoder.features.denseblock4.denselayer12.conv2.weight\", \"encoder.features.denseblock4.denselayer13.norm1.weight\", \"encoder.features.denseblock4.denselayer13.norm1.bias\", \"encoder.features.denseblock4.denselayer13.norm1.running_mean\", \"encoder.features.denseblock4.denselayer13.norm1.running_var\", \"encoder.features.denseblock4.denselayer13.conv1.weight\", \"encoder.features.denseblock4.denselayer13.norm2.weight\", \"encoder.features.denseblock4.denselayer13.norm2.bias\", \"encoder.features.denseblock4.denselayer13.norm2.running_mean\", \"encoder.features.denseblock4.denselayer13.norm2.running_var\", \"encoder.features.denseblock4.denselayer13.conv2.weight\", \"encoder.features.denseblock4.denselayer14.norm1.weight\", \"encoder.features.denseblock4.denselayer14.norm1.bias\", \"encoder.features.denseblock4.denselayer14.norm1.running_mean\", \"encoder.features.denseblock4.denselayer14.norm1.running_var\", \"encoder.features.denseblock4.denselayer14.conv1.weight\", \"encoder.features.denseblock4.denselayer14.norm2.weight\", \"encoder.features.denseblock4.denselayer14.norm2.bias\", \"encoder.features.denseblock4.denselayer14.norm2.running_mean\", \"encoder.features.denseblock4.denselayer14.norm2.running_var\", \"encoder.features.denseblock4.denselayer14.conv2.weight\", \"encoder.features.denseblock4.denselayer15.norm1.weight\", \"encoder.features.denseblock4.denselayer15.norm1.bias\", \"encoder.features.denseblock4.denselayer15.norm1.running_mean\", \"encoder.features.denseblock4.denselayer15.norm1.running_var\", \"encoder.features.denseblock4.denselayer15.conv1.weight\", \"encoder.features.denseblock4.denselayer15.norm2.weight\", \"encoder.features.denseblock4.denselayer15.norm2.bias\", \"encoder.features.denseblock4.denselayer15.norm2.running_mean\", \"encoder.features.denseblock4.denselayer15.norm2.running_var\", \"encoder.features.denseblock4.denselayer15.conv2.weight\", \"encoder.features.denseblock4.denselayer16.norm1.weight\", \"encoder.features.denseblock4.denselayer16.norm1.bias\", \"encoder.features.denseblock4.denselayer16.norm1.running_mean\", \"encoder.features.denseblock4.denselayer16.norm1.running_var\", \"encoder.features.denseblock4.denselayer16.conv1.weight\", \"encoder.features.denseblock4.denselayer16.norm2.weight\", \"encoder.features.denseblock4.denselayer16.norm2.bias\", \"encoder.features.denseblock4.denselayer16.norm2.running_mean\", \"encoder.features.denseblock4.denselayer16.norm2.running_var\", \"encoder.features.denseblock4.denselayer16.conv2.weight\", \"encoder.features.norm5.weight\", \"encoder.features.norm5.bias\", \"encoder.features.norm5.running_mean\", \"encoder.features.norm5.running_var\", \"decoder.p5.weight\", \"decoder.p5.bias\", \"decoder.p4.skip_conv.weight\", \"decoder.p4.skip_conv.bias\", \"decoder.p3.skip_conv.weight\", \"decoder.p3.skip_conv.bias\", \"decoder.p2.skip_conv.weight\", \"decoder.p2.skip_conv.bias\", \"decoder.seg_blocks.0.block.0.block.0.weight\", \"decoder.seg_blocks.0.block.0.block.1.weight\", \"decoder.seg_blocks.0.block.0.block.1.bias\", \"decoder.seg_blocks.0.block.1.block.0.weight\", \"decoder.seg_blocks.0.block.1.block.1.weight\", \"decoder.seg_blocks.0.block.1.block.1.bias\", \"decoder.seg_blocks.0.block.2.block.0.weight\", \"decoder.seg_blocks.0.block.2.block.1.weight\", \"decoder.seg_blocks.0.block.2.block.1.bias\", \"decoder.seg_blocks.1.block.0.block.0.weight\", \"decoder.seg_blocks.1.block.0.block.1.weight\", \"decoder.seg_blocks.1.block.0.block.1.bias\", \"decoder.seg_blocks.1.block.1.block.0.weight\", \"decoder.seg_blocks.1.block.1.block.1.weight\", \"decoder.seg_blocks.1.block.1.block.1.bias\", \"decoder.seg_blocks.2.block.0.block.0.weight\", \"decoder.seg_blocks.2.block.0.block.1.weight\", \"decoder.seg_blocks.2.block.0.block.1.bias\", \"decoder.seg_blocks.3.block.0.block.0.weight\", \"decoder.seg_blocks.3.block.0.block.1.weight\", \"decoder.seg_blocks.3.block.0.block.1.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.bn3.num_batches_tracked\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.0.downsample.1.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.1.bn3.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer1.2.bn3.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.0.bn3.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.1.bn3.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.2.bn3.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer2.3.bn3.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.0.bn3.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.1.bn3.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.2.bn3.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.3.bn3.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.4.bn3.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer3.5.bn3.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.0.bn3.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.1.bn3.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\", \"encoder.layer4.2.bn3.num_batches_tracked\", \"decoder.blocks.0.conv1.0.weight\", \"decoder.blocks.0.conv1.1.weight\", \"decoder.blocks.0.conv1.1.bias\", \"decoder.blocks.0.conv1.1.running_mean\", \"decoder.blocks.0.conv1.1.running_var\", \"decoder.blocks.0.conv1.1.num_batches_tracked\", \"decoder.blocks.0.conv2.0.weight\", \"decoder.blocks.0.conv2.1.weight\", \"decoder.blocks.0.conv2.1.bias\", \"decoder.blocks.0.conv2.1.running_mean\", \"decoder.blocks.0.conv2.1.running_var\", \"decoder.blocks.0.conv2.1.num_batches_tracked\", \"decoder.blocks.1.conv1.0.weight\", \"decoder.blocks.1.conv1.1.weight\", \"decoder.blocks.1.conv1.1.bias\", \"decoder.blocks.1.conv1.1.running_mean\", \"decoder.blocks.1.conv1.1.running_var\", \"decoder.blocks.1.conv1.1.num_batches_tracked\", \"decoder.blocks.1.conv2.0.weight\", \"decoder.blocks.1.conv2.1.weight\", \"decoder.blocks.1.conv2.1.bias\", \"decoder.blocks.1.conv2.1.running_mean\", \"decoder.blocks.1.conv2.1.running_var\", \"decoder.blocks.1.conv2.1.num_batches_tracked\", \"decoder.blocks.2.conv1.0.weight\", \"decoder.blocks.2.conv1.1.weight\", \"decoder.blocks.2.conv1.1.bias\", \"decoder.blocks.2.conv1.1.running_mean\", \"decoder.blocks.2.conv1.1.running_var\", \"decoder.blocks.2.conv1.1.num_batches_tracked\", \"decoder.blocks.2.conv2.0.weight\", \"decoder.blocks.2.conv2.1.weight\", \"decoder.blocks.2.conv2.1.bias\", \"decoder.blocks.2.conv2.1.running_mean\", \"decoder.blocks.2.conv2.1.running_var\", \"decoder.blocks.2.conv2.1.num_batches_tracked\", \"decoder.blocks.3.conv1.0.weight\", \"decoder.blocks.3.conv1.1.weight\", \"decoder.blocks.3.conv1.1.bias\", \"decoder.blocks.3.conv1.1.running_mean\", \"decoder.blocks.3.conv1.1.running_var\", \"decoder.blocks.3.conv1.1.num_batches_tracked\", \"decoder.blocks.3.conv2.0.weight\", \"decoder.blocks.3.conv2.1.weight\", \"decoder.blocks.3.conv2.1.bias\", \"decoder.blocks.3.conv2.1.running_mean\", \"decoder.blocks.3.conv2.1.running_var\", \"decoder.blocks.3.conv2.1.num_batches_tracked\", \"decoder.blocks.4.conv1.0.weight\", \"decoder.blocks.4.conv1.1.weight\", \"decoder.blocks.4.conv1.1.bias\", \"decoder.blocks.4.conv1.1.running_mean\", \"decoder.blocks.4.conv1.1.running_var\", \"decoder.blocks.4.conv1.1.num_batches_tracked\", \"decoder.blocks.4.conv2.0.weight\", \"decoder.blocks.4.conv2.1.weight\", \"decoder.blocks.4.conv2.1.bias\", \"decoder.blocks.4.conv2.1.running_mean\", \"decoder.blocks.4.conv2.1.running_var\", \"decoder.blocks.4.conv2.1.num_batches_tracked\". \n\tsize mismatch for segmentation_head.0.weight: copying a param with shape torch.Size([1, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-9cfbf5699023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0meval_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'gen_image'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mgen_val_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-af54c3b4a7be>\u001b[0m in \u001b[0;36meval_image\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"module.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1224\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FPN:\n\tMissing key(s) in state_dict: \"encoder.features.conv0.weight\", \"encoder.features.norm0.weight\", \"encoder.features.norm0.bias\", \"encoder.features.norm0.running_mean\", \"encoder.features.norm0.running_var\", \"encoder.features.denseblock1.denselayer1.norm1.weight\", \"encoder.features.denseblock1.denselayer1.norm1.bias\", \"encoder.features.denseblock1.denselayer1.norm1.running_mean\", \"encoder.features.denseblock1.denselayer1.norm1.running_var\", \"encoder.features.denseblock1.denselayer1.conv1.weight\", \"encoder.features.denseblock1.denselayer1.norm2.weight\", \"encoder.features.denseblock1.denselayer1.norm2.bias\", \"encoder.features.denseblock1.denselayer1.norm2.running_mean\", \"encoder.features.denseblock1.denselayer1.norm2.running_var\", \"encoder.features.denseblock1.denselayer1.conv2.weight\", \"encoder.features.denseblock1.denselayer2.norm1.weight\", \"encoder.features.denseblock1.denselayer2.norm1.bias\", \"encoder.features.denseblock1.denselayer2.norm1.running_mean\", \"encoder.features.denseblock1.denselayer2.norm1.running_var\", \"encoder.features.denseblock1.denselayer2.conv1.weight\", \"encoder.features.denseblock1.denselayer2.norm2.weight\", \"encoder.features.denseblock1.denselayer2.norm2.bias\", \"encoder.features.denseblock1.denselayer2.norm2.running_mean\", \"encoder.features.denseblock1.denselayer2.norm2.running_var\", \"encoder.features.denseblock1.denselayer2.conv2.weight\", \"encoder.features.denseblock1.denselayer3.norm1.weight\", \"encoder.features.denseblock1.denselayer3.norm1.bias\", \"encoder.features.denseblock1.denselayer3.norm1.running_mean\", \"encoder.features.denseblock1.denselayer3.norm1.running_var\", \"encoder.features.denseblock1.denselayer3.conv1.weight\", \"encoder.features.denseblock1.denselayer3.norm2.weight\", \"encoder.features.denseblock1.denselayer3.norm2.bias\", \"encoder.features.denseblock1.denselayer3.norm2.running_mean\", \"encoder.features.denseblock1.denselayer3.norm2.running_var\", \"encoder.features.denseblock1.denselayer3.conv2.weight\", \"encoder.features.denseblock1.denselayer4.norm1.weight\", \"encoder.features.denseblock1.denselayer4.norm1.bias\", \"encoder.features.denseblock1.denselayer4.norm1.running_mean\", \"encoder.features.denseblock1.denselayer4.norm1.running_var\", \"encoder.features.denseblock1.denselayer4.conv1.weight\", \"encoder.features.denseblock1.denselayer4.norm2.weight\", \"encoder.features.denseblock1.denselayer4.norm2.bias\", \"encoder.features.denseblock1.denselayer4.norm2.running_mean\", \"encoder.features.denseblock1.denselayer4.norm2.running_var\", \"encoder.features.denseblock1.denselayer4.conv2.weight\", \"encoder.features.denseblock1.denselayer5.norm1.weight\", \"encoder.features.denseblock1.denselayer5.norm1.bias\", \"encoder.features.denseblock1.denselayer5.norm1.running_mean\", \"encoder.features.denseblock1.denselayer5.norm1.running_var\", \"encoder.features.denseblock1.denselayer5.conv1.weight\", \"encoder.features.denseblock1.denselayer5.norm2.weight\", \"encoder.features.denseblock1.denselayer5.norm2.bias\", \"encoder.features.denseblock1.denselayer5.norm2.running_mean\", \"encoder.features.denseblock1.denselayer5.norm2.running_var\", \"encoder.features.denseblock1.denselayer5.conv2.weight\", \"encoder.features.denseblock1.denselayer6.norm1.weight\", \"encoder.features.denseblock1.denselayer6.norm1.bias\", \"encoder.features.denseblock1.denselayer6.norm1.running_mean\", \"encoder.features.denseblock1.denselayer6.norm1.running_var\", \"encoder.features.denseblock1.denselayer6.conv1.weight\", \"encoder.features.denseblock1.denselayer6.norm2.weight\", \"encoder.features.denseblock1.denselayer6.norm2.bias\", \"encoder.features.denseblock1.denselayer6.norm2.running_mean\", \"encoder.features.denseblock1.denselayer6.norm2.running_var\", \"encoder.features.denseblock1.denselayer6.conv2.weight\", \"encoder.features.transition1.norm.weight\", \"encoder.features.transition1.norm.bias\", \"encoder.features.transition1.norm.running_mean\", \"encoder.features.transition1.norm.running_var\", \"encoder.features.transition1.conv.weight\", \"encoder.features.denseblock2.denselayer1.norm1.weight\", \"encoder.features.denseblock2.denselayer1.norm1.bias\", \"encoder.features.denseblock2.denselayer1.norm1.running_mean\", \"encoder.features.denseblock2.denselayer1.norm1.running_var\", \"encoder.features.denseblock2.denselayer1.conv1.weight\", \"encoder.features.denseblock2.denselayer1.norm2.weight\", \"encoder.features.denseblock2.denselayer1.norm2.bias\", \"encoder.features.denseblock2.denselayer1.norm2.running_mean\", \"encoder.features.denseblock2.denselayer1.norm2.running_var\", \"encoder.features.denseblock2.denselayer1.conv2.weight\", \"encoder.features.denseblock2.denselayer2.norm1.weight\", \"encoder.features.denseblock2.denselayer2.norm1.bias\", \"encoder.features.denseblock2.denselayer2.norm1.running_mean\", \"encoder.features.denseblock2.denselayer2.norm1.running_var\", \"encoder.features.denseblock2.denselayer2.conv1.weight\", \"encoder.features.denseblock2.denselayer2.norm2.weight\", \"encoder.features.denseblock2.denselayer2.norm2.bias\", \"encoder.features.denseblock2.denselayer2.norm2.running_mean\", \"encoder.features.denseblock2.denselayer2.norm2.running_var\", \"encoder.features.denseblock2.denselayer2.conv2.weight\", \"encoder.features.denseblock2.denselayer3.norm1.weight\", \"encoder.features.denseblock2.denselayer3.norm1.bias\", \"encoder.features.denseblock2.denselayer3.norm1.running_mean\", \"encoder.features.denseblock2.denselayer3.norm1.running_var\", \"encoder.features.denseblock2.denselayer3.conv1.weight\", \"encoder.features.denseblock2.denselayer3.norm2.weight\", \"encoder.features.denseblock2.denselayer3.norm2.bias\", \"encoder.features.denseblock2.denselayer3.norm2.running_mean\", \"encoder.features.denseblock2.denselayer3.norm2.running_var\", \"encoder.features.denseblock2.denselayer3.conv2.weight\", \"encoder.features.denseblock2.denselayer4.norm1.weight\", \"encoder.features.denseblock2.denselayer4.norm1.bias\", \"encoder.features.denseblock2.denselayer4.norm1.running_mean\", \"encoder.features.denseblock2.denselayer4.norm1.running_var\", \"encoder.features.denseblock2.denselayer4.conv1.weight\", \"encoder.features.denseblock2.denselayer4.norm2.weight\", \"encoder.features.denseblock2.denselayer4.norm2.bias\", \"encoder.features.denseblock2.denselayer4.norm2.running_mean\", \"encoder.features.denseblock2.denselayer4.norm2.running_var\", \"encoder.features.denseblock2.denselayer4.conv2.weight\", \"encoder.features.denseblock2.denselayer5.norm1.weight\", \"encoder.features.denseblock2.denselayer5.norm1.bias\", \"encoder.features.denseblock2.denselayer5.norm1.running_mean\", \"encoder.features.denseblock2.denselayer5.norm1.running_var\", \"encoder.features.denseblock2.denselayer5.conv1.weight\", \"encoder.features.denseblock2.denselayer5.norm2.weight\", \"encoder.features.denseblock2.denselayer5.norm2.bias\", \"encoder.features.denseblock2.denselayer5.norm2.running_mean\", \"encoder.features.denseblock2.denselayer5.norm2.running_var\", \"encoder.features.denseblock2.denselayer5.conv2.weight\", \"encoder.features.denseblock2.denselayer6.norm1.weight\", \"encoder.features.denseblock2.denselayer6.norm1.bias\", \"encoder.features.denseblock2.denselayer6.norm1.running_mean\", \"encoder.features.denseblock2.denselayer6.norm1.running_var\", \"encoder.features.denseblock2.denselayer6.conv1.weight\", \"encoder.features.denseblock2.denselayer6.norm2.weight\", \"encoder.features.denseblock2.denselayer6.norm2.bias\", \"encoder.features.denseblock2.denselayer6.norm2.running_mean\", \"encoder.features.denseblock2.denselayer6.norm2.running_var\", \"encoder.features.denseblock2.denselayer6.conv2.weight\", \"encoder.features.denseblock2.denselayer7.norm1.weight\", \"encoder.features.denseblock2.denselayer7.norm1.bias\", \"encoder.features.denseblock2.denselayer7.norm1.running_mean\", \"encoder.features.denseblock2.denselayer7.norm1.running_var\", \"encoder.features.denseblock2.denselayer7.conv1.weight\", \"encoder.features.denseblock2.denselayer7.norm2.weight\", \"encoder.features.denseblock2.denselayer7.norm2.bias\", \"encoder.features.denseblock2.denselayer7.norm2.running_mean\", \"encoder.features.denseblock2.denselayer7.norm2.running_var\", \"encoder.features.denseblock2.denselayer7.conv2.weight\", \"encoder.features.denseblock2.denselayer8.norm1.weight\", \"encoder.features.denseblock2.denselayer8.norm1.bias\", \"encoder.features.denseblock2.denselayer8.norm1.running_mean\", \"encoder.features.denseblock2.denselayer8.norm1.running_var\", \"encoder.features.denseblock2.denselayer8.conv1.weight\", \"encoder.features.denseblock2.denselayer8.norm2.weight\", \"encoder.features.denseblock2.denselayer8.norm2.bias\", \"encoder.features.denseblock2.denselayer8.norm2.running_mean\", \"encoder.features.denseblock2.denselayer8.norm2.running_var\", \"encoder.features.denseblock2.denselayer8.conv2.weight\", \"encoder.features.denseblock2.denselayer9.norm1.weight\", \"encoder.features.denseblock2.denselayer9.norm1.bias\", \"encoder.features.denseblock2.denselayer9.norm1.running_mean\", \"encoder.features.denseblock2.denselayer9.norm1.running_var\", \"encoder.features.denseblock2.denselayer9.conv1.weight\", \"encoder.features.denseblock2.denselayer9.norm2.weight\", \"encoder.features.denseblock2.denselayer9.norm2.bias\", \"encoder.features.denseblock2.denselayer9.norm2.running_mean\", \"encoder.features.denseblock2.denselayer9.norm2.running_var\", \"encoder.features.denseblock2.denselayer9.conv2.weight\", \"encoder.features.denseblock2.denselayer10.norm1.weight\", \"encoder.features.denseblock2.denselayer10.norm1.bias\", \"encoder.features.denseblock2.denselayer10.norm1.running_mean\", \"encoder.features.denseblock2.denselayer10.norm1.running_var\", \"encoder.features.denseblock2.denselayer10.conv1.weight\", \"encoder.features.denseblock2.denselayer10.norm2.weight\", \"encoder.features.denseblock2.denselayer10.norm2.bias\", \"encoder.features.denseblock2.denselayer10.norm2.running_mean\", \"encoder.features.denseblock2.denselayer10.norm2.running_var\", \"encoder.features.denseblock2.denselayer10.conv2.weight\", \"encoder.features.denseblock2.denselayer11.norm1.weight\", \"encoder.features.denseblock2.denselayer11.norm1.bias\", \"encoder.features.denseblock2.denselayer11.norm1.running_mean\", \"encoder.features.denseblock2.denselayer11.norm1.running_var\", \"encoder.features.denseblock2.denselayer11.conv1.weight\", \"encoder.features.denseblock2.denselayer11.norm2.weight\", \"encoder.features.denseblock2.denselayer11.norm2.bias\", \"encoder.features.denseblock2.denselayer11.norm2.running_mean\", \"encoder.features.denseblock2.denselayer11.norm2.running_var\", \"encoder.features.denseblock2.denselayer11.conv2.weight\", \"encoder.features.denseblock2.denselayer12.norm1.weight\", \"encoder.features.denseblock2.denselayer12.norm1.bias\", \"encoder.features.denseblock2.denselayer12.norm1.running_mean\", \"encoder.features.denseblock2.denselayer12.norm1.running_var\", \"encoder.features.denseblock2.denselayer12.conv1.weight\", \"encoder.features.denseblock2.denselayer12.norm2.weight\", \"encoder.features.denseblock2.denselayer12.norm2.bias\", \"encoder.features.denseblock2.denselayer12.norm2.running_mean\", \"encoder.features.denseblock2.denselayer12.norm2.running_var\", \"encoder.features.denseblock2.denselayer12.conv2.weight\", \"encoder.features.transition2.norm.weight\", \"encoder.features.transition2.norm.bias\", \"encoder.features.transition2.norm.running_mean\", \"encoder.features.transition2.norm.running_var\", \"encoder.features.transition2.conv.weight\", \"encoder.features.denseblock3.denselayer1.norm1.weight\", \"encoder.features.denseblock3.denselayer1.norm1.bias\", \"encoder.features.denseblock3.denselayer1.norm1.running_mean\", \"encoder.features.denseblock3.denselayer1.norm1.running_var\", \"encoder.features.denseblock3.denselayer1.conv1.weight\", \"encoder.features.denseblock3.denselayer1.norm2.weight\", \"encoder.features.denseblock3.denselayer1.norm2.bias\", \"encoder.features.denseblock3.denselayer1.norm2.running_mean\", \"encoder.features.denseblock3.denselayer1.norm2.running_var\", \"encoder.features.denseblock3.denselayer1.conv2.weight\", \"encoder.features.denseblock3.denselayer2.norm1.weight\", \"encoder.features.denseblock3.denselayer2.norm1.bias\", \"encoder.features.denseblock3.denselayer2.norm1.running_mean\", \"encoder.features.denseblock3.denselayer2.norm1.running_var\", \"encoder.features.denseblock3.denselayer2.conv1.weight\", \"encoder.features.denseblock3.denselayer2.norm2.weight\", \"encoder.features.denseblock3.denselayer2.norm2.bias\", \"encoder.features.denseblock3.denselayer2.norm2.running_mean\", \"encoder.features.denseblock3.denselayer2.norm2.running_var\", \"encoder.features.denseblock3.denselayer2.conv2.weight\", \"encoder.features.denseblock3.denselayer3.norm1.weight\", \"encoder.features.denseblock3.denselayer3.norm1.bias\", \"encoder.features.denseblock3.denselayer3.norm1.running_mean\", \"encoder.features.denseblock3.denselayer3.norm1.running_var\", \"encoder.features.denseblock3.denselayer3.conv1.weight\", \"encoder.features.denseblock3.denselayer3.norm2.weight\", \"encoder.features.denseblock3.denselayer3.norm2.bias\", \"encoder.features.denseblock3.denselayer3.norm2.running_mean\", \"encoder.features.denseblock3.denselayer3.norm2.running_var\", \"encoder.features.denseblock3.denselayer3.conv2.weight\", \"encoder.features.denseblock3.denselayer4.norm1.weight\", \"encoder.features.denseblock3.denselayer4.norm1.bias\", \"encoder.features.denseblock3.denselayer4.norm1.running_mean\", \"encoder.features.denseblock3.denselayer4.norm1.running_var\", \"encoder.features.denseblock3.denselayer4.conv1.weight\", \"encoder.features.denseblock3.denselayer4.norm2.weight\", \"encoder.features.denseblock3.denselayer4.norm2.bias\", \"encoder.features.denseblock3.denselayer4.norm2.running_mean\", \"encoder.features.denseblock3.denselayer4.norm2.running_var\", \"encoder.features.denseblock3.denselayer4.conv2.weight\", \"encoder.features.denseblock3.denselayer5.norm1.weight\", \"encoder.features.denseblock3.denselayer5.norm1.bias\", \"encoder.features.denseblock3.denselayer5.norm1.running_mean\", \"encoder.features.denseblock3.denselayer5.norm1.running_var\", \"encoder.features.denseblock3.denselayer5.conv1.weight\", \"encoder.features.denseblock3.denselayer5.norm2.weight\", \"encoder.features.denseblock3.denselayer5.norm2.bias\", \"encoder.features.denseblock3.denselayer5.norm2.running_mean\", \"encoder.features.denseblock3.denselayer5.norm2.running_var\", \"encoder.features.denseblock3.denselayer5.conv2.weight\", \"encoder.features.denseblock3.denselayer6.norm1.weight\", \"encoder.features.denseblock3.denselayer6.norm1.bias\", \"encoder.features.denseblock3.denselayer6.norm1.running_mean\", \"encoder.features.denseblock3.denselayer6.norm1.running_var\", \"encoder.features.denseblock3.denselayer6.conv1.weight\", \"encoder.features.denseblock3.denselayer6.norm2.weight\", \"encoder.features.denseblock3.denselayer6.norm2.bias\", \"encoder.features.denseblock3.denselayer6.norm2.running_mean\", \"encoder.features.denseblock3.denselayer6.norm2.running_var\", \"encoder.features.denseblock3.denselayer6.conv2.weight\", \"encoder.features.denseblock3.denselayer7.norm1.weight\", \"encoder.features.denseblock3.denselayer7.norm1.bias\", \"encoder.features.denseblock3.denselayer7.norm1.running_mean\", \"encoder.features.denseblock3.denselayer7.norm1.running_var\", \"encoder.features.denseblock3.denselayer7.conv1.weight\", \"encoder.features.denseblock3.denselayer7.norm2.weight\", \"encoder.features.denseblock3.denselayer7.norm2.bias\", \"encoder.features.denseblock3.denselayer7.norm2.running_mean\", \"encoder.features.denseblock3.denselayer7.norm2.running_var\", \"encoder.features.denseblock3.denselayer7.conv2.weight\", \"encoder.features.denseblock3.denselayer8.norm1.weight\", \"encoder.features.denseblock3.denselayer8.norm1.bias\", \"encoder.features.denseblock3.denselayer8.norm1.running_mean\", \"encoder.features.denseblock3.denselayer8.norm1.running_var\", \"encoder.features.denseblock3.denselayer8.conv1.weight\", \"encoder.features.denseblock3.denselayer8.norm2.weight\", \"encoder.features.denseblock3.denselayer8.norm2.bias\", \"encoder.features.denseblock3.denselayer8.norm2.running_mean\", \"encoder.features.denseblock3.denselayer8.norm2.running_var\", \"encoder.features.denseblock3.denselayer8.conv2.weight\", \"encoder.features.denseblock3.denselayer9.norm1.weight\", \"encoder.features.denseblock3.denselayer9.norm1.bias\", \"encoder.features.denseblock3.denselayer9.norm1.running_mean\", \"encoder.features.denseblock3.denselayer9.norm1.running_var\", \"encoder.features.denseblock3.denselayer9.conv1.weight\", \"encoder.features.denseblock3.denselayer9.norm2.weight\", \"encoder.features.denseblock3.denselayer9.norm2.bias\", \"encoder.features.denseblock3.denselayer9.norm2.running_mean\", \"encoder.features.denseblock3.denselayer9.norm2.running_var\", \"encoder.features.denseblock3.denselayer9.conv2.weight\", \"encoder.features.denseblock3.denselayer10.norm1.weight\", \"encoder.features.denseblock3.denselayer10.norm1.bias\", \"encoder.features.denseblock3.denselayer10.norm1.running_mean\", \"encoder.features.denseblock3.denselayer10.norm1.running_var\", \"encoder.features.denseblock3.denselayer10.conv1.weight\", \"encoder.features.denseblock3.denselayer10.norm2.weight\", \"encoder.features.denseblock3.denselayer10.norm2.bias\", \"encoder.features.denseblock3.denselayer10.norm2.running_mean\", \"encoder.features.denseblock3.denselayer10.norm2.running_var\", \"encoder.features.denseblock3.denselayer10.conv2.weight\", \"encoder.features.denseblock3.denselayer11.norm1.weight\", \"encoder.features.denseblock3.denselayer11.norm1.bias\", \"encoder.features.denseblock3.denselayer11.norm1.running_mean\", \"encoder.features.denseblock3.denselayer11.norm1.running_var\", \"encoder.features.denseblock3.denselayer11.conv1.weight\", \"encoder.features.denseblock3.denselayer11.norm2.weight\", \"encoder.features.denseblock3.denselayer11.norm2.bias\", \"encoder.features.denseblock3.denselayer11.norm2.running_mean\", \"encoder.features.denseblock3.denselayer11.norm2.running_var\", \"encoder.features.denseblock3.denselayer11.conv2.weight\", \"encoder.features.denseblock3.denselayer12.norm1.weight\", \"encoder.features.denseblock3.denselayer12.norm1.bias\", \"encoder.features.denseblock3.denselayer12.norm1.running_mean\", \"encoder.features.denseblock3.denselayer12.norm1.running_var\", \"encoder.features.denseblock3.denselayer12.conv1.weight\", \"encoder.features.denseblock3.denselayer12.norm2.weight\", \"encoder.features.denseblock3.denselayer12.norm2.bias\", \"encoder.features.denseblock3.denselayer12.norm2.running_mean\", \"encoder.features.denseblock3.denselayer12.norm2.running_var\", \"encoder.features.denseblock3.denselayer12.conv2.weight\", \"encoder.features.denseblock3.denselayer13.norm1.weight\", \"encoder.features.denseblock3.denselayer13.norm1.bias\", \"encoder.features.denseblock3.denselayer13.norm1.running_mean\", \"encoder.features.denseblock3.denselayer13.norm1.running_var\", \"encoder.features.denseblock3.denselayer13.conv1.weight\", \"encoder.features.denseblock3.denselayer13.norm2.weight\", \"encoder.features.denseblock3.denselayer13.norm2.bias\", \"encoder.features.denseblock3.denselayer13.norm2.running_mean\", \"encoder.features.denseblock3.denselayer13.norm2.running_var\", \"encoder.features.denseblock3.denselayer13.conv2.weight\", \"encoder.features.denseblock3.denselayer14.norm1.weight\", \"encoder.features.denseblock3.denselayer14.norm1.bias\", \"encoder.features.denseblock3.denselayer14.norm1.running_mean\", \"encoder.features.denseblock3.denselayer14.norm1.running_var\", \"encoder.features.denseblock3.denselayer14.conv1.weight\", \"encoder.features.denseblock3.denselayer14.norm2.weight\", \"encoder.features.denseblock3.denselayer14.norm2.bias\", \"encoder.features.denseblock3.denselayer14.norm2.running_mean\", \"encoder.features.denseblock3.denselayer14.norm2.running_var\", \"encoder.features.denseblock3.denselayer14.conv2.weight\", \"encoder.features.denseblock3.denselayer15.norm1.weight\", \"encoder.features.denseblock3.denselayer15.norm1.bias\", \"encoder.features.denseblock3.denselayer15.norm1.running_mean\", \"encoder.features.denseblock3.denselayer15.norm1.running_var\", \"encoder.features.denseblock3.denselayer15.conv1.weight\", \"encoder.features.denseblock3.denselayer15.norm2.weight\", \"encoder.features.denseblock3.denselayer15.norm2.bias\", \"encoder.features.denseblock3.denselayer15.norm2.running_mean\", \"encoder.features.denseblock3.denselayer15.norm2.running_var\", \"encoder.features.denseblock3.denselayer15.conv2.weight\", \"encoder.features.denseblock3.denselayer16.norm1.weight\", \"encoder.features.denseblock3.denselayer16.norm1.bias\", \"encoder.features.denseblock3.denselayer16.norm1.running_mean\", \"encoder.features.denseblock3.denselayer16.norm1.running_var\", \"encoder.features.denseblock3.denselayer16.conv1.weight\", \"encoder.features.denseblock3.denselayer16.norm2.weight\", \"encoder.features.denseblock3.denselayer16.norm2.bias\", \"encoder.features.denseblock3.denselayer16.norm2.running_mean\", \"encoder.features.denseblock3.denselayer16.norm2.running_var\", \"encoder.features.denseblock3.denselayer16.conv2.weight\", \"encoder.features.denseblock3.denselayer17.norm1.weight\", \"encoder.features.denseblock3.denselayer17.norm1.bias\", \"encoder.features.denseblock3.denselayer17.norm1.running_mean\", \"encoder.features.denseblock3.denselayer17.norm1.running_var\", \"encoder.features.denseblock3.denselayer17.conv1.weight\", \"encoder.features.denseblock3.denselayer17.norm2.weight\", \"encoder.features.denseblock3.denselayer17.norm2.bias\", \"encoder.features.denseblock3.denselayer17.norm2.running_mean\", \"encoder.features.denseblock3.denselayer17.norm2.running_var\", \"encoder.features.denseblock3.denselayer17.conv2.weight\", \"encoder.features.denseblock3.denselayer18.norm1.weight\", \"encoder.features.denseblock3.denselayer18.norm1.bias\", \"encoder.features.denseblock3.denselayer18.norm1.running_mean\", \"encoder.features.denseblock3.denselayer18.norm1.running_var\", \"encoder.features.denseblock3.denselayer18.conv1.weight\", \"encoder.features.denseblock3.denselayer18.norm2.weight\", \"encoder.features.denseblock3.denselayer18.norm2.bias\", \"encoder.features.denseblock3.denselayer18.norm2.running_mean\", \"encoder.features.denseblock3.denselayer18.norm2.running_var\", \"encoder.features.denseblock3.denselayer18.conv2.weight\", \"encoder.features.denseblock3.denselayer19.norm1.weight\", \"encoder.features.denseblock3.denselayer19.norm1.bias\", \"encoder.features.denseblock3.denselayer19.norm1.running_mean\", \"encoder.features.denseblock3.denselayer19.norm1.running_var\", \"encoder.features.denseblock3.denselayer19.conv1.weight\", \"encoder.features.denseblock3.denselayer19.norm2.weight\", \"encoder.features.denseblock3.denselayer19.norm2.bias\", \"encoder.features.denseblock3.denselayer19.norm2.running_mean\", \"encoder.features.denseblock3.denselayer19.norm2.running_var\", \"encoder.features.denseblock3.denselayer19.conv2.weight\", \"encoder.features.denseblock3.denselayer20.norm1.weight\", \"encoder.features.denseblock3.denselayer20.norm1.bias\", \"encoder.features.denseblock3.denselayer20.norm1.running_mean\", \"encoder.features.denseblock3.denselayer20.norm1.running_var\", \"encoder.features.denseblock3.denselayer20.conv1.weight\", \"encoder.features.denseblock3.denselayer20.norm2.weight\", \"encoder.features.denseblock3.denselayer20.norm2.bias\", \"encoder.features.denseblock3.denselayer20.norm2.running_mean\", \"encoder.features.denseblock3.denselayer20.norm2.running_var\", \"encoder.features.denseblock3.denselayer20.conv2.weight\", \"encoder.features.denseblock3.denselayer21.norm1.weight\", \"encoder.features.denseblock3.denselayer21.norm1.bias\", \"encoder.features.denseblock3.denselayer21.norm1.running_mean\", \"encoder.features.denseblock3.denselayer21.norm1.running_var\", \"encoder.features.denseblock3.denselayer21.conv1.weight\", \"encoder.features.denseblock3.denselayer21.norm2.weight\", \"encoder.features.denseblock3.denselayer21.norm2.bias\", \"encoder.features.denseblock3.denselayer21.norm2.running_mean\", \"encoder.features.denseblock3.denselayer21.norm2.running_var\", \"encoder.features.denseblock3.denselayer21.conv2.weight\", \"encoder.features.denseblock3.denselayer22.norm1.weight\", \"encoder.features.denseblock3.denselayer22.norm1.bias\", \"encoder.features.denseblock3.denselayer22.norm1.running_mean\", \"encoder.features.denseblock3.denselayer22.norm1.running_var\", \"encoder.features.denseblock3.denselayer22.conv1.weight\", \"encoder.features.denseblock3.denselayer22.norm2.weight\", \"encoder.features.denseblock3.denselayer22.norm2.bias\", \"encoder.features.denseblock3.denselayer22.norm2.running_mean\", \"encoder.features.denseblock3.denselayer22.norm2.running_var\", \"encoder.features.denseblock3.denselayer22.conv2.weight\", \"encoder.features.denseblock3.denselayer23.norm1.weight\", \"encoder.features.denseblock3.denselayer23.norm1.bias\", \"encoder.features.denseblock3.denselayer23.norm1.running_mean\", \"encoder.features.denseblock3.denselayer23.norm1.running_var\", \"encoder.features.denseblock3.denselayer23.conv1.weight\", \"encoder.features.denseblock3.denselayer23.norm2.weight\", \"encoder.features.denseblock3.denselayer23.norm2.bias\", \"encoder.features.denseblock3.denselayer23.norm2.running_mean\", \"encoder.features.denseblock3.denselayer23.norm2.running_var\", \"encoder.features.denseblock3.denselayer23.conv2.weight\", \"encoder.features.denseblock3.denselayer24.norm1.weight\", \"encoder.features.denseblock3.denselayer24.norm1.bias\", \"encoder.features.denseblock3.denselayer24.norm1.running_mean\", \"encoder.features.denseblock3.denselayer24.norm1.running_var\", \"encoder.features.denseblock3.denselayer24.conv1.weight\", \"encoder.features.denseblock3.denselayer24.norm2.weight\", \"encoder.features.denseblock3.denselayer24.norm2.bias\", \"encoder.features.denseblock3.denselayer24.norm2.running_mean\", \"encoder.features.denseblock3.denselayer24.norm2.running_var\", \"encoder.features.denseblock3.denselayer24.conv2.weight\", \"encoder.features.transition3.norm.weight\", \"encoder.features.transition3.norm.bias\", \"encoder.features.transition3.norm.running_mean\", \"encoder.features.transition3.norm.running_var\", \"encoder.features.transition3.conv.weight\", \"encoder.features.denseblock4.denselayer1.norm1.weight\", \"encoder.features.denseblock4.denselayer1.norm1.bias\", \"encoder.features.denseblock4.denselayer1.norm1.running_mean\", \"encoder.features.denseblock4.denselayer1.norm1.running_var\", \"encoder.features.denseblock4.denselayer1.conv1.weight\", \"encoder.features.denseblock4.denselayer1.norm2.weight\", \"encoder.features.denseblock4.denselayer1.norm2.bias\", \"encoder.features.denseblock4.denselayer1.norm2.running_mean\", \"encoder.features.denseblock4.denselayer1.norm2.running_var\", \"encoder.features.denseblock4.denselayer1.conv2.weight\", \"encoder.features.denseblock4.denselayer2.norm1.weight\", \"encoder.features.denseblock4.denselayer2.norm1.bias\", \"encoder.features.denseblock4.denselayer2.norm1.running_mean\", \"encoder.features.denseblock4.denselayer2.norm1.running_var\", \"encoder.features.denseblock4.denselayer2.conv1.weight\", \"encoder.features.denseblock4.denselayer2.norm2.weight\", \"encoder.features.denseblock4.denselayer2.norm2.bias\", \"encoder.features.denseblock4.denselayer2.norm2.running_mean\", \"encoder.features.denseblock4.denselayer2.norm2.running_var\", \"encoder.features.denseblock4.denselayer2.conv2.weight\", \"encoder.features.denseblock4.denselayer3.norm1.weight\", \"encoder.features.denseblock4.denselayer3.norm1.bias\", \"encoder.features.denseblock4.denselayer3.norm1.running_mean\", \"encoder.features.denseblock4.denselayer3.norm1.running_var\", \"encoder.features.denseblock4.denselayer3.conv1.weight\", \"encoder.features.denseblock4.denselayer3.norm2.weight\", \"encoder.features.denseblock4.denselayer3.norm2.bias\", \"encoder.features.denseblock4.denselayer3.norm2.running_mean\", \"encoder.features.denseblock4.denselayer3.norm2.running_var\", \"encoder.features.denseblock4.denselayer3.conv2.weight\", \"encoder.features.denseblock4.denselayer4.norm1.weight\", \"encoder.features.denseblock4.denselayer4.norm1.bias\", \"encoder.features.denseblock4.denselayer4.norm1.running_mean\", \"encoder.features.denseblock4.denselayer4.norm1.running_var\", \"encoder.features.denseblock4.denselayer4.conv1.weight\", \"encoder.features.denseblock4.denselayer4.norm2.weight\", \"encoder.features.denseblock4.denselayer4.norm2.bias\", \"encoder.features.denseblock4.denselayer4.norm2.running_mean\", \"encoder.features.denseblock4.denselayer4.norm2.running_var\", \"encoder.features.denseblock4.denselayer4.conv2.weight\", \"encoder.features.denseblock4.denselayer5.norm1.weight\", \"encoder.features.denseblock4.denselayer5.norm1.bias\", \"encoder.features.denseblock4.denselayer5.norm1.running_mean\", \"encoder.features.denseblock4.denselayer5.norm1.running_var\", \"encoder.features.denseblock4.denselayer5.conv1.weight\", \"encoder.features.denseblock4.denselayer5.norm2.weight\", \"encoder.features.denseblock4.denselayer5.norm2.bias\", \"encoder.features.denseblock4.denselayer5.norm2.running_mean\", \"encoder.features.denseblock4.denselayer5.norm2.running_var\", \"encoder.features.denseblock4.denselayer5.conv2.weight\", \"encoder.features.denseblock4.denselayer6.norm1.weight\", \"encoder.features.denseblock4.denselayer6.norm1.bias\", \"encoder.features.denseblock4.denselayer6.norm1.running_mean\", \"encoder.features.denseblock4.denselayer6.norm1.running_var\", \"encoder.features.denseblock4.denselayer6.conv1.weight\", \"encoder.features.denseblock4.denselayer6.norm2.weight\", \"encoder.features.denseblock4.denselayer6.norm2.bias\", \"encoder.features.denseblock4.denselayer6.norm2.running_mean\", \"encoder.features.denseblock4.denselayer6.norm2.running_var\", \"encoder.features.denseblock4.denselayer6.conv2.weight\", \"encoder.features.denseblock4.denselayer7.norm1.weight\", \"encoder.features.denseblock4.denselayer7.norm1.bias\", \"encoder.features.denseblock4.denselayer7.norm1.running_mean\", \"encoder.features.denseblock4.denselayer7.norm1.running_var\", \"encoder.features.denseblock4.denselayer7.conv1.weight\", \"encoder.features.denseblock4.denselayer7.norm2.weight\", \"encoder.features.denseblock4.denselayer7.norm2.bias\", \"encoder.features.denseblock4.denselayer7.norm2.running_mean\", \"encoder.features.denseblock4.denselayer7.norm2.running_var\", \"encoder.features.denseblock4.denselayer7.conv2.weight\", \"encoder.features.denseblock4.denselayer8.norm1.weight\", \"encoder.features.denseblock4.denselayer8.norm1.bias\", \"encoder.features.denseblock4.denselayer8.norm1.running_mean\", \"encoder.features.denseblock4.denselayer8.norm1.running_var\", \"encoder.features.denseblock4.denselayer8.conv1.weight\", \"encoder.features.denseblock4.denselayer8.norm2.weight\", \"encoder.features.denseblock4.denselayer8.norm2.bias\", \"encoder.features.denseblock4.denselayer8.norm2.running_mean\", \"encoder.features.denseblock4.denselayer8.norm2.running_var\", \"encoder.features.denseblock4.denselayer8.conv2.weight\", \"encoder.features.denseblock4.denselayer9.norm1.weight\", \"encoder.features.denseblock4.denselayer9.norm1.bias\", \"encoder.features.denseblock4.denselayer9.norm1.running_mean\", \"encoder.features.denseblock4.denselayer9.norm1.running_var\", \"encoder.features.denseblock4.denselayer9.conv1.weight\", \"encoder.features.denseblock4.denselayer9.norm2.weight\", \"encoder.features.denseblock4.denselayer9.norm2.bias\", \"encoder.features.denseblock4.denselayer9.norm2.running_mean\", \"encoder.features.denseblock4.denselayer9.norm2.running_var\", \"encoder.features.denseblock4.denselayer9.conv2.weight\", \"encoder.features.denseblock4.denselayer10.norm1.weight\", \"encoder.features.denseblock4.denselayer10.norm1.bias\", \"encoder.features.denseblock4.denselayer10.norm1.running_mean\", \"encoder.features.denseblock4.denselayer10.norm1.running_var\", \"encoder.features.denseblock4.denselayer10.conv1.weight\", \"encoder.features.denseblock4.denselayer10.norm2.weight\", \"encoder.features.denseblock4.denselayer10.norm2.bias\", \"encoder.features.denseblock4.denselayer10.norm2.running_mean\", \"encoder.features.denseblock4.denselayer10.norm2.running_var\", \"encoder.features.denseblock4.denselayer10.conv2.weight\", \"encoder.features.denseblock4.denselayer11.norm1.weight\", \"encoder.features.denseblock4.denselayer11.norm1.bias\", \"encoder.features.denseblock4.denselayer11.norm1.running_mean\", \"encoder.features.denseblock4.denselayer11.norm1.running_var\", \"encoder.features.denseblock4.denselayer11.conv1.weight\", \"encoder.features.denseblock4.denselayer11.norm2.weight\", \"encoder.features.denseblock4.denselayer11.norm2.bias\", \"encoder.features.denseblock4.denselayer11.norm2.running_mean\", \"encoder.features.denseblock4.denselayer11.norm2.running_var\", \"encoder.features.denseblock4.denselayer11.conv2.weight\", \"encoder.features.denseblock4.denselayer12.norm1.weight\", \"encoder.features.denseblock4.denselayer12.norm1.bias\", \"encoder.features.denseblock4.denselayer12.norm1.running_mean\", \"encoder.features.denseblock4.denselayer12.norm1.running_var\", \"encoder.features.denseblock4.denselayer12.conv1.weight\", \"encoder.features.denseblock4.denselayer12.norm2.weight\", \"encoder.features.denseblock4.denselayer12.norm2.bias\", \"encoder.features.denseblock4.denselayer12.norm2.running_mean\", \"encoder.features.denseblock4.denselayer12.norm2.running_var\", \"encoder.features.denseblock4.denselayer12.conv2.weight\", \"encoder.features.denseblock4.denselayer13.norm1.weight\", \"encoder.features.denseblock4.denselayer13.norm1.bias\", \"encoder.features.denseblock4.denselayer13.norm1.running_mean\", \"encoder.features.denseblock4.denselayer13.norm1.running_var\", \"encoder.features.denseblock4.denselayer13.conv1.weight\", \"encoder.features.denseblock4.denselayer13.norm2.weight\", \"encoder.features.denseblock4.denselayer13.norm2.bias\", \"encoder.features.denseblock4.denselayer13.norm2.running_mean\", \"encoder.features.denseblock4.denselayer13.norm2.running_var\", \"encoder.features.denseblock4.denselayer13.conv2.weight\", \"encoder.features.denseblock4.denselayer14.norm1.weight\", \"encoder.features.denseblock4.denselayer14.norm1.bias\", \"encoder.features.denseblock4.denselayer14.norm1.running_mean\", \"encoder.features.denseblock4.denselayer14.norm1.running_var\", \"encoder.features.denseblock4.denselayer14.conv1.weight\", \"encoder.features.denseblock4.denselayer14.norm2.weight\", \"encoder.features.denseblock4.denselayer14.norm2.bias\", \"encoder.features.denseblock4.denselayer14.norm2.running_mean\", \"encoder.features.denseblock4.denselayer14.norm2.running_var\", \"encoder.features.denseblock4.denselayer14.conv2.weight\", \"encoder.features.denseblock4.denselayer15.norm1.weight\", \"encoder.features.denseblock4.denselayer15.norm1.bias\", \"encoder.features.denseblock4.denselayer15.norm1.running_mean\", \"encoder.features.denseblock4.denselayer15.norm1.running_var\", \"encoder.features.denseblock4.denselayer15.conv1.weight\", \"encoder.features.denseblock4.denselayer15.norm2.weight\", \"encoder.features.denseblock4.denselayer15.norm2.bias\", \"encoder.features.denseblock4.denselayer15.norm2.running_mean\", \"encoder.features.denseblock4.denselayer15.norm2.running_var\", \"encoder.features.denseblock4.denselayer15.conv2.weight\", \"encoder.features.denseblock4.denselayer16.norm1.weight\", \"encoder.features.denseblock4.denselayer16.norm1.bias\", \"encoder.features.denseblock4.denselayer16.norm1.running_mean\", \"encoder.features.denseblock4.denselayer16.norm1.running_var\", \"encoder.features.denseblock4.denselayer16.conv1.weight\", \"encoder.features.denseblock4.denselayer16.norm2.weight\", \"encoder.features.denseblock4.denselayer16.norm2.bias\", \"encoder.features.denseblock4.denselayer16.norm2.running_mean\", \"encoder.features.denseblock4.denselayer16.norm2.running_var\", \"encoder.features.denseblock4.denselayer16.conv2.weight\", \"encoder.features.norm5.weight\", \"encoder.features.norm5.bias\", \"encoder.features.norm5.running_mean\", \"encoder.features.norm5.running_var\", \"decoder.p5.weight\", \"decoder.p5.bias\", \"decoder.p4.skip_conv.weight\", \"decoder.p4.skip_conv.bias\", \"decoder.p3.skip_conv.weight\", \"decoder.p3.skip_conv.bias\", \"decoder.p2.skip_conv.weight\", \"decoder.p2.skip_conv.bias\", \"decoder.seg_blocks.0.block.0.block.0.weight\", \"decoder.seg_blocks.0.block.0.block.1.weight\", \"decoder.seg_blocks.0.block.0.block.1.bias\", \"decoder.seg_blocks.0.block.1.block.0.weight\", \"decoder.seg_blocks.0.block.1.block.1.weight\", \"decoder.seg_blocks.0.block.1.block.1.bias\", \"decoder.seg_blocks.0.block.2.block.0.weight\", \"decoder.seg_blocks.0.block.2.block.1.weight\", \"decoder.seg_blocks.0.block.2.block.1.bias\", \"decoder.seg_blocks.1.block.0.block.0.weight\", \"decoder.seg_blocks.1.block.0.block.1.weight\", \"decoder.seg_blocks.1.block.0.block.1.bias\", \"decoder.seg_blocks.1.block.1.block.0.weight\", \"decoder.seg_blocks.1.block.1.block.1.weight\", \"decoder.seg_blocks.1.block.1.block.1.bias\", \"decoder.seg_blocks.2.block.0.block.0.weight\", \"decoder.seg_blocks.2.block.0.block.1.weight\", \"decoder.seg_blocks.2.block.0.block.1.bias\", \"decoder.seg_blocks.3.block.0.block.0.weight\", \"decoder.seg_blocks.3.block.0.block.1.weight\", \"decoder.seg_blocks.3.block.0.block.1.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.0.conv3.weight\", \"encoder.layer1.0.bn3.weight\", \"encoder.layer1.0.bn3.bias\", \"encoder.layer1.0.bn3.running_mean\", \"encoder.layer1.0.bn3.running_var\", \"encoder.layer1.0.bn3.num_batches_tracked\", \"encoder.layer1.0.downsample.0.weight\", \"encoder.layer1.0.downsample.1.weight\", \"encoder.layer1.0.downsample.1.bias\", \"encoder.layer1.0.downsample.1.running_mean\", \"encoder.layer1.0.downsample.1.running_var\", \"encoder.layer1.0.downsample.1.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.1.conv3.weight\", \"encoder.layer1.1.bn3.weight\", \"encoder.layer1.1.bn3.bias\", \"encoder.layer1.1.bn3.running_mean\", \"encoder.layer1.1.bn3.running_var\", \"encoder.layer1.1.bn3.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer1.2.conv3.weight\", \"encoder.layer1.2.bn3.weight\", \"encoder.layer1.2.bn3.bias\", \"encoder.layer1.2.bn3.running_mean\", \"encoder.layer1.2.bn3.running_var\", \"encoder.layer1.2.bn3.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.conv3.weight\", \"encoder.layer2.0.bn3.weight\", \"encoder.layer2.0.bn3.bias\", \"encoder.layer2.0.bn3.running_mean\", \"encoder.layer2.0.bn3.running_var\", \"encoder.layer2.0.bn3.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.1.conv3.weight\", \"encoder.layer2.1.bn3.weight\", \"encoder.layer2.1.bn3.bias\", \"encoder.layer2.1.bn3.running_mean\", \"encoder.layer2.1.bn3.running_var\", \"encoder.layer2.1.bn3.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.2.conv3.weight\", \"encoder.layer2.2.bn3.weight\", \"encoder.layer2.2.bn3.bias\", \"encoder.layer2.2.bn3.running_mean\", \"encoder.layer2.2.bn3.running_var\", \"encoder.layer2.2.bn3.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer2.3.conv3.weight\", \"encoder.layer2.3.bn3.weight\", \"encoder.layer2.3.bn3.bias\", \"encoder.layer2.3.bn3.running_mean\", \"encoder.layer2.3.bn3.running_var\", \"encoder.layer2.3.bn3.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.conv3.weight\", \"encoder.layer3.0.bn3.weight\", \"encoder.layer3.0.bn3.bias\", \"encoder.layer3.0.bn3.running_mean\", \"encoder.layer3.0.bn3.running_var\", \"encoder.layer3.0.bn3.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.1.conv3.weight\", \"encoder.layer3.1.bn3.weight\", \"encoder.layer3.1.bn3.bias\", \"encoder.layer3.1.bn3.running_mean\", \"encoder.layer3.1.bn3.running_var\", \"encoder.layer3.1.bn3.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.2.conv3.weight\", \"encoder.layer3.2.bn3.weight\", \"encoder.layer3.2.bn3.bias\", \"encoder.layer3.2.bn3.running_mean\", \"encoder.layer3.2.bn3.running_var\", \"encoder.layer3.2.bn3.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.3.conv3.weight\", \"encoder.layer3.3.bn3.weight\", \"encoder.layer3.3.bn3.bias\", \"encoder.layer3.3.bn3.running_mean\", \"encoder.layer3.3.bn3.running_var\", \"encoder.layer3.3.bn3.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.4.conv3.weight\", \"encoder.layer3.4.bn3.weight\", \"encoder.layer3.4.bn3.bias\", \"encoder.layer3.4.bn3.running_mean\", \"encoder.layer3.4.bn3.running_var\", \"encoder.layer3.4.bn3.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer3.5.conv3.weight\", \"encoder.layer3.5.bn3.weight\", \"encoder.layer3.5.bn3.bias\", \"encoder.layer3.5.bn3.running_mean\", \"encoder.layer3.5.bn3.running_var\", \"encoder.layer3.5.bn3.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.conv3.weight\", \"encoder.layer4.0.bn3.weight\", \"encoder.layer4.0.bn3.bias\", \"encoder.layer4.0.bn3.running_mean\", \"encoder.layer4.0.bn3.running_var\", \"encoder.layer4.0.bn3.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.1.conv3.weight\", \"encoder.layer4.1.bn3.weight\", \"encoder.layer4.1.bn3.bias\", \"encoder.layer4.1.bn3.running_mean\", \"encoder.layer4.1.bn3.running_var\", \"encoder.layer4.1.bn3.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\", \"encoder.layer4.2.conv3.weight\", \"encoder.layer4.2.bn3.weight\", \"encoder.layer4.2.bn3.bias\", \"encoder.layer4.2.bn3.running_mean\", \"encoder.layer4.2.bn3.running_var\", \"encoder.layer4.2.bn3.num_batches_tracked\", \"decoder.blocks.0.conv1.0.weight\", \"decoder.blocks.0.conv1.1.weight\", \"decoder.blocks.0.conv1.1.bias\", \"decoder.blocks.0.conv1.1.running_mean\", \"decoder.blocks.0.conv1.1.running_var\", \"decoder.blocks.0.conv1.1.num_batches_tracked\", \"decoder.blocks.0.conv2.0.weight\", \"decoder.blocks.0.conv2.1.weight\", \"decoder.blocks.0.conv2.1.bias\", \"decoder.blocks.0.conv2.1.running_mean\", \"decoder.blocks.0.conv2.1.running_var\", \"decoder.blocks.0.conv2.1.num_batches_tracked\", \"decoder.blocks.1.conv1.0.weight\", \"decoder.blocks.1.conv1.1.weight\", \"decoder.blocks.1.conv1.1.bias\", \"decoder.blocks.1.conv1.1.running_mean\", \"decoder.blocks.1.conv1.1.running_var\", \"decoder.blocks.1.conv1.1.num_batches_tracked\", \"decoder.blocks.1.conv2.0.weight\", \"decoder.blocks.1.conv2.1.weight\", \"decoder.blocks.1.conv2.1.bias\", \"decoder.blocks.1.conv2.1.running_mean\", \"decoder.blocks.1.conv2.1.running_var\", \"decoder.blocks.1.conv2.1.num_batches_tracked\", \"decoder.blocks.2.conv1.0.weight\", \"decoder.blocks.2.conv1.1.weight\", \"decoder.blocks.2.conv1.1.bias\", \"decoder.blocks.2.conv1.1.running_mean\", \"decoder.blocks.2.conv1.1.running_var\", \"decoder.blocks.2.conv1.1.num_batches_tracked\", \"decoder.blocks.2.conv2.0.weight\", \"decoder.blocks.2.conv2.1.weight\", \"decoder.blocks.2.conv2.1.bias\", \"decoder.blocks.2.conv2.1.running_mean\", \"decoder.blocks.2.conv2.1.running_var\", \"decoder.blocks.2.conv2.1.num_batches_tracked\", \"decoder.blocks.3.conv1.0.weight\", \"decoder.blocks.3.conv1.1.weight\", \"decoder.blocks.3.conv1.1.bias\", \"decoder.blocks.3.conv1.1.running_mean\", \"decoder.blocks.3.conv1.1.running_var\", \"decoder.blocks.3.conv1.1.num_batches_tracked\", \"decoder.blocks.3.conv2.0.weight\", \"decoder.blocks.3.conv2.1.weight\", \"decoder.blocks.3.conv2.1.bias\", \"decoder.blocks.3.conv2.1.running_mean\", \"decoder.blocks.3.conv2.1.running_var\", \"decoder.blocks.3.conv2.1.num_batches_tracked\", \"decoder.blocks.4.conv1.0.weight\", \"decoder.blocks.4.conv1.1.weight\", \"decoder.blocks.4.conv1.1.bias\", \"decoder.blocks.4.conv1.1.running_mean\", \"decoder.blocks.4.conv1.1.running_var\", \"decoder.blocks.4.conv1.1.num_batches_tracked\", \"decoder.blocks.4.conv2.0.weight\", \"decoder.blocks.4.conv2.1.weight\", \"decoder.blocks.4.conv2.1.bias\", \"decoder.blocks.4.conv2.1.running_mean\", \"decoder.blocks.4.conv2.1.running_var\", \"decoder.blocks.4.conv2.1.num_batches_tracked\". \n\tsize mismatch for segmentation_head.0.weight: copying a param with shape torch.Size([1, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 128, 1, 1])."
     ]
    }
   ],
   "source": [
    "\"\"\"red is real\"\"\"\n",
    "if 1: #normal\n",
    "    if __name__ == '__main__':\n",
    "        if args.mode == 'eval':\n",
    "            eval_image(args)\n",
    "        elif args.mode =='gen_image':\n",
    "            gen_val_image(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-hydrogen",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "varied-feeling",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    # ---- factor ---- #\n",
    "    server ='kaggle' # ['kaggle', 'local'] local은 cv측정용도\n",
    "    amp = False\n",
    "    gpu = 1\n",
    "    \n",
    "    encoder='b4'#'resnet34'\n",
    "    decoder='unet'\n",
    "    \n",
    "    diff_arch = True\n",
    "    encoders = [\"efficientnet-b4\", \"efficientnet-b4\", \"resnet34\", \"xception\", \"dpn68\"]\n",
    "    decoders = [\"unet\", \"fpn\", \"upp\", \"unet\", \"upp\"]\n",
    "    n_fold = 5\n",
    "    batch_size=64\n",
    "    clf_head=False\n",
    "    \n",
    "    threshold = 0.3\n",
    "    \n",
    "    model_path = '../hubmap/result/'\n",
    "\n",
    "    en_model_path = [\"./data/result/30_['efficientnet-b4', 'efficientnet-b4', 'resnet34', 'xception', 'dpn68']_['unet', 'fpn', 'upp', 'unet', \"\\\n",
    "                  + \"'upp']_512_640_320_0.5_b4_512//checkpoint/\" + x for x in \\\n",
    "                 ['0fold_29epoch_0.9328_efficientnet-b4_unetmodel.pth','1fold_30epoch_0.9338_efficientnet-b4_fpnmodel.pth',\n",
    "                 '2fold_13epoch_0.9356_resnet34_uppmodel.pth','3fold_26epoch_0.9548_xception_unetmodel.pth',\n",
    "                 '4fold_9epoch_0.9258_dpn68_uppmodel.pth']]\n",
    "    sub = '30epoch_imagefold_0.9338_320_160'# submission name\n",
    "    \n",
    "    # ---- Dataset ---- #\n",
    "    \n",
    "    tile_size = 640\n",
    "    tile_average_step = 320\n",
    "    tile_scale = 0.5\n",
    "    tile_min_score = 0.25  \n",
    "\n",
    "assert args.server!='local', 'not implement'\n",
    "device = torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "horizontal-booking",
   "metadata": {
    "code_folding": [
     4,
     26,
     257,
     353,
     363
    ]
   },
   "outputs": [],
   "source": [
    "thres = args.threshold\n",
    "\n",
    "prob = []\n",
    "\n",
    "def mask_to_csv(image_id, submit_dir):\n",
    "\n",
    "    predicted = []\n",
    "    for id in image_id:\n",
    "        image_file = data_dir + '/test/%s.tiff' % id\n",
    "        image = read_tiff(image_file)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        predict_file = submit_dir + '/%s.predict.png' % id\n",
    "        # predict = cv2.imread(predict_file, cv2.IMREAD_GRAYSCALE)\n",
    "        predict = np.array(Image.open(predict_file))\n",
    "        predict = cv2.resize(predict, dsize=(width, height), interpolation=cv2.INTER_LINEAR)\n",
    "        predict = (predict > 128).astype(np.uint8) * 255\n",
    "\n",
    "        p = rle_encode(predict)\n",
    "        predicted.append(p)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = image_id\n",
    "    df['predicted'] = predicted\n",
    "    return df\n",
    "\n",
    "def run_submit(args):\n",
    "\n",
    "    #fold = 6\n",
    "    out_dir = args.model_path.split('checkpoint')[0]\n",
    "    initial_checkpoint = out_dir + '/checkpoint' + args.model_path.split('checkpoint')[1]\n",
    "    \n",
    "    # local은 cv측정 용도\n",
    "\n",
    "    server = args.server#'kaggle' , 'local'\n",
    "\n",
    "    #---\n",
    "    submit_dir = out_dir + '/test/%s-%s-mean-thres(%s)'%(server, initial_checkpoint[-18:-4],thres)\n",
    "    os.makedirs(submit_dir,exist_ok=True)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.submit.txt',mode='a')\n",
    "\n",
    "    #---\n",
    "    if server == 'local':\n",
    "        valid_image_id = make_image_id('valid-%d' % fold)\n",
    "    if server == 'kaggle':\n",
    "        valid_image_id = make_image_id('test-all')\n",
    "\n",
    "    if server == 'local':\n",
    "        tile_size = args.tile_size #320\n",
    "        tile_average_step = args.tile_average_step#320 #192\n",
    "        tile_scale = args.tile_scale\n",
    "        tile_min_score = args.tile_min_score\n",
    "    if server == 'kaggle' :\n",
    "        tile_size = args.tile_size#640#640 #320\n",
    "        tile_average_step = args.tile_average_step#320#320 #192\n",
    "        tile_scale = args.tile_scale#0.25\n",
    "        tile_min_score = args.tile_min_score#0.25   \n",
    "\n",
    "    log.write('tile_size = %d \\n'%tile_size)\n",
    "    log.write('tile_average_step = %d \\n'%tile_average_step)\n",
    "    log.write('tile_scale = %f \\n'%tile_scale)\n",
    "    log.write('tile_min_score = %f \\n'%tile_min_score)\n",
    "    log.write('\\n')\n",
    "\n",
    "    \n",
    "    # ----- model -------\n",
    "    net = SegModel() \n",
    "    net.to(device)\n",
    "    state_dict = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)['state_dict']\n",
    "    net.load_state_dict(state_dict,strict=True)  #True\n",
    "    net = net.eval()\n",
    "    \n",
    "    start_timer = timer()\n",
    "    for id in valid_image_id:\n",
    "        if server == 'local':\n",
    "            image_file = data_dir + '/train/%s.tiff' % id\n",
    "            image = read_tiff(image_file)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            json_file  = data_dir + '/train/%s-anatomical-structure.json' % id\n",
    "            structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)   \n",
    "            mask_file = data_dir + '/train/%s.mask.png' % id\n",
    "            mask  = read_mask(mask_file)\n",
    "\n",
    "        if server == 'kaggle':\n",
    "            image_file = data_dir + '/test/%s.tiff' % id\n",
    "            json_file  = data_dir + '/test/%s-anatomical-structure.json' % id\n",
    "\n",
    "            image = read_tiff(image_file)\n",
    "            height, width = image.shape[:2]\n",
    "            structure = draw_strcuture(read_json_as_df(json_file), height, width, structure=['Cortex'])\n",
    "\n",
    "            mask = None\n",
    "\n",
    "\n",
    "        #--- predict here!  ---\n",
    "        tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "\n",
    "        tile_image = tile['tile_image']\n",
    "        tile_image = np.stack(tile_image)[..., ::-1]\n",
    "        tile_image = np.ascontiguousarray(tile_image.transpose(0,3,1,2))\n",
    "        tile_image = tile_image.astype(np.float32)/255\n",
    "        print(tile_image.shape)\n",
    "        tile_probability = []\n",
    "        \n",
    "        batch = np.array_split(tile_image, len(tile_image)//4)\n",
    "        for t,m in enumerate(batch):\n",
    "            print('\\r %s  %d / %d   %s'%(id, t, len(batch), time_to_str(timer() - start_timer, 'sec')), end='',flush=True)\n",
    "            m = torch.from_numpy(m).to(device)\n",
    "\n",
    "            p = []\n",
    "            with torch.no_grad():\n",
    "                logit = net(m)\n",
    "                p.append(torch.sigmoid(logit))\n",
    "\n",
    "                #---\n",
    "                if server == 'kaggle':\n",
    "                    if 1: #tta here\n",
    "                        logit = net(m.flip(dims=(2,)))\n",
    "                        p.append(torch.sigmoid(logit.flip(dims=(2,))))\n",
    "\n",
    "                        logit = net(m.flip(dims=(3,)))\n",
    "                        p.append(torch.sigmoid(logit.flip(dims=(3,))))\n",
    "                    p = torch.stack(p).mean(0)\n",
    "                if server == 'local':\n",
    "                    if 0: #tta here\n",
    "                        #logit = data_parallel(net, m.flip(dims=(2,)))\n",
    "                        logit = net(m.flip(dims=(2,)))\n",
    "                        p.append(torch.sigmoid(logit.flip(dims=(2,))))\n",
    "\n",
    "                        #logit = data_parallel(net, m.flip(dims=(3,)))\n",
    "                        logit = net(m.flip(dims=(3,)))\n",
    "                        p.append(torch.sigmoid(logit.flip(dims=(3,))))\n",
    "                    p = torch.cat(p)\n",
    "                    #p = torch.stack(p)\n",
    "\n",
    "            tile_probability.append(p.data.cpu().numpy())\n",
    "\n",
    "        print('\\r' , end='',flush=True)\n",
    "        log.write('%s  %d / %d   %s\\n'%(id, t, len(batch), time_to_str(timer() - start_timer, 'sec')))\n",
    "\n",
    "        tile_probability = np.concatenate(tile_probability).squeeze(1)\n",
    "        height, width = tile['image_small'].shape[:2]\n",
    "        probability = to_mask(tile_probability, tile['coord'], height, width,\n",
    "                              tile_scale, tile_size, tile_average_step, tile_min_score,\n",
    "                              aggregate='mean')\n",
    "        \n",
    "\n",
    "        #--- show results ---\n",
    "        if server == 'local':\n",
    "            truth = tile['mask_small'].astype(np.float32)/255\n",
    "            truth2 = np.concatenate(tile['tile_mask']).astype(np.float32)/255\n",
    "        if server == 'kaggle':\n",
    "            truth = np.zeros((height, width), np.float32)\n",
    "\n",
    "        overlay = np.dstack([\n",
    "            np.zeros_like(truth),\n",
    "            probability, #green\n",
    "            truth, #red\n",
    "        ])\n",
    "        image_small = tile['image_small'].astype(np.float32)/255\n",
    "        predict = (probability>thres).astype(np.float32)\n",
    "        overlay1 = 1-(1-image_small)*(1-overlay)\n",
    "        overlay2 = image_small.copy()\n",
    "        overlay2 = draw_contour_overlay(overlay2, tile['structure_small'], color=(1, 1, 1), thickness=3)\n",
    "        overlay2 = draw_contour_overlay(overlay2, truth, color=(0, 0, 1), thickness=8)\n",
    "        overlay2 = draw_contour_overlay(overlay2, probability, color=(0, 1, 0), thickness=3)\n",
    "\n",
    "        if 1:\n",
    "            cv2.imwrite(submit_dir+'/%s.image_small.png'%id, (image_small*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.probability.png'%id, (probability*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.predict.png'%id, (predict*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.overlay.png'%id, (overlay*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.overlay1.png'%id, (overlay1*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.overlay2.png'%id, (overlay2*255).astype(np.uint8))\n",
    "\n",
    "        #---\n",
    "\n",
    "        if server == 'local':\n",
    "\n",
    "            loss = np_binary_cross_entropy_loss(probability, truth)\n",
    "            dice = np_dice_score(probability, truth) # 여기는 큰이미지로 바꾼상태에서 dice\n",
    "            dice2 = np_dice_score(tile_probability, truth2) # 작은이미지상태, 즉 training과 같은 cv구할려고 dice\n",
    "            tp, tn = np_accuracy(probability, truth)\n",
    "            log.write('submit_dir = %s \\n'%submit_dir)\n",
    "            log.write('initial_checkpoint = %s \\n'%initial_checkpoint)\n",
    "            log.write('loss   = %0.8f \\n'%loss)\n",
    "            log.write('dice   = %0.8f \\n'%dice)\n",
    "            log.write('dice2   = %0.8f \\n'%dice2)\n",
    "            log.write('tp, tn = %0.8f, %0.8f \\n'%(tp, tn))\n",
    "            log.write('\\n')\n",
    "            #cv2.waitKey(0)\n",
    "\n",
    "    #-----\n",
    "    if server == 'kaggle':\n",
    "        csv_file = submit_dir + args.sub+'.csv'\n",
    "        df = mask_to_csv(valid_image_id, submit_dir)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(df)\n",
    "\n",
    "    zz=0\n",
    "    \n",
    "def run_submit_ensemble(args):\n",
    "\n",
    "    #fold = 6\n",
    "    out_dir = args.en_model_path[0].split('checkpoint')[0]\n",
    "    \n",
    "    \n",
    "    # local은 cv측정 용도\n",
    "\n",
    "    server = args.server#'kaggle' , 'local'\n",
    "\n",
    "    #---\n",
    "    submit_dir = out_dir + '/test/%s-%s-thres(%s)'%(server, args.sub,thres)\n",
    "    os.makedirs(submit_dir,exist_ok=True)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.submit.txt',mode='a')\n",
    "\n",
    "    #---\n",
    "    if server == 'local':\n",
    "        valid_image_id = make_image_id('valid-%d' % fold)\n",
    "    if server == 'kaggle':\n",
    "        valid_image_id = make_image_id('test-all')\n",
    "\n",
    "    if server == 'local':\n",
    "        tile_size = args.tile_size #320\n",
    "        tile_average_step = args.tile_average_step#320 #192\n",
    "        tile_scale = args.tile_scale\n",
    "        tile_min_score = args.tile_min_score\n",
    "    if server == 'kaggle' :\n",
    "        tile_size = args.tile_size#640#640 #320\n",
    "        tile_average_step = args.tile_average_step#320#320 #192\n",
    "        tile_scale = args.tile_scale#0.25\n",
    "        tile_min_score = args.tile_min_score#0.25   \n",
    "\n",
    "    log.write('tile_size = %d \\n'%tile_size)\n",
    "    log.write('tile_average_step = %d \\n'%tile_average_step)\n",
    "    log.write('tile_scale = %f \\n'%tile_scale)\n",
    "    log.write('tile_min_score = %f \\n'%tile_min_score)\n",
    "    log.write('\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    start_timer = timer()\n",
    "    for id in valid_image_id:\n",
    "        fold_prob = []\n",
    "        for m_p in args.en_model_path:\n",
    "            initial_checkpoint = m_p\n",
    "            # ----- model -------\n",
    "            net = SegModel() \n",
    "            net.to(device)\n",
    "            state_dict = torch.load(initial_checkpoint, map_location=lambda storage, loc: storage)['state_dict']\n",
    "            net.load_state_dict(state_dict,strict=True)  #True\n",
    "            net = net.eval()\n",
    "            if server == 'local':\n",
    "                image_file = data_dir + '/train/%s.tiff' % id\n",
    "                image = read_tiff(image_file)\n",
    "                height, width = image.shape[:2]\n",
    "\n",
    "                json_file  = data_dir + '/train/%s-anatomical-structure.json' % id\n",
    "                structure = draw_strcuture_from_hue(image, fill=255, scale=tile_scale/32)   \n",
    "                mask_file = data_dir + '/train/%s.mask.png' % id\n",
    "                mask  = read_mask(mask_file)\n",
    "\n",
    "            if server == 'kaggle':\n",
    "                image_file = data_dir + '/test/%s.tiff' % id\n",
    "                json_file  = data_dir + '/test/%s-anatomical-structure.json' % id\n",
    "\n",
    "                image = read_tiff(image_file)\n",
    "                height, width = image.shape[:2]\n",
    "                structure = draw_strcuture(read_json_as_df(json_file), height, width, structure=['Cortex'])\n",
    "\n",
    "                mask = None\n",
    "\n",
    "\n",
    "            #--- predict here!  ---\n",
    "            tile = to_tile(image, mask, structure, tile_scale, tile_size, tile_average_step, tile_min_score)\n",
    "\n",
    "            tile_image = tile['tile_image']\n",
    "            tile_image = np.stack(tile_image)[..., ::-1]\n",
    "            tile_image = np.ascontiguousarray(tile_image.transpose(0,3,1,2))\n",
    "            tile_image = tile_image.astype(np.float32)/255\n",
    "            print(tile_image.shape)\n",
    "            tile_probability = []\n",
    "\n",
    "            batch = np.array_split(tile_image, len(tile_image)//4)\n",
    "            for t,m in enumerate(batch):\n",
    "                print('\\r %s  %d / %d   %s'%(id, t, len(batch), time_to_str(timer() - start_timer, 'sec')), end='',flush=True)\n",
    "                m = torch.from_numpy(m).to(device)\n",
    "\n",
    "                p = []\n",
    "                with torch.no_grad():\n",
    "                    logit = net(m)\n",
    "                    p.append(torch.sigmoid(logit))\n",
    "\n",
    "                    #---\n",
    "                    if server == 'kaggle':\n",
    "                        if 1: #tta here\n",
    "                            logit = net(m.flip(dims=(2,)))\n",
    "                            p.append(torch.sigmoid(logit.flip(dims=(2,))))\n",
    "\n",
    "                            logit = net(m.flip(dims=(3,)))\n",
    "                            p.append(torch.sigmoid(logit.flip(dims=(3,))))\n",
    "                        p = torch.stack(p).mean(0)\n",
    "                    if server == 'local':\n",
    "                        if 0: #tta here\n",
    "                            #logit = data_parallel(net, m.flip(dims=(2,)))\n",
    "                            logit = net(m.flip(dims=(2,)))\n",
    "                            p.append(torch.sigmoid(logit.flip(dims=(2,))))\n",
    "\n",
    "                            #logit = data_parallel(net, m.flip(dims=(3,)))\n",
    "                            logit = net(m.flip(dims=(3,)))\n",
    "                            p.append(torch.sigmoid(logit.flip(dims=(3,))))\n",
    "                        p = torch.cat(p)\n",
    "                        #p = torch.stack(p)\n",
    "\n",
    "                tile_probability.append(p.data.cpu().numpy())\n",
    "\n",
    "            print('\\r' , end='',flush=True)\n",
    "            log.write('%s  %d / %d   %s\\n'%(id, t, len(batch), time_to_str(timer() - start_timer, 'sec')))\n",
    "\n",
    "            tile_probability = np.concatenate(tile_probability).squeeze(1)\n",
    "            height, width = tile['image_small'].shape[:2]\n",
    "            probability = to_mask(tile_probability, tile['coord'], height, width,\n",
    "                                  tile_scale, tile_size, tile_average_step, tile_min_score,\n",
    "                                  aggregate='mean')\n",
    "\n",
    "            fold_prob.append(probability)\n",
    "        \n",
    "        probability = sum(fold_prob)/len(args.en_model_path)\n",
    "        #--- show results ---\n",
    "        if server == 'local':\n",
    "            truth = tile['mask_small'].astype(np.float32)/255\n",
    "            truth2 = np.concatenate(tile['tile_mask']).astype(np.float32)/255\n",
    "        if server == 'kaggle':\n",
    "            truth = np.zeros((height, width), np.float32)\n",
    "\n",
    "        overlay = np.dstack([\n",
    "            np.zeros_like(truth),\n",
    "            probability, #green\n",
    "            truth, #red\n",
    "        ])\n",
    "        image_small = tile['image_small'].astype(np.float32)/255\n",
    "        predict = (probability>thres).astype(np.float32)\n",
    "        overlay1 = 1-(1-image_small)*(1-overlay)\n",
    "        overlay2 = image_small.copy()\n",
    "        overlay2 = draw_contour_overlay(overlay2, tile['structure_small'], color=(1, 1, 1), thickness=3)\n",
    "        overlay2 = draw_contour_overlay(overlay2, truth, color=(0, 0, 1), thickness=8)\n",
    "        overlay2 = draw_contour_overlay(overlay2, probability, color=(0, 1, 0), thickness=3)\n",
    "\n",
    "        if 1:\n",
    "            cv2.imwrite(submit_dir+'/%s.image_small.png'%id, (image_small*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.probability.png'%id, (probability*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.predict.png'%id, (predict*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.overlay.png'%id, (overlay*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.overlay1.png'%id, (overlay1*255).astype(np.uint8))\n",
    "            cv2.imwrite(submit_dir+'/%s.overlay2.png'%id, (overlay2*255).astype(np.uint8))\n",
    "\n",
    "        #---\n",
    "\n",
    "        if server == 'local':\n",
    "\n",
    "            loss = np_binary_cross_entropy_loss(probability, truth)\n",
    "            dice = np_dice_score(probability, truth) # 여기는 큰이미지로 바꾼상태에서 dice\n",
    "            dice2 = np_dice_score(tile_probability, truth2) # 작은이미지상태, 즉 training과 같은 cv구할려고 dice\n",
    "            tp, tn = np_accuracy(probability, truth)\n",
    "            log.write('submit_dir = %s \\n'%submit_dir)\n",
    "            log.write('initial_checkpoint = %s \\n'%initial_checkpoint)\n",
    "            log.write('loss   = %0.8f \\n'%loss)\n",
    "            log.write('dice   = %0.8f \\n'%dice)\n",
    "            log.write('dice2   = %0.8f \\n'%dice2)\n",
    "            log.write('tp, tn = %0.8f, %0.8f \\n'%(tp, tn))\n",
    "            log.write('\\n')\n",
    "            #cv2.waitKey(0)\n",
    "\n",
    "    #-----\n",
    "    if server == 'kaggle':\n",
    "        csv_file = submit_dir +'.csv'\n",
    "        df = mask_to_csv(valid_image_id, submit_dir)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(df)\n",
    "\n",
    "    zz=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brazilian-pennsylvania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_size = 640 \n",
      "tile_average_step = 320 \n",
      "tile_scale = 0.500000 \n",
      "tile_min_score = 0.250000 \n",
      "\n",
      "(1423, 3, 640, 640)\n",
      "(5, 3, 640, 640)\n",
      " 2ec3f1bb9  0 / 355    0 min 07 sec"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-37ef7c2c9a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mrun_submit_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-ada87571763a>\u001b[0m in \u001b[0;36mrun_submit_ensemble\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if 0: #normal\n",
    "    if __name__ == '__main__':\n",
    "        run_submit(args)\n",
    "elif 1:# ensemble\n",
    "    if __name__ == '__main__':\n",
    "        run_submit_ensemble(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-cornell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubmap",
   "language": "python",
   "name": "hubmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
